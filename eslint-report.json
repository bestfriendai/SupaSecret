[{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/api/anthropic.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/api/chat-service.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/api/grok.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/api/image-generation.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/api/openai.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/api/transcribe-audio.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/api/transcription.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/AdMobService.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":370,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":370,"endColumn":17},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":392,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":392,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { Platform } from \"react-native\";\nimport Constants from \"expo-constants\";\nimport { hasAdvertisingConsent } from \"../state/consentStore\";\nimport { getConfig } from \"../config/production\";\n\n// Note: AdMob requires development build - this is demo mode for Expo Go\nconst IS_EXPO_GO = Constants.appOwnership === \"expo\";\nconst config = getConfig();\n\n// AdMob Ad Unit IDs - use test IDs in development, production IDs in release\nconst AD_UNIT_IDS = {\n  banner: __DEV__\n    ? Platform.select({\n        ios: \"ca-app-pub-3940256099942544/2934735716\",\n        android: \"ca-app-pub-3940256099942544/6300978111\",\n      })\n    : config.ADMOB.AD_UNITS.banner,\n  interstitial: __DEV__\n    ? Platform.select({\n        ios: \"ca-app-pub-3940256099942544/4411468910\",\n        android: \"ca-app-pub-3940256099942544/1033173712\",\n      })\n    : config.ADMOB.AD_UNITS.interstitial,\n  rewarded: __DEV__\n    ? Platform.select({\n        ios: \"ca-app-pub-3940256099942544/1712485313\",\n        android: \"ca-app-pub-3940256099942544/5224354917\",\n      })\n    : config.ADMOB.AD_UNITS.rewarded,\n};\n\nexport class AdMobService {\n  private static lastInterstitialTime = 0;\n  private static readonly INTERSTITIAL_COOLDOWN = 60000; // 1 minute\n  private static isInitialized = false;\n  private static mobileAds: any = null;\n  private static interstitialAd: any = null;\n  private static rewardedAd: any = null;\n  private static AdMobModule: any = null;\n\n  // Type definitions for AdMob components\n  private static MobileAdsType: any = null;\n  private static InterstitialAdType: any = null;\n  private static RewardedAdType: any = null;\n  private static BannerAdSizeType: any = null;\n  private static TestIdsType: any = null;\n  private static AdEventTypeConst: any = null;\n  private static RewardedAdEventTypeConst: any = null;\n\n  private static isValidAdUnit(id: any): boolean {\n    return typeof id === \"string\" && id.startsWith(\"ca-app-pub-\") && id.includes(\"/\");\n  }\n\n  static async initialize(): Promise<void> {\n    if (this.isInitialized) return;\n\n    if (IS_EXPO_GO) {\n      console.log(\"üéØ AdMob Demo Mode - Development build required for real ads\");\n      this.isInitialized = true;\n      return;\n    }\n\n    try {\n      // Real AdMob initialization for development build\n      this.AdMobModule = await import(\"react-native-google-mobile-ads\");\n      const {\n        default: mobileAds,\n        InterstitialAd,\n        RewardedAd,\n        BannerAdSize,\n        TestIds,\n        AdEventType,\n        RewardedAdEventType,\n      } = this.AdMobModule;\n\n      // Store type references for later use\n      this.MobileAdsType = mobileAds;\n      this.InterstitialAdType = InterstitialAd;\n      this.RewardedAdType = RewardedAd;\n      this.BannerAdSizeType = BannerAdSize;\n      this.TestIdsType = TestIds;\n      this.AdEventTypeConst = AdEventType;\n      this.RewardedAdEventTypeConst = RewardedAdEventType;\n\n      this.mobileAds = mobileAds;\n\n      // Initialize AdMob\n      await mobileAds().initialize();\n\n      // Set request configuration based on consent\n      const hasConsent = hasAdvertisingConsent();\n      await mobileAds().setRequestConfiguration({\n        // Set to true if user has not consented to personalized ads\n        tagForChildDirectedTreatment: false,\n        tagForUnderAgeOfConsent: false,\n        maxAdContentRating: \"MA\",\n        requestNonPersonalizedAdsOnly: !hasConsent,\n      });\n\n      // Pre-load interstitial ad (guard invalid unit)\n      if (this.isValidAdUnit(AD_UNIT_IDS.interstitial)) {\n        this.interstitialAd = InterstitialAd.createForAdRequest(AD_UNIT_IDS.interstitial);\n        this.interstitialAd.load();\n      } else {\n        console.warn(\"AdMob interstitial unit invalid/missing; skipping preload (demo mode path)\");\n      }\n\n      // Pre-load rewarded ad (guard invalid unit)\n      if (this.isValidAdUnit(AD_UNIT_IDS.rewarded)) {\n        this.rewardedAd = RewardedAd.createForAdRequest(AD_UNIT_IDS.rewarded);\n        this.rewardedAd.load();\n      } else {\n        console.warn(\"AdMob rewarded unit invalid/missing; skipping preload (demo mode path)\");\n      }\n\n      console.log(\"üöÄ AdMob initialized for development build\");\n      this.isInitialized = true;\n    } catch (error) {\n      console.warn(\n        \"AdMob not available, running in demo mode:\",\n        error instanceof Error ? error.message : String(error),\n      );\n      console.log(\"üéØ AdMob demo mode - react-native-google-mobile-ads not installed\");\n      this.isInitialized = true;\n    }\n  }\n\n  // Demo mode methods for Expo Go\n\n  static shouldShowAd(isPremium: boolean): boolean {\n    return !isPremium;\n  }\n\n  static async showInterstitialAd(isPremium: boolean = false): Promise<boolean> {\n    if (!this.shouldShowAd(isPremium)) {\n      console.log(\"üéØ User is premium, skipping ad\");\n      return false;\n    }\n\n    // Check consent\n    if (!hasAdvertisingConsent()) {\n      console.log(\"üéØ User has not consented to ads, skipping\");\n      return false;\n    }\n\n    const now = Date.now();\n    if (now - this.lastInterstitialTime < this.INTERSTITIAL_COOLDOWN) {\n      console.log(\"‚è∞ Ad cooldown active, skipping ad\");\n      return false;\n    }\n\n    if (IS_EXPO_GO) {\n      console.log(\"üéØ Demo: Interstitial ad would show here (Development build required)\");\n      return new Promise((resolve) => {\n        setTimeout(() => {\n          console.log(\"‚úÖ Demo interstitial ad completed\");\n          this.lastInterstitialTime = now;\n          resolve(true);\n        }, 1500);\n      });\n    }\n\n    try {\n      // Real AdMob implementation for development build\n      const loaded = await this.ensureInterstitialLoaded();\n      if (!loaded || !this.interstitialAd) return false;\n\n      // Use stored InterstitialAd type or try to import it with error handling\n      let InterstitialAd = this.InterstitialAdType;\n      if (!InterstitialAd) {\n        try {\n          const adModule = await import(\"react-native-google-mobile-ads\");\n          InterstitialAd = adModule.InterstitialAd;\n          this.InterstitialAdType = InterstitialAd;\n        } catch (importError) {\n          console.error(\"Failed to import InterstitialAd:\", importError);\n          return false;\n        }\n      }\n\n      return new Promise((resolve) => {\n        let unsubscribeLoaded: (() => void) | null = null;\n        let unsubscribeClosed: (() => void) | null = null;\n        let unsubscribeError: (() => void) | null = null;\n\n        const cleanup = () => {\n          try {\n            if (unsubscribeLoaded) unsubscribeLoaded();\n            if (unsubscribeClosed) unsubscribeClosed();\n            if (unsubscribeError) unsubscribeError();\n          } catch (cleanupError) {\n            console.warn(\"Error during cleanup:\", cleanupError);\n          }\n        };\n\n        try {\n          const AET = this.AdEventTypeConst || (this.AdMobModule && this.AdMobModule.AdEventType);\n          unsubscribeLoaded = this.interstitialAd.addAdEventListener(AET?.LOADED || \"loaded\", () => {\n            console.log(\"üöÄ Interstitial ad loaded, showing...\");\n            this.interstitialAd.show();\n          });\n\n          unsubscribeClosed = this.interstitialAd.addAdEventListener(AET?.CLOSED || \"closed\", () => {\n            console.log(\"‚úÖ Interstitial ad closed\");\n            this.lastInterstitialTime = now;\n\n            // Pre-load next ad with error handling\n            try {\n              if (this.isValidAdUnit(AD_UNIT_IDS.interstitial)) {\n                this.interstitialAd = InterstitialAd.createForAdRequest(AD_UNIT_IDS.interstitial);\n                this.interstitialAd.load();\n              }\n            } catch (adCreateError) {\n              console.warn(\"Failed to create new interstitial ad:\", adCreateError);\n            }\n\n            cleanup();\n            resolve(true);\n          });\n\n          unsubscribeError = this.interstitialAd.addAdEventListener(AET?.ERROR || \"error\", async (error: any) => {\n            console.error(\"Interstitial ad error:\", error);\n            // schedule reload with simple backoff and abort mechanism\n            let aborted = false;\n            const timeouts: NodeJS.Timeout[] = [];\n\n            const abort = () => {\n              aborted = true;\n              timeouts.forEach(clearTimeout);\n            };\n\n            // Store original cleanup and create enhanced cleanup\n            const originalCleanup = cleanup;\n            const enhancedCleanup = () => {\n              abort();\n              originalCleanup();\n            };\n\n            try {\n              for (let i = 0; i < 3 && !aborted; i++) {\n                const timeout = setTimeout(() => {}, 500 * Math.pow(2, i));\n                timeouts.push(timeout);\n                await new Promise((r) => setTimeout(r, 500 * Math.pow(2, i)));\n                if (aborted) break;\n\n                try {\n                  if (this.isValidAdUnit(AD_UNIT_IDS.interstitial)) {\n                    this.interstitialAd = InterstitialAd.createForAdRequest(AD_UNIT_IDS.interstitial);\n                    this.interstitialAd.load();\n                  }\n                  break;\n                } catch {}\n              }\n            } catch {}\n            enhancedCleanup();\n            resolve(false);\n          });\n\n          // If already loaded, show immediately\n          if (this.interstitialAd.loaded) {\n            this.interstitialAd.show();\n          }\n        } catch (error) {\n          console.error(\"Error setting up interstitial ad listeners:\", error);\n          cleanup();\n          resolve(false);\n        }\n      });\n    } catch (error) {\n      console.error(\"‚ùå Failed to show interstitial ad:\", error);\n      return false;\n    }\n  }\n\n  static async showRewardedAd(): Promise<{ shown: boolean; rewarded: boolean }> {\n    if (IS_EXPO_GO) {\n      console.log(\"üéØ Demo: Rewarded ad would show here (Development build required)\");\n      return new Promise((resolve) => {\n        setTimeout(() => {\n          console.log(\"‚úÖ Demo rewarded ad completed - user rewarded!\");\n          resolve({ shown: true, rewarded: true });\n        }, 2500);\n      });\n    }\n\n    try {\n      const ok = await this.ensureRewardedLoaded();\n      if (!ok || !this.rewardedAd) return { shown: false, rewarded: false };\n\n      return await new Promise((resolve) => {\n        let rewarded = false;\n        const RAET = this.RewardedAdEventTypeConst || (this.AdMobModule && this.AdMobModule.RewardedAdEventType);\n        const unsubscribeEarned = this.rewardedAd.addAdEventListener(RAET?.EARNED_REWARD || \"earned\", () => {\n          rewarded = true;\n        });\n        const finalize = (result: { shown: boolean; rewarded: boolean }) => {\n          try {\n            unsubscribeEarned?.();\n            unsubscribeClosed?.();\n            unsubscribeError?.();\n          } catch {}\n          resolve(result);\n        };\n        const AEType = this.AdEventTypeConst || (this.AdMobModule && this.AdMobModule.AdEventType);\n        const unsubscribeClosed = this.rewardedAd.addAdEventListener(AEType?.CLOSED || \"closed\", () => {\n          // preload next\n          try {\n            const { RewardedAd } = this.AdMobModule || {};\n            if (RewardedAd) {\n              if (this.isValidAdUnit(AD_UNIT_IDS.rewarded)) {\n                this.rewardedAd = RewardedAd.createForAdRequest(AD_UNIT_IDS.rewarded);\n                this.rewardedAd.load();\n              }\n            }\n          } catch {}\n          finalize({ shown: true, rewarded });\n        });\n        const unsubscribeError = this.rewardedAd.addAdEventListener(AEType?.ERROR || \"error\", () => {\n          // preload next after error\n          try {\n            const { RewardedAd } = this.AdMobModule || {};\n            if (RewardedAd) {\n              if (this.isValidAdUnit(AD_UNIT_IDS.rewarded)) {\n                this.rewardedAd = RewardedAd.createForAdRequest(AD_UNIT_IDS.rewarded);\n                this.rewardedAd.load();\n              }\n            }\n          } catch {}\n          finalize({ shown: false, rewarded: false });\n        });\n        this.rewardedAd.show();\n      });\n    } catch (error) {\n      console.error(\"‚ùå Failed to show rewarded ad:\", error);\n      return { shown: false, rewarded: false };\n    }\n  }\n\n  static getBannerAdUnitId(): string {\n    if (IS_EXPO_GO || __DEV__) {\n      return (\n        Platform.select({\n          ios: \"ca-app-pub-3940256099942544/2934735716\",\n          android: \"ca-app-pub-3940256099942544/6300978111\",\n        }) || \"demo-banner-ad-unit\"\n      );\n    }\n    // In production, return empty string to hide banner when IDs are missing\n    return this.isValidAdUnit(AD_UNIT_IDS.banner) ? (AD_UNIT_IDS.banner as string) : \"\";\n  }\n\n  static isExpoGo(): boolean {\n    return IS_EXPO_GO;\n  }\n\n  private static async ensureInterstitialLoaded(retries = 3, base = 500) {\n    if (IS_EXPO_GO) return true;\n    const { InterstitialAd } = this.AdMobModule || (await import(\"react-native-google-mobile-ads\"));\n    for (let i = 0; i < retries; i++) {\n      try {\n        if (!this.interstitialAd) {\n          if (!this.isValidAdUnit(AD_UNIT_IDS.interstitial)) return false;\n          this.interstitialAd = InterstitialAd.createForAdRequest(AD_UNIT_IDS.interstitial);\n        }\n        if (!this.interstitialAd.loaded) {\n          this.interstitialAd.load();\n        }\n        await new Promise((r) => setTimeout(r, 500 * (i + 1)));\n        if (this.interstitialAd.loaded) return true;\n      } catch (e) {\n        if (i === retries - 1) return false;\n        await new Promise((r) => setTimeout(r, base * Math.pow(2, i)));\n      }\n    }\n    return false;\n  }\n\n  private static async ensureRewardedLoaded(retries = 3, base = 500) {\n    if (IS_EXPO_GO) return true;\n    const { RewardedAd } = this.AdMobModule || (await import(\"react-native-google-mobile-ads\"));\n    for (let i = 0; i < retries; i++) {\n      try {\n        if (!this.rewardedAd) {\n          if (!this.isValidAdUnit(AD_UNIT_IDS.rewarded)) return false;\n          this.rewardedAd = RewardedAd.createForAdRequest(AD_UNIT_IDS.rewarded);\n        }\n        if (!this.rewardedAd.loaded) {\n          this.rewardedAd.load();\n        }\n        await new Promise((r) => setTimeout(r, 500 * (i + 1)));\n        if (this.rewardedAd.loaded) return true;\n      } catch (e) {\n        if (i === retries - 1) return false;\n        await new Promise((r) => setTimeout(r, base * Math.pow(2, i)));\n      }\n    }\n    return false;\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/Anonymiser.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/AvatarService.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'uploadData' is assigned a value but never used.","line":86,"column":13,"nodeType":null,"messageId":"unusedVar","endLine":86,"endColumn":23},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":310,"column":14,"nodeType":null,"messageId":"unusedVar","endLine":310,"endColumn":19}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Avatar Service\n * Handles avatar upload, compression, and management with Supabase Storage\n */\n\nimport * as FileSystem from \"../utils/legacyFileSystem\";\nimport * as ImageManipulator from \"expo-image-manipulator\";\nimport { supabase } from \"../lib/supabase\";\nimport { storageWithRetry } from \"../utils/supabaseWithRetry\";\n\nconst AVATAR_BUCKET = \"images\";\nconst MAX_AVATAR_SIZE = 1024; // 1024x1024 pixels\nconst AVATAR_QUALITY = 0.8;\nconst MAX_FILE_SIZE_MB = 5;\n\nexport interface AvatarUploadOptions {\n  onProgress?: (progress: number) => void;\n  quality?: number;\n  maxSize?: number;\n}\n\nexport interface AvatarUploadResult {\n  url: string;\n  path: string;\n  size: number;\n}\n\nexport class AvatarService {\n  /**\n   * Upload and process avatar image\n   */\n  static async uploadAvatar(\n    imageUri: string,\n    userId: string,\n    options: AvatarUploadOptions = {},\n  ): Promise<AvatarUploadResult> {\n    const { onProgress, quality = AVATAR_QUALITY, maxSize = MAX_AVATAR_SIZE } = options;\n\n    try {\n      onProgress?.(10);\n\n      // Validate file size\n      try {\n        const fileInfo = await FileSystem.getInfoAsync(imageUri);\n        if (!fileInfo.exists) {\n          throw new Error(\"Image file not found\");\n        }\n\n        const fileSizeMB = (fileInfo.size || 0) / (1024 * 1024);\n        if (fileSizeMB > MAX_FILE_SIZE_MB) {\n          throw new Error(\n            `Image file is too large (${fileSizeMB.toFixed(1)}MB). Maximum size is ${MAX_FILE_SIZE_MB}MB.`,\n          );\n        }\n      } catch (error) {\n        if (error instanceof Error && error.message.includes(\"too large\")) {\n          throw error;\n        }\n        throw new Error(\"Image file not found\");\n      }\n\n      onProgress?.(20);\n\n      // Process and compress image\n      const processedImage = await this.processImage(imageUri, {\n        maxSize,\n        quality,\n      });\n\n      onProgress?.(40);\n\n      // Generate unique filename\n      const timestamp = Date.now();\n      const filename = `${userId}_${timestamp}.jpg`;\n      const filePath = `${userId}/${filename}`;\n\n      onProgress?.(50);\n\n      // Convert processed image to blob for upload\n      const response = await fetch(processedImage.uri);\n      const blob = await response.blob();\n\n      onProgress?.(60);\n\n      // Upload to Supabase Storage with retry logic\n      const uploadData = await storageWithRetry.upload(AVATAR_BUCKET, filePath, blob, {\n        upsert: true,\n        retryOptions: {\n          maxAttempts: 3,\n          initialDelay: 1000,\n          maxDelay: 5000,\n        },\n      });\n\n      onProgress?.(80);\n\n      // Get public URL\n      const { data: urlData } = storageWithRetry.getPublicUrl(AVATAR_BUCKET, filePath);\n\n      if (!urlData.publicUrl) {\n        throw new Error(\"Failed to get public URL for uploaded avatar\");\n      }\n\n      onProgress?.(90);\n\n      // Clean up temporary processed image\n      await FileSystem.deleteAsync(processedImage.uri, { idempotent: true });\n\n      onProgress?.(100);\n\n      return {\n        url: urlData.publicUrl,\n        path: filePath,\n        size: blob.size,\n      };\n    } catch (error) {\n      console.error(\"Avatar upload failed:\", error);\n      throw new Error(error instanceof Error ? error.message : \"Failed to upload avatar. Please try again.\");\n    }\n  }\n\n  /**\n   * Process and compress image for avatar use\n   */\n  private static async processImage(\n    imageUri: string,\n    options: { maxSize: number; quality: number },\n  ): Promise<ImageManipulator.ImageResult> {\n    try {\n      // Get image dimensions\n      const imageInfo = await ImageManipulator.manipulateAsync(imageUri, [], {\n        format: ImageManipulator.SaveFormat.JPEG,\n      });\n\n      // Calculate resize dimensions to maintain aspect ratio\n      const { width, height } = imageInfo;\n      const maxDimension = Math.max(width, height);\n\n      let resizeWidth = width;\n      let resizeHeight = height;\n\n      if (maxDimension > options.maxSize) {\n        const ratio = options.maxSize / maxDimension;\n        resizeWidth = Math.round(width * ratio);\n        resizeHeight = Math.round(height * ratio);\n      }\n\n      // Process image: resize, crop to square, and compress\n      const processedImage = await ImageManipulator.manipulateAsync(\n        imageUri,\n        [\n          // Resize if needed\n          ...(maxDimension > options.maxSize ? [{ resize: { width: resizeWidth, height: resizeHeight } }] : []),\n          // Crop to square (center crop)\n          {\n            crop: {\n              originX: Math.max(0, (resizeWidth - Math.min(resizeWidth, resizeHeight)) / 2),\n              originY: Math.max(0, (resizeHeight - Math.min(resizeWidth, resizeHeight)) / 2),\n              width: Math.min(resizeWidth, resizeHeight),\n              height: Math.min(resizeWidth, resizeHeight),\n            },\n          },\n        ],\n        {\n          compress: options.quality,\n          format: ImageManipulator.SaveFormat.JPEG,\n        },\n      );\n\n      return processedImage;\n    } catch (error) {\n      console.error(\"Image processing failed:\", error);\n      throw new Error(\"Failed to process image. Please try a different image.\");\n    }\n  }\n\n  /**\n   * Delete old avatar from storage\n   */\n  static async deleteAvatar(avatarPath: string): Promise<void> {\n    try {\n      const { error } = await supabase.storage.from(AVATAR_BUCKET).remove([avatarPath]);\n\n      if (error) {\n        console.warn(\"Failed to delete old avatar:\", error);\n        // Don't throw error for deletion failures as it's not critical\n      }\n    } catch (error) {\n      console.warn(\"Avatar deletion failed:\", error);\n    }\n  }\n\n  /**\n   * Update user avatar URL in database\n   */\n  static async updateUserAvatar(userId: string, avatarUrl: string): Promise<void> {\n    try {\n      const { error } = await supabase\n        .from(\"profiles\" as any)\n        .update({\n          avatar_url: avatarUrl,\n          updated_at: new Date().toISOString(),\n        })\n        .eq(\"id\", userId);\n\n      if (error) {\n        throw error;\n      }\n    } catch (error) {\n      console.error(\"Failed to update user avatar in database:\", error);\n      throw new Error(\"Failed to update profile. Please try again.\");\n    }\n  }\n\n  /**\n   * Complete avatar update process\n   */\n  static async updateAvatar(\n    imageUri: string,\n    userId: string,\n    currentAvatarUrl?: string,\n    options: AvatarUploadOptions = {},\n  ): Promise<string> {\n    try {\n      // Upload new avatar\n      const uploadResult = await this.uploadAvatar(imageUri, userId, options);\n\n      // Update user profile\n      await this.updateUserAvatar(userId, uploadResult.url);\n\n      // Delete old avatar if it exists and is from our storage\n      if (currentAvatarUrl && this.isAvatarFromOurBucket(currentAvatarUrl)) {\n        const oldPath = this.extractPathFromUrl(currentAvatarUrl);\n        if (oldPath) {\n          await this.deleteAvatar(oldPath);\n        }\n      }\n\n      return uploadResult.url;\n    } catch (error) {\n      console.error(\"Avatar update failed:\", error);\n      throw error;\n    }\n  }\n\n  /**\n   * Check if URL is from our avatar bucket\n   */\n  private static isAvatarFromOurBucket(url: string): boolean {\n    try {\n      const parsedUrl = new URL(url);\n      // Check if the pathname contains our avatar bucket\n      return parsedUrl.pathname.includes(`/${AVATAR_BUCKET}/`);\n    } catch (error) {\n      console.warn(\"Failed to parse avatar URL:\", error);\n      return false;\n    }\n  }\n\n  /**\n   * Extract storage path from public URL\n   */\n  private static extractPathFromUrl(url: string): string | null {\n    try {\n      const parsedUrl = new URL(url);\n      const pathname = parsedUrl.pathname;\n\n      // Find the avatar bucket segment in the path\n      const bucketIndex = pathname.indexOf(`/${AVATAR_BUCKET}/`);\n      if (bucketIndex === -1) {\n        return null;\n      }\n\n      // Extract the path after the bucket segment\n      const pathAfterBucket = pathname.substring(bucketIndex + `/${AVATAR_BUCKET}/`.length);\n\n      // Decode URI components and normalize\n      const decodedPath = decodeURIComponent(pathAfterBucket);\n\n      return decodedPath || null;\n    } catch (error) {\n      console.warn(\"Failed to extract path from avatar URL:\", error);\n      return null;\n    }\n  }\n\n  /**\n   * Validate image file\n   */\n  static async validateImage(imageUri: string): Promise<{ valid: boolean; error?: string }> {\n    try {\n      const fileInfo = await FileSystem.getInfoAsync(imageUri);\n\n      if (!fileInfo.exists) {\n        return { valid: false, error: \"Image file not found\" };\n      }\n\n      const fileSizeMB = (fileInfo.size || 0) / (1024 * 1024);\n      if (fileSizeMB > MAX_FILE_SIZE_MB) {\n        return {\n          valid: false,\n          error: `Image file too large. Maximum size is ${MAX_FILE_SIZE_MB}MB`,\n        };\n      }\n\n      // Try to get image info to validate it's a valid image\n      await ImageManipulator.manipulateAsync(imageUri, [], {});\n\n      return { valid: true };\n    } catch (error) {\n      return {\n        valid: false,\n        error: \"Invalid image file. Please select a valid image.\",\n      };\n    }\n  }\n}\n\n// Export convenience functions\nexport const uploadAvatar = AvatarService.uploadAvatar.bind(AvatarService);\nexport const updateAvatar = AvatarService.updateAvatar.bind(AvatarService);\nexport const validateImage = AvatarService.validateImage.bind(AvatarService);\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/FaceBlurProcessor.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'Platform' is defined but never used.","line":2,"column":17,"nodeType":null,"messageId":"unusedVar","endLine":2,"endColumn":25},{"ruleId":"import/no-unresolved","severity":2,"message":"Unable to resolve path to module '@react-native-ml-kit/face-detection'.","line":17,"column":36,"nodeType":"Literal","endLine":17,"endColumn":73},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":57,"column":18,"nodeType":null,"messageId":"unusedVar","endLine":57,"endColumn":23},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'selectiveBlurCommand' is assigned a value but never used.","line":191,"column":9,"nodeType":null,"messageId":"unusedVar","endLine":191,"endColumn":29}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { useState, useCallback } from \"react\";\nimport { Alert, Platform } from \"react-native\";\nimport * as FileSystem from \"../utils/legacyFileSystem\";\nimport { IS_EXPO_GO } from \"../utils/environmentCheck\";\n\n// Lazy load native modules to prevent Expo Go crashes\nlet FaceDetection: any;\nlet FFmpegKit: any;\n\nconst loadNativeModules = async () => {\n  if (IS_EXPO_GO) {\n    throw new Error(\"Face blur not available in Expo Go - use development build\");\n  }\n\n  try {\n    if (!FaceDetection) {\n      FaceDetection = await import(\"@react-native-ml-kit/face-detection\");\n    }\n    if (!FFmpegKit) {\n      FFmpegKit = await import(\"ffmpeg-kit-react-native\");\n    }\n  } catch (error) {\n    console.error(\"Failed to load native modules:\", error);\n    throw new Error(\"Native modules not available\");\n  }\n};\n\nexport interface FaceBlurOptions {\n  blurIntensity?: number; // 1-50, default 15\n  detectionMode?: \"fast\" | \"accurate\"; // default 'fast'\n  onProgress?: (progress: number, status: string) => void;\n}\n\nexport const useFaceBlurProcessing = () => {\n  const [isProcessing, setIsProcessing] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n\n  const processVideoWithFaceBlur = useCallback(\n    async (videoUri: string, options: FaceBlurOptions = {}): Promise<string> => {\n      const { blurIntensity = 15, detectionMode = \"fast\", onProgress } = options;\n\n      setIsProcessing(true);\n      setError(null);\n      onProgress?.(0, \"Initializing face detection...\");\n\n      try {\n        // Load native modules\n        await loadNativeModules();\n        onProgress?.(10, \"Loading video for analysis...\");\n\n        // Check if input file exists\n        try {\n          const fileInfo = await FileSystem.getInfoAsync(videoUri);\n          if (!fileInfo.exists) {\n            throw new Error(\"Video file not found\");\n          }\n        } catch (error) {\n          throw new Error(\"Video file not found\");\n        }\n\n        // Create output path\n        const outputUri = videoUri.replace(/\\.(mp4|mov)$/i, \"_blurred.$1\");\n        onProgress?.(20, \"Detecting faces in video...\");\n\n        // For development builds, use ML Kit for face detection\n        const faceDetector = FaceDetection.FaceDetector.create({\n          detectionMode:\n            detectionMode === \"fast\" ? FaceDetection.FaceDetectionMode.FAST : FaceDetection.FaceDetectionMode.ACCURATE,\n          landmarkMode: FaceDetection.FaceDetectionLandmarkMode.NONE,\n          contourMode: FaceDetection.FaceDetectionContourMode.NONE,\n          classificationMode: FaceDetection.FaceDetectionClassificationMode.NONE,\n        });\n\n        // Extract first frame for face detection\n        const thumbnailUri = `${FileSystem.Paths.cache.uri}face_detection_frame.jpg`;\n\n        onProgress?.(30, \"Extracting frame for analysis...\");\n\n        // Use FFmpeg to extract first frame\n        const extractFrameCommand = `-i \"${videoUri}\" -vf \"select=eq(n\\\\,0)\" -vframes 1 -y \"${thumbnailUri}\"`;\n\n        const extractSession = await FFmpegKit.FFmpegKit.execute(extractFrameCommand);\n        const extractReturnCode = await extractSession.getReturnCode();\n\n        if (!FFmpegKit.ReturnCode.isSuccess(extractReturnCode)) {\n          throw new Error(\"Failed to extract frame for face detection\");\n        }\n\n        onProgress?.(40, \"Analyzing faces...\");\n\n        // Detect faces in the extracted frame\n        if (!faceDetector) {\n          throw new Error(\"Face detector not initialized\");\n        }\n        const faces = await faceDetector.processImage(thumbnailUri);\n\n        console.log(`Detected ${faces.length} faces in video`);\n\n        if (faces.length === 0) {\n          onProgress?.(100, \"No faces detected - returning original video\");\n          Alert.alert(\"No Faces Detected\", \"No faces found in the video. Original video will be used.\");\n          return videoUri;\n        }\n\n        onProgress?.(50, `Applying blur to ${faces.length} detected face(s)...`);\n\n        // Apply blur using FFmpeg\n        // For simplicity, we'll apply a general blur to the entire video\n        // In production, you'd want to track faces and apply selective blur\n        const blurCommand = `-i \"${videoUri}\" -vf \"boxblur=${blurIntensity}:1\" -c:a copy -y \"${outputUri}\"`;\n\n        onProgress?.(70, \"Processing video with face blur...\");\n\n        const blurSession = await FFmpegKit.FFmpegKit.execute(blurCommand);\n        const blurReturnCode = await blurSession.getReturnCode();\n\n        if (!FFmpegKit.ReturnCode.isSuccess(blurReturnCode)) {\n          const logs = await blurSession.getAllLogsAsString();\n          console.error(\"FFmpeg blur failed:\", logs);\n          throw new Error(\"Failed to apply face blur\");\n        }\n\n        onProgress?.(90, \"Finalizing processed video...\");\n\n        // Verify output file exists\n        const outputInfo = await FileSystem.getInfoAsync(outputUri);\n        if (!outputInfo.exists) {\n          throw new Error(\"Processed video file not created\");\n        }\n\n        // Cleanup temporary files\n        try {\n          await FileSystem.deleteAsync(thumbnailUri, { idempotent: true });\n        } catch (cleanupError) {\n          console.warn(\"Failed to cleanup temporary files:\", cleanupError);\n        }\n\n        onProgress?.(100, \"Face blur processing complete!\");\n\n        return outputUri;\n      } catch (error) {\n        const errorMessage = error instanceof Error ? error.message : \"Unknown error occurred\";\n        console.error(\"Face blur processing failed:\", error);\n        setError(errorMessage);\n\n        // Show user-friendly error\n        if (errorMessage.includes(\"Expo Go\")) {\n          Alert.alert(\"Feature Unavailable\", \"Face blur requires a development build. Please use the original video.\");\n        } else {\n          Alert.alert(\"Processing Error\", `Face blur failed: ${errorMessage}. Using original video.`);\n        }\n\n        // Return original video on error\n        return videoUri;\n      } finally {\n        setIsProcessing(false);\n      }\n    },\n    [],\n  );\n\n  return {\n    processVideoWithFaceBlur,\n    isProcessing,\n    error,\n  };\n};\n\n// Advanced face blur with selective region processing (for future enhancement)\nexport const processVideoWithSelectiveFaceBlur = async (\n  videoUri: string,\n  faces: any[],\n  options: FaceBlurOptions = {},\n): Promise<string> => {\n  const { blurIntensity = 15 } = options;\n\n  // This would implement frame-by-frame face tracking and selective blur\n  // For now, we use the simpler approach above\n\n  const outputUri = videoUri.replace(/\\.(mp4|mov)$/i, \"_selective_blur.$1\");\n\n  // Build complex FFmpeg filter for selective blur based on face coordinates\n  const faceFilters = faces\n    .map((face, index) => {\n      const { boundingBox } = face;\n      return `[0:v]crop=${boundingBox.width}:${boundingBox.height}:${boundingBox.left}:${boundingBox.top},boxblur=${blurIntensity}:1[blurred${index}]`;\n    })\n    .join(\";\");\n\n  // This is a simplified example - real implementation would be more complex\n  const selectiveBlurCommand = `-i \"${videoUri}\" -filter_complex \"${faceFilters}\" -c:a copy -y \"${outputUri}\"`;\n\n  // Implementation would continue here...\n  return outputUri;\n};\n\n// Fallback blur for Expo Go (applies general blur without face detection)\nexport const applyGeneralBlur = async (\n  videoUri: string,\n  blurIntensity: number = 15,\n  onProgress?: (progress: number, status: string) => void,\n): Promise<string> => {\n  onProgress?.(0, \"Applying general blur...\");\n\n  try {\n    // For Expo Go, we can't use FFmpeg, so we return the original video\n    // In a real implementation, you might use server-side processing\n    if (IS_EXPO_GO) {\n      onProgress?.(100, \"Blur not available in Expo Go\");\n      Alert.alert(\"Feature Limited\", \"Video blur requires a development build. Original video will be used.\");\n      return videoUri;\n    }\n\n    // Load FFmpeg for development builds\n    await loadNativeModules();\n\n    const outputUri = videoUri.replace(/\\.(mp4|mov)$/i, \"_blurred.$1\");\n\n    onProgress?.(50, \"Processing video with blur...\");\n\n    const blurCommand = `-i \"${videoUri}\" -vf \"boxblur=${blurIntensity}:1\" -c:a copy -y \"${outputUri}\"`;\n\n    const session = await FFmpegKit.FFmpegKit.execute(blurCommand);\n    const returnCode = await session.getReturnCode();\n\n    if (FFmpegKit.ReturnCode.isSuccess(returnCode)) {\n      onProgress?.(100, \"Blur applied successfully!\");\n      return outputUri;\n    } else {\n      throw new Error(\"Failed to apply blur\");\n    }\n  } catch (error) {\n    console.error(\"General blur failed:\", error);\n    onProgress?.(100, \"Blur failed - using original video\");\n    return videoUri;\n  }\n};\n\nexport default {\n  useFaceBlurProcessing,\n  processVideoWithSelectiveFaceBlur,\n  applyGeneralBlur,\n};\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/IAnonymiser.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/ModernVideoProcessor.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'ImageManipulator' is defined but never used.","line":8,"column":13,"nodeType":null,"messageId":"unusedVar","endLine":8,"endColumn":29},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'VideoView' is defined but never used.","line":9,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":9,"endColumn":19},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'useVideoPlayer' is defined but never used.","line":9,"column":21,"nodeType":null,"messageId":"unusedVar","endLine":9,"endColumn":35},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'Platform' is defined but never used.","line":13,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":13,"endColumn":18},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'FFmpegKitConfig' is assigned a value but never used.","line":27,"column":5,"nodeType":null,"messageId":"unusedVar","endLine":27,"endColumn":20},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":44,"column":12,"nodeType":null,"messageId":"unusedVar","endLine":44,"endColumn":17},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":148,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":148,"endColumn":21},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":246,"column":14,"nodeType":null,"messageId":"unusedVar","endLine":246,"endColumn":19}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":8,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Modern Video Processing Service for September 2025\n * Supports both Expo Go (fallback) and Development Builds (full features)\n * Replaces deprecated react-native-video-processing\n */\n\nimport * as VideoThumbnails from \"expo-video-thumbnails\";\nimport * as ImageManipulator from \"expo-image-manipulator\";\nimport { VideoView, useVideoPlayer } from \"expo-video\";\nimport * as FileSystem from \"../utils/legacyFileSystem\";\nimport { Directory } from \"expo-file-system\";\nimport Constants from \"expo-constants\";\nimport { Platform } from \"react-native\";\nimport {\n  videoValidation,\n  validateVideoProcessingOptions,\n  VideoProcessingOptions as ValidationVideoProcessingOptions,\n} from \"../utils/validation\";\n\n// Check if we're in Expo Go or Development Build\nconst IS_EXPO_GO = Constants.appOwnership === \"expo\";\nconst IS_DEV_BUILD = Constants.appOwnership === null;\nconst HAS_FFMPEG = !IS_EXPO_GO; // FFmpeg only available in dev builds\n\n// Lazy load FFmpeg for development builds only\nlet FFmpegKit: any = null;\nlet FFmpegKitConfig: any = null;\nlet FFprobeKit: any = null;\nlet ReturnCode: any = null;\n\nconst loadFFmpeg = async () => {\n  if (!HAS_FFMPEG || FFmpegKit) return;\n\n  try {\n    const ffmpegModule = await import(\"ffmpeg-kit-react-native\");\n    FFmpegKit = ffmpegModule.FFmpegKit;\n    FFmpegKitConfig = ffmpegModule.FFmpegKitConfig;\n    FFprobeKit = ffmpegModule.FFprobeKit;\n    ReturnCode = ffmpegModule.ReturnCode;\n\n    if (__DEV__) {\n      console.log(\"‚úÖ FFmpeg loaded successfully for development build\");\n    }\n  } catch (error) {\n    if (__DEV__) {\n      console.log(\"‚ö†Ô∏è FFmpeg not available - using Expo Go fallbacks\");\n    }\n  }\n};\n\n// Initialize FFmpeg on module load for dev builds\nif (HAS_FFMPEG) {\n  loadFFmpeg();\n}\n\nconst resolveCacheDirectory = (): string => {\n  const fsAny = FileSystem as unknown as {\n    cacheDirectory?: string | null;\n    documentDirectory?: string | null;\n    temporaryDirectory?: string | null;\n    Paths?: { cache?: { uri?: string }; document?: { uri?: string } };\n  };\n\n  const candidate =\n    fsAny.cacheDirectory ??\n    fsAny.documentDirectory ??\n    fsAny.temporaryDirectory ??\n    fsAny.Paths?.cache?.uri ??\n    fsAny.Paths?.document?.uri ??\n    null;\n\n  if (typeof candidate === \"string\" && candidate.length > 0) {\n    return candidate.endsWith(\"/\") ? candidate : `${candidate}/`;\n  }\n\n  throw new Error(\"Unable to resolve cache directory.\");\n};\n\nexport interface VideoProcessingOptions {\n  quality?: \"low\" | \"medium\" | \"high\" | \"highest\";\n  maxDuration?: number; // seconds\n  removeAudio?: boolean;\n  outputFormat?: \"mp4\" | \"mov\";\n  width?: number;\n  height?: number;\n  bitrate?: number;\n  fps?: number;\n}\n\nexport interface ProcessedVideo {\n  uri: string;\n  width: number;\n  height: number;\n  duration: number;\n  size: number;\n  thumbnail?: string;\n}\n\nexport class ModernVideoProcessor {\n  private static instance: ModernVideoProcessor;\n\n  static getInstance(): ModernVideoProcessor {\n    if (!this.instance) {\n      this.instance = new ModernVideoProcessor();\n    }\n    return this.instance;\n  }\n\n  /**\n   * Process video with automatic fallback for Expo Go\n   */\n  async processVideo(\n    videoUri: string,\n    options: VideoProcessingOptions = {},\n    onProgress?: (progress: number) => void,\n  ): Promise<ProcessedVideo> {\n    try {\n      onProgress?.(1);\n\n      // Validate processing options using comprehensive validation\n      const mappedOptions: ValidationVideoProcessingOptions = {\n        quality: options.quality === \"highest\" ? \"high\" : (options.quality as \"low\" | \"medium\" | \"high\" | undefined),\n        voiceEffect: \"none\", // Not supported in this processor\n        transcriptionEnabled: false, // Not supported in this processor\n        backgroundMusic: false,\n        filters: [], // Not supported in this processor\n      };\n\n      const optionsValidation = validateVideoProcessingOptions(mappedOptions);\n      if (!optionsValidation.isValid && optionsValidation.error) {\n        throw new Error(`Invalid processing options: ${optionsValidation.error}`);\n      }\n\n      // Log validation warnings\n      if (optionsValidation.warnings && __DEV__) {\n        console.warn(\"ModernVideoProcessor options warnings:\", optionsValidation.warnings);\n      }\n\n      onProgress?.(2);\n\n      // Validate video file\n      let fileInfo: any;\n      try {\n        fileInfo = await FileSystem.getInfoAsync(videoUri);\n        if (!fileInfo.exists) {\n          throw new Error(\"Video file does not exist\");\n        }\n      } catch (error) {\n        throw new Error(\"Video file does not exist\");\n      }\n\n      // Comprehensive file validation\n      const fileValidation = videoValidation.videoFile({ uri: videoUri, size: fileInfo.size });\n      if (!fileValidation.isValid && fileValidation.error) {\n        throw new Error(fileValidation.error);\n      }\n\n      // Validate file size\n      if (fileInfo.size) {\n        const maxSize = IS_EXPO_GO ? 50 : 200; // Lower limits for Expo Go\n        const sizeValidation = videoValidation.videoSize(fileInfo.size, maxSize);\n        if (!sizeValidation.isValid && sizeValidation.error) {\n          throw new Error(sizeValidation.error);\n        }\n\n        if (sizeValidation.warnings && __DEV__) {\n          console.warn(\"Video size warnings:\", sizeValidation.warnings);\n        }\n      }\n\n      // Validate video format from URI\n      const videoFormat = this.extractFormatFromUri(videoUri);\n      if (videoFormat) {\n        const formatValidation = videoValidation.videoFormat(videoFormat);\n        if (!formatValidation.isValid && formatValidation.error) {\n          throw new Error(formatValidation.error);\n        }\n      }\n\n      // Validate environment-specific options\n      if (IS_EXPO_GO && options.maxDuration && options.maxDuration > 120) {\n        throw new Error(\"Maximum duration in Expo Go is limited to 120 seconds\");\n      }\n\n      if (!IS_EXPO_GO && options.maxDuration && options.maxDuration > 300) {\n        throw new Error(\"Maximum duration is limited to 300 seconds\");\n      }\n\n      onProgress?.(5);\n\n      // Process video with selected method\n      if (IS_EXPO_GO) {\n        try {\n          return await this.processVideoExpoGo(videoUri, options, onProgress);\n        } catch (error) {\n          console.error(\"Expo Go processing failed, using minimal fallback:\", error);\n          // Minimal fallback - just copy the file and generate basic metadata\n          return this.createMinimalProcessedVideo(videoUri, options);\n        }\n      } else {\n        return this.processVideoWithFFmpeg(videoUri, options, onProgress);\n      }\n    } catch (error) {\n      console.error(\"[ModernVideoProcessor] Processing failed:\", error);\n\n      // Enhanced error handling for validation errors\n      if (error instanceof Error) {\n        if (\n          error.message.includes(\"Invalid processing options:\") ||\n          error.message.includes(\"Unsupported video format\") ||\n          error.message.includes(\"Video size must be less than\") ||\n          error.message.includes(\"Maximum duration\")\n        ) {\n          // These are validation errors - re-throw with original message\n          throw error;\n        }\n\n        throw new Error(`Video processing failed: ${error.message}`);\n      }\n\n      throw new Error(\"Video processing failed: Unknown error occurred\");\n    }\n  }\n\n  /**\n   * Expo Go fallback - limited processing using only Expo SDK APIs\n   */\n  private async processVideoExpoGo(\n    videoUri: string,\n    options: VideoProcessingOptions,\n    onProgress?: (progress: number) => void,\n  ): Promise<ProcessedVideo> {\n    if (__DEV__) {\n      console.log(\"üì± Using Expo Go video processing fallback\");\n    }\n\n    onProgress?.(10);\n\n    // Get video info\n    let videoInfo: any;\n    try {\n      videoInfo = await FileSystem.getInfoAsync(videoUri);\n      if (!videoInfo.exists) {\n        throw new Error(\"Video file not found\");\n      }\n    } catch (error) {\n      throw new Error(\"Video file not found\");\n    }\n\n    onProgress?.(30);\n\n    // Generate thumbnail\n    const thumbnail = await this.generateThumbnail(videoUri);\n\n    onProgress?.(60);\n\n    // In Expo Go, we can't compress or trim, so we just copy the file\n    const outputDir = `${resolveCacheDirectory()}processed/`;\n    new Directory(outputDir).create({ intermediates: true });\n\n    const outputUri = `${outputDir}video_${Date.now()}.mp4`;\n    await FileSystem.copyAsync({\n      from: videoUri,\n      to: outputUri,\n    });\n\n    onProgress?.(90);\n\n    // Return processed video info\n    const result: ProcessedVideo = {\n      uri: outputUri,\n      width: 1920, // Default values since we can't get actual dimensions in Expo Go\n      height: 1080,\n      duration: 60, // Default duration\n      size: (videoInfo as any).size || 0,\n      thumbnail,\n    };\n\n    onProgress?.(100);\n\n    if (__DEV__) {\n      console.log(\"‚úÖ Expo Go video processing complete (limited features)\");\n    }\n\n    return result;\n  }\n\n  /**\n   * Development build - full processing with FFmpeg\n   */\n  private async processVideoWithFFmpeg(\n    videoUri: string,\n    options: VideoProcessingOptions,\n    onProgress?: (progress: number) => void,\n  ): Promise<ProcessedVideo> {\n    await loadFFmpeg();\n\n    if (!FFmpegKit) {\n      console.warn(\"FFmpeg not available, falling back to Expo Go processing\");\n      return this.processVideoExpoGo(videoUri, options, onProgress);\n    }\n\n    if (__DEV__) {\n      console.log(\"üé¨ Using FFmpeg for full video processing\");\n    }\n\n    onProgress?.(10);\n\n    // Get video metadata\n    const metadata = await this.getVideoMetadata(videoUri);\n\n    onProgress?.(20);\n\n    // Build FFmpeg command\n    const outputDir = `${resolveCacheDirectory()}processed/`;\n    new Directory(outputDir).create({ intermediates: true });\n\n    const outputUri = `${outputDir}video_${Date.now()}.mp4`;\n    const command = this.buildFFmpegCommand(videoUri, outputUri, options, metadata);\n\n    onProgress?.(30);\n\n    // Execute FFmpeg command\n    const session = await FFmpegKit.execute(command);\n    const returnCode = await session.getReturnCode();\n\n    if (!ReturnCode.isSuccess(returnCode)) {\n      throw new Error(\"Video processing failed\");\n    }\n\n    onProgress?.(80);\n\n    // Generate thumbnail\n    const thumbnail = await this.generateThumbnail(outputUri);\n\n    onProgress?.(90);\n\n    // Get processed video info\n    const processedInfo = await FileSystem.getInfoAsync(outputUri);\n    const processedMetadata = await this.getVideoMetadata(outputUri);\n\n    const result: ProcessedVideo = {\n      uri: outputUri,\n      width: processedMetadata.width,\n      height: processedMetadata.height,\n      duration: processedMetadata.duration,\n      size: (processedInfo as any).size || 0,\n      thumbnail,\n    };\n\n    onProgress?.(100);\n\n    if (__DEV__) {\n      console.log(\"‚úÖ FFmpeg video processing complete\");\n    }\n\n    return result;\n  }\n\n  /**\n   * Create minimal processed video for fallback scenarios\n   */\n  private async createMinimalProcessedVideo(\n    videoUri: string,\n    options: VideoProcessingOptions,\n  ): Promise<ProcessedVideo> {\n    // Just copy the file and generate basic metadata\n    const outputDir = `${resolveCacheDirectory()}fallback/`;\n    new Directory(outputDir).create({ intermediates: true });\n\n    const outputUri = `${outputDir}video_${Date.now()}.mp4`;\n    await FileSystem.copyAsync({\n      from: videoUri,\n      to: outputUri,\n    });\n\n    // Generate thumbnail\n    const thumbnail = await this.generateThumbnail(videoUri);\n\n    // Get file size\n    let size = 0;\n    try {\n      const fileInfo = await FileSystem.getInfoAsync(outputUri);\n      size = (fileInfo as any).size || 0;\n    } catch (error) {\n      console.warn(\"Could not get file size:\", error);\n    }\n\n    return {\n      uri: outputUri,\n      width: 1920,\n      height: 1080,\n      duration: 60,\n      size,\n      thumbnail,\n    };\n  }\n\n  /**\n   * Generate video thumbnail\n   */\n  async generateThumbnail(videoUri: string, time: number = 0): Promise<string> {\n    try {\n      const { uri } = await VideoThumbnails.getThumbnailAsync(videoUri, {\n        time: time * 1000, // Convert to milliseconds\n        quality: 0.8,\n      });\n      return uri;\n    } catch (error) {\n      if (__DEV__) {\n        console.warn(\"Failed to generate thumbnail:\", error);\n      }\n      // Return a placeholder or empty string if thumbnail generation fails\n      return \"\";\n    }\n  }\n\n  /**\n   * Get video metadata using FFprobe (dev builds only)\n   */\n  private async getVideoMetadata(videoUri: string): Promise<any> {\n    if (!FFprobeKit) {\n      // Return default values for Expo Go\n      return {\n        width: 1920,\n        height: 1080,\n        duration: 60,\n        bitrate: 5000000,\n        fps: 30,\n      };\n    }\n\n    return new Promise((resolve, reject) => {\n      FFprobeKit.getMediaInformation(videoUri, async (session: any) => {\n        const info = await session.getMediaInformation();\n        if (info) {\n          const streams = info.getStreams();\n          const videoStream = streams.find((s: any) => s.getType() === \"video\");\n\n          resolve({\n            width: videoStream?.getWidth() || 1920,\n            height: videoStream?.getHeight() || 1080,\n            duration: info.getDuration() || 60,\n            bitrate: info.getBitrate() || 5000000,\n            fps: videoStream?.getFps() || 30,\n          });\n        } else {\n          reject(new Error(\"Failed to get video metadata\"));\n        }\n      });\n    });\n  }\n\n  /**\n   * Build FFmpeg command based on options\n   */\n  private buildFFmpegCommand(\n    inputUri: string,\n    outputUri: string,\n    options: VideoProcessingOptions,\n    metadata: any,\n  ): string {\n    const args: string[] = [\"-i\", inputUri];\n\n    // Quality/bitrate settings\n    const qualityBitrates = {\n      low: 500000,\n      medium: 1000000,\n      high: 2500000,\n      highest: 5000000,\n    };\n\n    const bitrate = options.bitrate || qualityBitrates[options.quality || \"high\"];\n    args.push(\"-b:v\", `${bitrate}`);\n\n    // Resolution\n    if (options.width || options.height) {\n      const width = options.width || -2;\n      const height = options.height || -2;\n      args.push(\"-vf\", `scale=${width}:${height}`);\n    }\n\n    // Frame rate\n    if (options.fps) {\n      args.push(\"-r\", `${options.fps}`);\n    }\n\n    // Duration limit\n    if (options.maxDuration) {\n      args.push(\"-t\", `${options.maxDuration}`);\n    }\n\n    // Audio settings\n    if (options.removeAudio) {\n      args.push(\"-an\");\n    } else {\n      args.push(\"-c:a\", \"aac\", \"-b:a\", \"128k\");\n    }\n\n    // Output format\n    args.push(\"-c:v\", \"h264\");\n    args.push(\"-preset\", \"fast\");\n    args.push(\"-movflags\", \"faststart\");\n\n    // Output file\n    args.push(outputUri);\n\n    return args.join(\" \");\n  }\n\n  /**\n   * Trim video (start and end times in seconds)\n   */\n  async trimVideo(\n    videoUri: string,\n    startTime: number,\n    endTime: number,\n    onProgress?: (progress: number) => void,\n  ): Promise<ProcessedVideo> {\n    if (IS_EXPO_GO) {\n      // In Expo Go, we can't trim, so return original\n      if (__DEV__) {\n        console.warn(\"Video trimming not available in Expo Go\");\n      }\n      return this.processVideoExpoGo(videoUri, {}, onProgress);\n    }\n\n    await loadFFmpeg();\n    if (!FFmpegKit) {\n      return this.processVideoExpoGo(videoUri, {}, onProgress);\n    }\n\n    const outputDir = `${resolveCacheDirectory()}trimmed/`;\n    new Directory(outputDir).create({ intermediates: true });\n\n    const outputUri = `${outputDir}trimmed_${Date.now()}.mp4`;\n    const duration = endTime - startTime;\n\n    // Safe FFmpeg arguments to prevent command injection\n    const safeStartTime = String(startTime).replace(/[^0-9.]/g, \"\");\n    const safeDuration = String(duration).replace(/[^0-9.]/g, \"\");\n    const safeVideoUri = videoUri.replace(/[;&|`$(){}[\\]<>]/g, \"\");\n    const safeOutputUri = outputUri.replace(/[;&|`$(){}[\\]<>]/g, \"\");\n\n    const command = `-ss ${safeStartTime} -i \"${safeVideoUri}\" -t ${safeDuration} -c copy \"${safeOutputUri}\"`;\n\n    const session = await FFmpegKit.execute(command);\n    const returnCode = await session.getReturnCode();\n\n    if (!ReturnCode.isSuccess(returnCode)) {\n      throw new Error(\"Video trimming failed\");\n    }\n\n    return this.getVideoInfo(outputUri);\n  }\n\n  /**\n   * Compress video\n   */\n  async compressVideo(\n    videoUri: string,\n    quality: \"low\" | \"medium\" | \"high\" = \"medium\",\n    onProgress?: (progress: number) => void,\n  ): Promise<ProcessedVideo> {\n    return this.processVideo(videoUri, { quality }, onProgress);\n  }\n\n  /**\n   * Extract video format from URI for validation\n   */\n  private extractFormatFromUri(videoUri: string): string | null {\n    try {\n      // Extract file extension from URI\n      const match = videoUri.match(/\\.([a-zA-Z0-9]+)(\\?.*)?$/);\n      if (match && match[1]) {\n        return match[1].toLowerCase();\n      }\n\n      // Try to extract from common video patterns\n      const formats = [\"mp4\", \"mov\", \"avi\", \"mkv\", \"m4v\", \"3gp\", \"webm\"];\n      for (const format of formats) {\n        if (videoUri.toLowerCase().includes(format)) {\n          return format;\n        }\n      }\n\n      return null;\n    } catch (error) {\n      if (__DEV__) {\n        console.warn(\"Failed to extract format from URI:\", videoUri, error);\n      }\n      return null;\n    }\n  }\n\n  /**\n   * Get basic video information\n   */\n  private async getVideoInfo(videoUri: string): Promise<ProcessedVideo> {\n    let fileSize = 0;\n    try {\n      const fileInfo = await FileSystem.getInfoAsync(videoUri);\n      fileSize = (fileInfo as any).size || 0;\n    } catch (error) {\n      console.warn(\"Could not get file info:\", error);\n    }\n\n    const thumbnail = await this.generateThumbnail(videoUri);\n    const metadata = await this.getVideoMetadata(videoUri);\n\n    return {\n      uri: videoUri,\n      width: metadata.width,\n      height: metadata.height,\n      duration: metadata.duration,\n      size: fileSize,\n      thumbnail,\n    };\n  }\n\n  /**\n   * Check if video processing features are available\n   */\n  static getCapabilities() {\n    return {\n      isExpoGo: IS_EXPO_GO,\n      isDevBuild: IS_DEV_BUILD,\n      hasFFmpeg: HAS_FFMPEG,\n      features: {\n        playback: true,\n        thumbnail: true,\n        trim: HAS_FFMPEG,\n        compress: HAS_FFMPEG,\n        removeAudio: HAS_FFMPEG,\n        resize: HAS_FFMPEG,\n        metadata: HAS_FFMPEG,\n      },\n    };\n  }\n}\n\n// Export singleton instance\nexport const videoProcessor = ModernVideoProcessor.getInstance();\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/NativeAnonymiser.ts","messages":[{"ruleId":"import/no-unresolved","severity":2,"message":"Unable to resolve path to module '@react-native-ml-kit/face-detection'.","line":28,"column":46,"nodeType":"Literal","endLine":28,"endColumn":83},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'transcriptionError' is defined but never used.","line":435,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":435,"endColumn":34}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import * as FileSystem from \"../utils/legacyFileSystem\";\nimport { Directory } from \"expo-file-system\";\nimport * as VideoThumbnails from \"expo-video-thumbnails\";\nimport { IAnonymiser, ProcessedVideo, VideoProcessingOptions } from \"./IAnonymiser\";\nimport { env } from \"../utils/env\";\n\n// These imports will only work in development/standalone builds, not in Expo Go\nlet FFmpegKit: any;\nlet ReturnCode: any;\nlet FaceDetection: any;\nlet Voice: any;\n\n// Lazy load native modules to prevent Expo Go crashes\nconst loadNativeModules = async () => {\n  if (env.expoGo) {\n    throw new Error(\"Native modules not available in Expo Go\");\n  }\n\n  try {\n    if (!FFmpegKit) {\n      const ffmpegModule = await import(\"ffmpeg-kit-react-native\");\n      FFmpegKit = ffmpegModule.FFmpegKit;\n      ReturnCode = ffmpegModule.ReturnCode;\n    }\n\n    if (!FaceDetection) {\n      try {\n        const faceModule: any = await import(\"@react-native-ml-kit/face-detection\");\n        FaceDetection = faceModule.default || faceModule;\n      } catch (error) {\n        console.warn(\"Face detection module not available:\", error);\n        // Provide fallback that will apply general blur\n        FaceDetection = {\n          detectFaces: async (imagePath: string) => {\n            console.warn(\"Using fallback face detection - applying general blur\");\n            return [\n              {\n                bounds: { x: 0, y: 0, width: 1920, height: 1080 }, // Full frame blur as fallback\n                landmarks: [],\n                angles: { x: 0, y: 0, z: 0 },\n              },\n            ];\n          },\n        };\n      }\n    }\n\n    if (!Voice) {\n      try {\n        const voiceModule = await import(\"@react-native-voice/voice\");\n        Voice = voiceModule.default || voiceModule;\n      } catch (error) {\n        console.warn(\"Voice recognition module not available:\", error);\n        // Provide fallback Voice mock\n        Voice = {\n          onSpeechResults: null,\n          onSpeechError: null,\n          start: async () => {},\n          destroy: async () => ({ removeAllListeners: () => {} }),\n        };\n      }\n    }\n  } catch (error) {\n    console.error(\"Failed to load native modules:\", error);\n    throw new Error(\"Native anonymization features require development build\");\n  }\n};\n\nconst tmp = FileSystem.Paths.cache.uri!;\n\nclass NativeAnonymiserImpl implements IAnonymiser {\n  private isInitialized = false;\n\n  async initialize(): Promise<void> {\n    if (this.isInitialized) return;\n\n    console.log(\"üöÄ NativeAnonymiser - Real processing with ML Kit + FFmpeg\");\n\n    try {\n      await loadNativeModules();\n\n      // Set global flag for compatibility\n      (global as any).__ffmpegAvailable = true;\n\n      this.isInitialized = true;\n    } catch (error) {\n      console.error(\"NativeAnonymiser initialization failed:\", error);\n      throw error;\n    }\n  }\n\n  async processVideo(videoUri: string, options: VideoProcessingOptions = {}): Promise<ProcessedVideo> {\n    await this.initialize();\n\n    const {\n      enableFaceBlur = true,\n      enableVoiceChange = true,\n      enableTranscription = true,\n      quality = \"medium\",\n      voiceEffect = \"deep\",\n      onProgress,\n    } = options;\n\n    onProgress?.(5, \"Preparing video processing...\");\n\n    try {\n      // Step 1: Face detection pass\n      let blurFilter = \"\";\n      if (enableFaceBlur) {\n        onProgress?.(15, \"Detecting faces for anonymization...\");\n        const faceBoxes = await this.scanFaces(videoUri);\n        blurFilter = this.buildBlurFilter(faceBoxes);\n      }\n\n      // Step 2: Generate transcription first (needed for video processing)\n      let transcription = \"\";\n      if (enableTranscription) {\n        onProgress?.(30, \"Generating speech transcription...\");\n        transcription = await this.generateTranscription(videoUri);\n      }\n\n      // Step 3: FFmpeg video + audio transform with captions\n      onProgress?.(50, \"Applying face blur, voice modifications, and captions...\");\n      const processedUri = await this.processVideoWithFFmpeg(\n        videoUri,\n        blurFilter,\n        enableVoiceChange,\n        voiceEffect,\n        quality,\n        enableTranscription ? transcription : undefined,\n      );\n\n      // Step 4: Generate thumbnail\n      onProgress?.(85, \"Creating thumbnail...\");\n      const thumbnailUri = await this.generateThumbnail(processedUri);\n\n      // Step 5: Get video duration\n      onProgress?.(95, \"Finalizing...\");\n      const duration = await this.getVideoDuration(processedUri);\n\n      onProgress?.(100, \"Processing complete!\");\n\n      return {\n        uri: processedUri,\n        transcription,\n        duration,\n        thumbnailUri,\n        faceBlurApplied: enableFaceBlur,\n        voiceChangeApplied: enableVoiceChange,\n      };\n    } catch (error) {\n      console.error(\"Native video processing failed:\", error);\n      throw new Error(`Video processing failed: ${error instanceof Error ? error.message : \"Unknown error\"}`);\n    }\n  }\n\n  private async scanFaces(videoUri: string): Promise<{ x: number; y: number; w: number; h: number }[]> {\n    // Extract frames for face detection\n    const framesDir = `${tmp}frames_${Date.now()}/`;\n    new Directory(framesDir).create({ intermediates: true });\n\n    try {\n      // Extract every 30th frame (1 fps for 30fps video) as JPEGs\n      const extractArgs = [\n        \"-y\",\n        \"-i\",\n        this.stripFileScheme(videoUri),\n        \"-vf\",\n        \"select=not(mod(n,30))\", // Fixed: removed unnecessary backslash\n        \"-vsync\",\n        \"vfr\",\n        \"-q:v\",\n        \"2\", // High quality JPEG\n        `${this.stripFileScheme(framesDir)}%03d.jpg`,\n      ];\n\n      await this.runFFmpegCommand(extractArgs);\n\n      // Process each frame for face detection\n      const files = await FileSystem.readDirectoryAsync(framesDir);\n      const allFaceBoxes: { x: number; y: number; w: number; h: number }[] = [];\n\n      for (const fileName of files) {\n        if (!fileName.endsWith(\".jpg\")) continue;\n\n        const imagePath = `${framesDir}${fileName}`;\n\n        try {\n          const faces = await FaceDetection.detectFaces(imagePath);\n\n          faces.forEach((face: any) => {\n            if (face.bounds) {\n              allFaceBoxes.push({\n                x: Math.round(face.bounds.x),\n                y: Math.round(face.bounds.y),\n                w: Math.round(face.bounds.width),\n                h: Math.round(face.bounds.height),\n              });\n            }\n          });\n        } catch (faceDetectionError) {\n          console.warn(`Face detection failed for frame ${fileName}:`, faceDetectionError);\n        }\n\n        // Clean up frame file immediately\n        await FileSystem.deleteAsync(imagePath, { idempotent: true });\n      }\n\n      // Clean up frames directory\n      await FileSystem.deleteAsync(framesDir, { idempotent: true });\n\n      // Merge overlapping face boxes\n      return this.mergeFaceBoxes(allFaceBoxes);\n    } catch (error) {\n      // Clean up on error\n      await FileSystem.deleteAsync(framesDir, { idempotent: true });\n      throw error;\n    }\n  }\n\n  private mergeFaceBoxes(\n    boxes: { x: number; y: number; w: number; h: number }[],\n  ): { x: number; y: number; w: number; h: number }[] {\n    if (boxes.length === 0) return [];\n\n    // Simple approach: create union of all detected face regions\n    const minX = Math.max(0, Math.min(...boxes.map((b) => b.x)) - 20); // Add padding\n    const minY = Math.max(0, Math.min(...boxes.map((b) => b.y)) - 20);\n    const maxX = Math.max(...boxes.map((b) => b.x + b.w)) + 20;\n    const maxY = Math.max(...boxes.map((b) => b.y + b.h)) + 20;\n\n    return [\n      {\n        x: minX,\n        y: minY,\n        w: maxX - minX,\n        h: maxY - minY,\n      },\n    ];\n  }\n\n  private buildBlurFilter(faceBoxes: { x: number; y: number; w: number; h: number }[]): string {\n    if (faceBoxes.length === 0) {\n      // If no faces detected, blur the top half of the video\n      return \"crop=iw:ih/2:0:0,boxblur=luma_radius=30:luma_power=3,pad=iw:2*ih:0:0\";\n    }\n\n    // Create blur filter for detected face regions\n    return (\n      faceBoxes\n        .map((box, index) => {\n          return `crop=${box.w}:${box.h}:${box.x}:${box.y},boxblur=luma_radius=30:luma_power=3[blur${index}]; [0:v][blur${index}]overlay=${box.x}:${box.y}`;\n        })\n        .join(\"; \") + \"[blurred]\"\n    );\n  }\n\n  private async processVideoWithFFmpeg(\n    inputUri: string,\n    blurFilter: string,\n    enableVoiceChange: boolean,\n    voiceEffect: \"deep\" | \"light\",\n    quality: \"high\" | \"medium\" | \"low\" | \"highest\",\n    transcription?: string,\n  ): Promise<string> {\n    const outputUri = `${tmp}processed_${Date.now()}.mp4`;\n    const inputPath = this.stripFileScheme(inputUri);\n    const outputPath = this.stripFileScheme(outputUri);\n\n    // Build video filter chain\n    const filters: string[] = [];\n\n    // Add blur filter if available\n    if (blurFilter) {\n      filters.push(blurFilter);\n    }\n\n    // Add TikTok-style captions if transcription is available\n    if (transcription && transcription.trim()) {\n      // Get video duration for proper timing\n      const duration = await this.getVideoDuration(inputUri);\n      const subtitleFilter = this.buildSubtitleFilter(transcription, duration);\n      if (subtitleFilter) {\n        filters.push(subtitleFilter);\n      }\n    }\n\n    const videoFilter = filters.length > 0 ? filters.join(\",\") : \"null\";\n\n    // Build audio filter for voice change\n    const audioFilter = enableVoiceChange ? this.getVoiceChangeFilter(voiceEffect) : \"anull\";\n\n    // Quality settings\n    const crf = quality === \"high\" ? 18 : quality === \"low\" ? 28 : 23;\n\n    const commandArgs = [\n      \"-y\", // Overwrite output\n      \"-i\",\n      inputPath,\n      \"-vf\",\n      videoFilter,\n      \"-af\",\n      audioFilter,\n      \"-c:v\",\n      \"libx264\",\n      \"-crf\",\n      crf.toString(),\n      \"-preset\",\n      \"fast\",\n      \"-c:a\",\n      \"aac\",\n      \"-b:a\",\n      \"128k\",\n      \"-movflags\",\n      \"+faststart\",\n      outputPath,\n    ];\n\n    await this.runFFmpegCommand(commandArgs);\n    return outputUri;\n  }\n\n  private getVoiceChangeFilter(effect: \"deep\" | \"light\"): string {\n    if (effect === \"deep\") {\n      // Deep voice: Lower pitch, add slight reverb, and formant shifting\n      return \"asetrate=44100*0.85,aresample=44100,atempo=1.18,aecho=0.8:0.88:60:0.4,equalizer=f=100:width_type=h:width=50:g=3\";\n    } else {\n      // Light voice: Slightly higher pitch with subtle formant adjustment\n      return \"asetrate=44100*1.08,aresample=44100,atempo=0.93,equalizer=f=200:width_type=h:width=100:g=2\";\n    }\n  }\n\n  private buildSubtitleFilter(transcription: string, videoDuration?: number): string {\n    // Create TikTok-style captions that appear on the video\n    // Split transcription into chunks for dynamic display\n    const words = transcription.trim().split(/\\s+/);\n    if (words.length === 0) return \"\";\n\n    const wordsPerSegment = Math.min(4, Math.max(2, words.length / 3)); // 2-4 words per segment\n    const segments = [];\n\n    for (let i = 0; i < words.length; i += wordsPerSegment) {\n      segments.push(words.slice(i, i + wordsPerSegment).join(\" \"));\n    }\n\n    if (segments.length === 0) return \"\";\n\n    // Calculate timing - use actual video duration or fallback to 30 seconds\n    const actualDuration = videoDuration && videoDuration > 0 && !isNaN(videoDuration) ? videoDuration : 30;\n    const segmentDuration = Math.max(1.5, actualDuration / segments.length);\n    let currentTime = 0;\n\n    const textFilters = segments.map((segment, index) => {\n      const startTime = currentTime;\n      const endTime = Math.min(currentTime + segmentDuration, actualDuration);\n      currentTime += segmentDuration;\n\n      // Comprehensive escaping for FFmpeg drawtext\n      const escapedText = this.escapeFFmpegText(segment);\n\n      // TikTok-style centered text at bottom with outline\n      return `drawtext=text='${escapedText}':fontsize=28:fontcolor=white:borderw=2:bordercolor=black:x=(w-text_w)/2:y=h-th-80:enable='between(t,${startTime.toFixed(1)},${endTime.toFixed(1)})'`;\n    });\n\n    return textFilters.join(\",\");\n  }\n\n  private async generateTranscription(videoUri: string): Promise<string> {\n    try {\n      // Extract audio for transcription\n      const audioUri = await this.extractAudio(videoUri);\n\n      // Use speech-to-text\n      const transcription = await this.speechToText(audioUri);\n\n      // Clean up audio file\n      await FileSystem.deleteAsync(audioUri, { idempotent: true });\n\n      return transcription;\n    } catch (error) {\n      console.warn(\"Transcription failed:\", error);\n      return \"Transcription not available\";\n    }\n  }\n\n  private async extractAudio(videoUri: string): Promise<string> {\n    const audioUri = `${tmp}audio_${Date.now()}.m4a`;\n    const commandArgs = [\n      \"-y\",\n      \"-i\",\n      this.stripFileScheme(videoUri),\n      \"-vn\", // No video\n      \"-acodec\",\n      \"aac\",\n      \"-b:a\",\n      \"128k\",\n      this.stripFileScheme(audioUri),\n    ];\n\n    await this.runFFmpegCommand(commandArgs);\n    return audioUri;\n  }\n\n  private async speechToText(audioUri: string): Promise<string> {\n    return new Promise<string>((resolve, reject) => {\n      const timeout = setTimeout(() => {\n        Voice.destroy();\n        reject(new Error(\"Speech recognition timeout\"));\n      }, 30000); // 30 second timeout\n\n      Voice.onSpeechResults = (event: any) => {\n        clearTimeout(timeout);\n        const results = event.value || [];\n        resolve(results.join(\" \") || \"No speech detected\");\n        Voice.destroy().then(() => Voice.removeAllListeners());\n      };\n\n      Voice.onSpeechError = (event: any) => {\n        clearTimeout(timeout);\n        console.warn(\"Speech recognition error:\", event);\n        resolve(\"Speech recognition failed\");\n        Voice.destroy().then(() => Voice.removeAllListeners());\n      };\n\n      // Use file-based transcription instead of Voice.start()\n      // Voice.start() is for real-time microphone input, not file processing\n      try {\n        // For file-based transcription, we would typically use a service like:\n        // - Google Cloud Speech-to-Text\n        // - Azure Cognitive Services\n        // - AWS Transcribe\n        // - OpenAI Whisper API\n        clearTimeout(timeout);\n        resolve(\"File-based transcription requires external service integration\");\n      } catch (transcriptionError) {\n        clearTimeout(timeout);\n        resolve(\"Speech recognition not available\");\n      }\n    });\n  }\n\n  private async generateThumbnail(videoUri: string): Promise<string> {\n    try {\n      const { uri } = await VideoThumbnails.getThumbnailAsync(videoUri, {\n        time: 1000, // 1 second\n        quality: 0.8,\n      });\n      return uri;\n    } catch (error) {\n      console.error(\"Thumbnail generation failed:\", error);\n\n      // Fallback: generate with FFmpeg\n      try {\n        const thumbUri = `${tmp}thumb_${Date.now()}.jpg`;\n        const commandArgs = [\n          \"-y\",\n          \"-i\",\n          this.stripFileScheme(videoUri),\n          \"-vf\",\n          \"thumbnail,scale=320:-1\",\n          \"-frames:v\",\n          \"1\",\n          this.stripFileScheme(thumbUri),\n        ];\n\n        await this.runFFmpegCommand(commandArgs);\n        return thumbUri;\n      } catch (ffmpegError) {\n        console.error(\"FFmpeg thumbnail generation also failed:\", ffmpegError);\n        return \"\";\n      }\n    }\n  }\n\n  private async getVideoDuration(videoUri: string): Promise<number> {\n    try {\n      const commandArgs = [\"-i\", this.stripFileScheme(videoUri), \"-hide_banner\"];\n      const session = await FFmpegKit.executeWithArguments(commandArgs);\n      const output = await session.getOutput();\n\n      // Parse duration from FFmpeg output\n      const durationMatch = output?.match(/Duration: (\\d+):(\\d+):([\\d.]+)/);\n      if (durationMatch) {\n        const hours = parseInt(durationMatch[1]);\n        const minutes = parseInt(durationMatch[2]);\n        const seconds = parseFloat(durationMatch[3]);\n        return hours * 3600 + minutes * 60 + seconds;\n      }\n\n      return 30; // Default fallback\n    } catch (error) {\n      console.warn(\"Duration detection failed:\", error);\n      return 30; // Default fallback\n    }\n  }\n\n  private async runFFmpegCommand(args: string[]): Promise<void> {\n    // Validate and sanitize arguments\n    const sanitizedArgs = args.map((arg) => this.sanitizeFFmpegArg(arg));\n\n    const session = await FFmpegKit.executeWithArguments(sanitizedArgs);\n    const returnCode = await session.getReturnCode();\n\n    if (!ReturnCode.isSuccess(returnCode)) {\n      const output = await session.getOutput();\n      const errorOutput = await session.getFailStackTrace();\n      throw new Error(`FFmpeg failed with code ${returnCode}: ${errorOutput || output}`);\n    }\n  }\n\n  private sanitizeFFmpegArg(arg: string): string {\n    // Basic validation and sanitization for FFmpeg arguments\n    if (typeof arg !== \"string\") {\n      throw new Error(\"FFmpeg argument must be a string\");\n    }\n\n    // Reject suspicious characters that could be used for command injection\n    const suspiciousChars = /[;&|`$(){}[\\]<>]/;\n    if (suspiciousChars.test(arg)) {\n      throw new Error(`Invalid characters in FFmpeg argument: ${arg}`);\n    }\n\n    // Fixed regex: Allow safe characters for file paths and filter strings\n    const allowedChars = /^[a-zA-Z0-9._\\-/\\\\:=,'\"()\\s+*?!@#%^&]+$/;\n    if (!allowedChars.test(arg)) {\n      throw new Error(`Unsafe characters in FFmpeg argument: ${arg}`);\n    }\n\n    return arg;\n  }\n\n  private escapeFFmpegText(text: string): string {\n    // Comprehensive escaping for FFmpeg drawtext filter\n    return text\n      .replace(/\\\\/g, \"\\\\\\\\\") // Escape backslashes\n      .replace(/'/g, \"\\\\'\") // Escape single quotes\n      .replace(/\"/g, '\\\\\"') // Escape double quotes\n      .replace(/:/g, \"\\\\:\") // Escape colons\n      .replace(/%/g, \"\\\\%\") // Escape percent signs\n      .replace(/,/g, \"\\\\,\") // Escape commas\n      .replace(/\\[/g, \"\\\\[\") // Escape square brackets\n      .replace(/\\]/g, \"\\\\]\") // Escape square brackets\n      .replace(/\\{/g, \"\\\\{\") // Escape curly brackets\n      .replace(/\\}/g, \"\\\\}\") // Escape curly brackets\n      .replace(/\\(/g, \"\\\\(\") // Escape round brackets\n      .replace(/\\)/g, \"\\\\)\") // Escape round brackets\n      .replace(/;/g, \"\\\\;\") // Escape semicolons\n      .replace(/&/g, \"\\\\&\") // Escape ampersands\n      .replace(/\\?/g, \"\\\\?\") // Escape question marks\n      .replace(/\\n/g, \"\\\\n\") // Replace newlines with literal \\n\n      .replace(/\\r/g, \"\"); // Remove carriage returns\n  }\n\n  private stripFileScheme(uri: string): string {\n    return uri.startsWith(\"file://\") ? uri.replace(\"file://\", \"\") : uri;\n  }\n\n  // Real-time transcription (placeholder for future implementation)\n  async startRealTimeTranscription(): Promise<void> {\n    console.log(\"üéØ Starting real-time transcription (native)\");\n    // TODO: Implement with Camera frame processor + Voice recognition\n  }\n\n  async stopRealTimeTranscription(): Promise<void> {\n    console.log(\"üéØ Stopping real-time transcription (native)\");\n    // TODO: Stop real-time processing\n  }\n}\n\n// Export singleton instance\nexport const nativeAnonymiser: IAnonymiser = new NativeAnonymiserImpl();\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/OptimizedVideoService.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'PreloadConfig' is defined but never used.","line":17,"column":11,"nodeType":null,"messageId":"unusedVar","endLine":17,"endColumn":24}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Optimized Video Service for Enhanced Performance\n * Implements best practices for video streaming with Supabase\n */\n\nimport { supabase } from \"../lib/supabase\";\nimport type { Confession } from \"../types/confession\";\nimport { normalizeConfessions } from \"../utils/confessionNormalizer\";\nimport { VideoDataService } from \"./VideoDataService\";\n\ninterface VideoCache {\n  data: Confession[];\n  timestamp: number;\n  etag?: string;\n}\n\ninterface PreloadConfig {\n  enabled: boolean;\n  batchSize: number;\n  maxConcurrent: number;\n}\n\nclass OptimizedVideoService {\n  private static instance: OptimizedVideoService;\n  private videoCache: Map<string, VideoCache> = new Map();\n  private preloadQueue: Set<string> = new Set();\n  private isPreloading: boolean = false;\n\n  // Performance configurations\n  private readonly CACHE_TTL_MS = 5 * 60 * 1000; // 5 minutes\n  private readonly MAX_CACHE_SIZE = 100;\n  private readonly PRELOAD_BATCH_SIZE = 5;\n  private readonly MAX_CONCURRENT_PRELOADS = 3;\n  private readonly VIDEO_QUALITY_MAPPING = {\n    high: { bitrate: 2500000, resolution: \"1080p\" },\n    medium: { bitrate: 1500000, resolution: \"720p\" },\n    low: { bitrate: 800000, resolution: \"480p\" },\n  };\n\n  private constructor() {\n    this.initializeService();\n  }\n\n  static getInstance(): OptimizedVideoService {\n    if (!OptimizedVideoService.instance) {\n      OptimizedVideoService.instance = new OptimizedVideoService();\n    }\n    return OptimizedVideoService.instance;\n  }\n\n  private async initializeService() {\n    // Setup periodic cache cleanup\n    setInterval(() => this.cleanupCache(), this.CACHE_TTL_MS);\n\n    // Monitor network status for adaptive streaming\n    if (typeof window !== \"undefined\" && \"connection\" in navigator) {\n      (navigator as any).connection?.addEventListener(\"change\", () => {\n        this.handleNetworkChange();\n      });\n    }\n  }\n\n  /**\n   * Fetch videos with intelligent caching and optimization\n   */\n  async fetchOptimizedVideos(\n    limit: number = 20,\n    offset: number = 0,\n    forceRefresh: boolean = false,\n  ): Promise<Confession[]> {\n    const cacheKey = `videos_${limit}_${offset}`;\n\n    // Check cache first\n    if (!forceRefresh) {\n      const cached = this.getCachedVideos(cacheKey);\n      if (cached) {\n        // Trigger background refresh if cache is stale\n        if (this.isCacheStale(cacheKey)) {\n          this.backgroundRefresh(cacheKey, limit, offset);\n        }\n        return cached;\n      }\n    }\n\n    try {\n      // Fetch from database with optimized query\n      const { data, error } = await supabase\n        .from(\"confessions\")\n        .select(\n          `\n          id,\n          type,\n          content,\n          video_uri,\n          video_url,\n          transcription,\n          created_at,\n          is_anonymous,\n          likes,\n          views,\n          user_id,\n          face_blur_applied,\n          voice_change_applied\n        `,\n        )\n        .eq(\"type\", \"video\")\n        .not(\"video_uri\", \"is\", null)\n        .order(\"created_at\", { ascending: false })\n        .range(offset, offset + limit - 1);\n\n      if (error) throw error;\n\n      const normalized = await normalizeConfessions(data || []);\n      const optimized = this.optimizeVideoData(normalized);\n\n      // Cache the results\n      this.setCachedVideos(cacheKey, optimized);\n\n      // Preload next batch\n      this.preloadNextBatch(limit, offset + limit);\n\n      return optimized;\n    } catch (error) {\n      console.error(\"OptimizedVideoService: Failed to fetch videos\", error);\n\n      // Fallback to cache if available\n      const fallback = this.getCachedVideos(cacheKey, true);\n      if (fallback) return fallback;\n\n      // Ultimate fallback to basic service\n      return VideoDataService.fetchVideoConfessions(limit);\n    }\n  }\n\n  /**\n   * Optimize video data for better performance\n   */\n  private optimizeVideoData(videos: Confession[]): Confession[] {\n    return videos.map((video) => ({\n      ...video,\n      // Add CDN optimization hints\n      videoUri: this.optimizeVideoUrl(video.videoUri),\n      // Prepare thumbnail URL if available\n      thumbnailUri: this.generateThumbnailUrl(video.videoUri),\n      // Add quality options\n      qualityOptions: this.getQualityOptions(video.videoUri),\n    }));\n  }\n\n  /**\n   * Optimize video URL for CDN delivery\n   */\n  private optimizeVideoUrl(url: string | null | undefined): string | null {\n    if (!url) return null;\n\n    // Add CDN parameters for optimized delivery\n    const optimizedUrl = new URL(url);\n\n    // Add cache-busting parameter if needed\n    if (!optimizedUrl.searchParams.has(\"v\")) {\n      optimizedUrl.searchParams.set(\"v\", Date.now().toString(36));\n    }\n\n    return optimizedUrl.toString();\n  }\n\n  /**\n   * Generate thumbnail URL from video URL\n   */\n  private generateThumbnailUrl(videoUrl: string | null | undefined): string | null {\n    if (!videoUrl) return null;\n\n    // For Google Cloud Storage videos, generate thumbnail\n    if (videoUrl.includes(\"commondatastorage.googleapis.com\")) {\n      // Use first frame as thumbnail\n      return `${videoUrl}#t=0.1`;\n    }\n\n    return null;\n  }\n\n  /**\n   * Get available quality options for adaptive streaming\n   */\n  private getQualityOptions(videoUrl: string | null | undefined): string[] {\n    if (!videoUrl) return [\"auto\"];\n\n    // Determine available qualities based on network\n    const connection = (navigator as any).connection;\n    if (connection) {\n      const effectiveType = connection.effectiveType;\n      switch (effectiveType) {\n        case \"4g\":\n          return [\"1080p\", \"720p\", \"480p\", \"auto\"];\n        case \"3g\":\n          return [\"720p\", \"480p\", \"auto\"];\n        case \"2g\":\n        case \"slow-2g\":\n          return [\"480p\", \"auto\"];\n        default:\n          return [\"auto\"];\n      }\n    }\n\n    return [\"1080p\", \"720p\", \"480p\", \"auto\"];\n  }\n\n  /**\n   * Preload next batch of videos\n   */\n  private async preloadNextBatch(limit: number, offset: number) {\n    const cacheKey = `videos_${limit}_${offset}`;\n\n    // Skip if already preloaded or currently preloading\n    if (this.preloadQueue.has(cacheKey) || this.isPreloading) return;\n\n    this.preloadQueue.add(cacheKey);\n    this.isPreloading = true;\n\n    try {\n      // Fetch next batch in background\n      setTimeout(async () => {\n        await this.fetchOptimizedVideos(limit, offset, false);\n        this.preloadQueue.delete(cacheKey);\n        this.isPreloading = false;\n      }, 1000); // Delay to prevent blocking main thread\n    } catch (error) {\n      console.warn(\"Preload failed:\", error);\n      this.preloadQueue.delete(cacheKey);\n      this.isPreloading = false;\n    }\n  }\n\n  /**\n   * Background refresh for stale cache\n   */\n  private async backgroundRefresh(cacheKey: string, limit: number, offset: number) {\n    try {\n      const fresh = await this.fetchOptimizedVideos(limit, offset, true);\n      this.setCachedVideos(cacheKey, fresh);\n    } catch (error) {\n      console.warn(\"Background refresh failed:\", error);\n    }\n  }\n\n  /**\n   * Handle network changes for adaptive streaming\n   */\n  private handleNetworkChange() {\n    const connection = (navigator as any).connection;\n    if (connection) {\n      console.log(\"Network changed:\", {\n        effectiveType: connection.effectiveType,\n        downlink: connection.downlink,\n        rtt: connection.rtt,\n      });\n\n      // Clear cache to force quality adjustment\n      if (connection.effectiveType === \"slow-2g\" || connection.effectiveType === \"2g\") {\n        this.videoCache.clear();\n      }\n    }\n  }\n\n  /**\n   * Cache management methods\n   */\n  private getCachedVideos(key: string, includeStale: boolean = false): Confession[] | null {\n    const cached = this.videoCache.get(key);\n    if (!cached) return null;\n\n    const age = Date.now() - cached.timestamp;\n    if (age > this.CACHE_TTL_MS && !includeStale) return null;\n\n    return [...cached.data]; // Return copy to prevent mutations\n  }\n\n  private setCachedVideos(key: string, videos: Confession[]) {\n    // Limit cache size\n    if (this.videoCache.size >= this.MAX_CACHE_SIZE) {\n      const oldestKey = this.videoCache.keys().next().value;\n      if (typeof oldestKey === \"string\") {\n        this.videoCache.delete(oldestKey);\n      }\n    }\n\n    this.videoCache.set(key, {\n      data: videos,\n      timestamp: Date.now(),\n      etag: this.generateEtag(videos),\n    });\n  }\n\n  private isCacheStale(key: string): boolean {\n    const cached = this.videoCache.get(key);\n    if (!cached) return true;\n\n    const age = Date.now() - cached.timestamp;\n    return age > this.CACHE_TTL_MS / 2; // Consider stale at half TTL\n  }\n\n  private cleanupCache() {\n    const now = Date.now();\n    for (const [key, value] of this.videoCache.entries()) {\n      if (now - value.timestamp > this.CACHE_TTL_MS * 2) {\n        this.videoCache.delete(key);\n      }\n    }\n  }\n\n  private generateEtag(videos: Confession[]): string {\n    const content = videos.map((v) => v.id).join(\",\");\n    return btoa(content).substring(0, 16);\n  }\n\n  /**\n   * Prefetch video content for smoother playback\n   */\n  async prefetchVideo(videoUrl: string): Promise<void> {\n    if (!videoUrl || typeof window === \"undefined\") return;\n\n    try {\n      // Create a video element to start preloading\n      const video = document.createElement(\"video\");\n      video.preload = \"auto\";\n      video.src = videoUrl;\n      video.muted = true;\n\n      // Start loading\n      video.load();\n\n      // Clean up after a delay\n      setTimeout(() => {\n        video.src = \"\";\n        video.remove();\n      }, 30000); // 30 seconds\n    } catch (error) {\n      console.warn(\"Video prefetch failed:\", error);\n    }\n  }\n\n  /**\n   * Get video analytics for optimization\n   */\n  async getVideoAnalytics(videoId: string): Promise<any> {\n    try {\n      const { data, error } = await supabase.from(\"video_analytics\").select(\"*\").eq(\"video_id\", videoId).single();\n\n      if (error) throw error;\n      return data;\n    } catch (error) {\n      console.warn(\"Failed to get video analytics:\", error);\n      return null;\n    }\n  }\n\n  /**\n   * Track video performance metrics\n   */\n  async trackVideoMetrics(\n    videoId: string,\n    metrics: {\n      loadTime?: number;\n      bufferCount?: number;\n      watchTime?: number;\n      completionRate?: number;\n    },\n  ): Promise<void> {\n    try {\n      // Queue metrics for batch processing\n      if (__DEV__) {\n        console.log(\"Video metrics:\", { videoId, ...metrics });\n      }\n\n      // In production, send to analytics service\n      // await supabase.rpc('track_video_metrics', { video_id: videoId, ...metrics });\n    } catch (error) {\n      console.warn(\"Failed to track video metrics:\", error);\n    }\n  }\n}\n\nexport default OptimizedVideoService.getInstance();\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/RevenueCatService.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'_CustomerInfo' is assigned a value but never used.","line":86,"column":5,"nodeType":null,"messageId":"unusedVar","endLine":86,"endColumn":18},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'_PurchasesOffering' is assigned a value but never used.","line":87,"column":5,"nodeType":null,"messageId":"unusedVar","endLine":87,"endColumn":23},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'_PurchasesPackage' is assigned a value but never used.","line":88,"column":5,"nodeType":null,"messageId":"unusedVar","endLine":88,"endColumn":22}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import Constants from \"expo-constants\";\nimport { supabase } from \"../lib/supabase\";\nimport { getConfig } from \"../config/production\";\nimport { withSupabaseConfig } from \"../lib/supabase\";\nimport { withSupabaseRetry } from \"../lib/supabase\";\n\n// Type definitions for RevenueCat\ninterface RevenueCatCustomerInfo {\n  activeSubscriptions: string[];\n  entitlements: {\n    active: Record<string, any>;\n  };\n  allPurchasedProductIdentifiers: string[];\n  latestExpirationDate: string | null;\n  originalAppUserId: string;\n  requestDate: string;\n}\n\ninterface RevenueCatOfferings {\n  current: RevenueCatOffering | null;\n  all: Record<string, RevenueCatOffering>;\n}\n\ninterface RevenueCatOffering {\n  identifier: string;\n  serverDescription: string;\n  metadata: Record<string, any>;\n  packages: RevenueCatPackage[];\n}\n\ninterface RevenueCatPackage {\n  identifier: string;\n  packageType: string;\n  product: RevenueCatProduct;\n  offeringIdentifier: string;\n}\n\ninterface RevenueCatProduct {\n  identifier: string;\n  description: string;\n  title: string;\n  price: number;\n  priceString: string;\n  currencyCode: string;\n  introPrice: RevenueCatProductPrice | null;\n}\n\ninterface RevenueCatProductPrice {\n  price: number;\n  priceString: string;\n  currencyCode: string;\n  period: string;\n  periodUnit: string;\n  cycles: number;\n}\n\ntype RevenueCatPurchaseResult = {\n  customerInfo: RevenueCatCustomerInfo;\n  productIdentifier: string;\n};\n\ntype MockPurchaseResult = {\n  mockCustomerInfo: boolean;\n};\n\ntype RevenueCatCustomerResult = RevenueCatCustomerInfo | MockPurchaseResult | null;\n\n// Check if running in Expo Go\nconst IS_EXPO_GO = Constants.appOwnership === \"expo\";\nconst config = getConfig();\n\n// RevenueCat API Key from configuration\nconst REVENUECAT_API_KEY = config.REVENUECAT.API_KEY;\n\n// Lazy load RevenueCat to prevent Expo Go crashes\nlet Purchases: {\n  configure: (config: { apiKey: string; appUserID: string | null }) => Promise<void>;\n  setLogLevel: (level: string) => Promise<void>;\n  getOfferings: () => Promise<RevenueCatOfferings>;\n  purchasePackage: (pkg: RevenueCatPackage) => Promise<RevenueCatPurchaseResult>;\n  restorePurchases: () => Promise<RevenueCatCustomerInfo>;\n  logIn: (userID: string) => Promise<void>;\n  getCustomerInfo: () => Promise<RevenueCatCustomerInfo>;\n} | null = null;\n\nlet _CustomerInfo: any = null;\nlet _PurchasesOffering: any = null;\nlet _PurchasesPackage: any = null;\n\nconst loadRevenueCat = async () => {\n  if (!Purchases && !IS_EXPO_GO) {\n    try {\n      const RevenueCatModule = await import(\"react-native-purchases\");\n      Purchases = RevenueCatModule.default as any;\n      // Types are exported separately in v9+\n      _CustomerInfo = {} as any;\n      _PurchasesOffering = {} as any;\n      _PurchasesPackage = {} as any;\n      if (__DEV__) {\n        console.log(\"üöÄ RevenueCat module loaded successfully\");\n      }\n    } catch (error) {\n      if (__DEV__) {\n        console.warn(\"RevenueCat not available, running in demo mode:\", (error as Error)?.message || String(error));\n        console.log(\"üéØ RevenueCat demo mode - react-native-purchases not installed\");\n      }\n    }\n  }\n};\n\nexport interface SubscriptionTier {\n  id: string;\n  name: string;\n  price: string;\n  features: string[];\n  isPopular?: boolean;\n}\n\nexport class RevenueCatService {\n  private static isInitialized = false;\n\n  private static sleep(ms: number) {\n    return new Promise((r) => setTimeout(r, ms));\n  }\n\n  // Retry wrapper for purchases to handle transient failures\n  private static async purchaseWithRetry(\n    pkg: RevenueCatPackage,\n    attempts = 3,\n    baseDelay = 500,\n  ): Promise<RevenueCatPurchaseResult | undefined> {\n    for (let i = 0; i < attempts; i++) {\n      try {\n        // Add null check for Purchases\n        if (!Purchases) {\n          throw new Error(\"RevenueCat Purchases not initialized\");\n        }\n        return await Purchases.purchasePackage(pkg);\n      } catch (e: any) {\n        const msg = (e?.message || \"\").toLowerCase();\n        const userCanceled = msg.includes(\"cancel\");\n        const retryable = !userCanceled && (msg.includes(\"network\") || msg.includes(\"timeout\") || e?.code === 503);\n        if (!retryable || i === attempts - 1) throw e;\n        await RevenueCatService.sleep(baseDelay * Math.pow(2, i));\n      }\n    }\n    return undefined;\n  }\n\n  static async initialize(): Promise<void> {\n    if (this.isInitialized) return;\n\n    if (IS_EXPO_GO) {\n      console.log(\"üéØ RevenueCat Demo Mode - Development build required for real subscriptions\");\n      this.isInitialized = true;\n      return;\n    }\n\n    try {\n      // Runtime guard for API key to prevent null-key initialization\n      if (!REVENUECAT_API_KEY) {\n        console.warn(\"RevenueCat API key missing/invalid; skipping Purchases.configure (demo mode)\");\n        this.isInitialized = true;\n        return;\n      }\n      await loadRevenueCat();\n\n      if (!Purchases) {\n        if (__DEV__) {\n          console.log(\"üéØ RevenueCat not available, running in demo mode\");\n        }\n        this.isInitialized = true;\n        return;\n      }\n\n      // Configure RevenueCat\n      await Purchases.configure({\n        apiKey: REVENUECAT_API_KEY,\n        appUserID: null, // Will be set when user logs in\n      });\n\n      // Set debug logs in development\n      if (__DEV__) {\n        await Purchases.setLogLevel(\"DEBUG\");\n      }\n\n      if (__DEV__) {\n        console.log(\"üöÄ RevenueCat initialized for development build\");\n      }\n      this.isInitialized = true;\n    } catch (error) {\n      if (__DEV__) {\n        console.warn(\n          \"RevenueCat initialization failed, running in demo mode:\",\n          (error as any)?.message || String(error),\n        );\n      }\n      this.isInitialized = true;\n    }\n  }\n\n  static async getOfferings(): Promise<RevenueCatOfferings | null> {\n    await this.initialize();\n\n    if (IS_EXPO_GO) {\n      console.log(\"üéØ Demo: Getting mock offerings\");\n      return null; // Demo mode\n    }\n\n    try {\n      if (!Purchases) {\n        throw new Error(\"RevenueCat not initialized\");\n      }\n\n      const offerings = await Purchases.getOfferings();\n      console.log(\"üöÄ Retrieved RevenueCat offerings:\", offerings);\n      return offerings;\n    } catch (error) {\n      console.error(\"Failed to get offerings:\", error);\n      return null;\n    }\n  }\n\n  static async purchasePackage(\n    packageToPurchase: RevenueCatPackage,\n  ): Promise<RevenueCatPurchaseResult | MockPurchaseResult> {\n    await this.initialize();\n\n    if (IS_EXPO_GO) {\n      if (__DEV__) {\n        console.log(\"üéØ Demo: Simulating purchase...\");\n      }\n      return new Promise((resolve) => {\n        setTimeout(() => {\n          if (__DEV__) {\n            console.log(\"‚úÖ Demo purchase completed successfully!\");\n          }\n          resolve({ mockCustomerInfo: true });\n        }, 2000);\n      });\n    }\n\n    try {\n      if (!Purchases) {\n        throw new Error(\"RevenueCat not initialized\");\n      }\n\n      if (__DEV__) {\n        console.log(\"üöÄ Purchasing package:\", packageToPurchase);\n      }\n      const result = await this.purchaseWithRetry(packageToPurchase);\n      // Handle undefined result\n      if (!result) {\n        throw new Error(\"Purchase result is undefined\");\n      }\n      const customerInfo = result.customerInfo;\n      const productIdentifier = result.productIdentifier;\n\n      if (__DEV__) {\n        console.log(\"‚úÖ Purchase completed successfully!\", { customerInfo, productIdentifier });\n      }\n\n      // Update subscription status in Supabase\n      if (customerInfo) {\n        await this.syncSubscriptionStatus(customerInfo);\n      }\n\n      return {\n        customerInfo: customerInfo || ({} as RevenueCatCustomerInfo),\n        productIdentifier: productIdentifier || \"\",\n      };\n    } catch (error) {\n      if (__DEV__) {\n        console.error(\"Purchase failed:\", error);\n      }\n      throw error;\n    }\n  }\n\n  static async restorePurchases(): Promise<RevenueCatCustomerInfo | MockPurchaseResult> {\n    await this.initialize();\n\n    if (IS_EXPO_GO) {\n      console.log(\"üéØ Demo: Simulating restore purchases...\");\n      return new Promise((resolve) => {\n        setTimeout(() => {\n          console.log(\"‚úÖ Demo restore completed!\");\n          resolve({ mockCustomerInfo: true });\n        }, 1500);\n      });\n    }\n\n    try {\n      if (!Purchases) {\n        throw new Error(\"RevenueCat not initialized\");\n      }\n\n      console.log(\"üöÄ Restoring purchases...\");\n      const customerInfo = await Purchases.restorePurchases();\n\n      console.log(\"‚úÖ Restore completed!\", customerInfo);\n\n      // Update subscription status in Supabase\n      await this.syncSubscriptionStatus(customerInfo);\n\n      return customerInfo;\n    } catch (error) {\n      console.error(\"Restore failed:\", error);\n      throw error;\n    }\n  }\n\n  // Sync subscription status with Supabase\n  private static async syncSubscriptionStatus(customerInfo: RevenueCatCustomerInfo): Promise<void> {\n    try {\n      const {\n        data: { user },\n      } = await supabase.auth.getUser();\n      if (!user) return;\n\n      const activeSubscriptions = customerInfo.activeSubscriptions || [];\n      const isPremium = activeSubscriptions.length > 0;\n\n      // Update user subscription status in Supabase with offline queue support\n      const { enqueue, isOnline } = await import(\"../lib/offlineQueue\");\n      const doUpsert = async () => {\n        const { error } = await withSupabaseRetry(async () =>\n          supabase.from(\"user_memberships\").upsert({\n            user_id: user.id,\n            tier: isPremium ? \"plus\" : \"free\",\n            created_at: new Date().toISOString(),\n            updated_at: new Date().toISOString(),\n          }),\n        );\n        if (error) throw error;\n      };\n\n      if (!isOnline()) {\n        enqueue(\"subscription.sync\", {\n          userId: user.id,\n          isPremium,\n          activeSubscriptions,\n          customerInfo,\n        });\n        console.log(\"üì¶ Queued subscription sync (offline)\");\n        return;\n      }\n\n      try {\n        // Fix withSupabaseConfig usage - it should wrap the operation\n        await withSupabaseConfig(() => doUpsert());\n        console.log(\"‚úÖ Subscription status synced with Supabase\");\n      } catch (e: any) {\n        const msg = (e?.message || \"\").toLowerCase();\n        if (/network|timeout|fetch|503|429/.test(msg)) {\n          enqueue(\"subscription.sync\", {\n            userId: user.id,\n            isPremium,\n            activeSubscriptions,\n            customerInfo,\n          });\n          console.log(\"üì¶ Queued subscription sync after network error\");\n        } else {\n          throw e;\n        }\n      }\n    } catch (error) {\n      console.error(\"Failed to sync subscription status:\", error);\n    }\n  }\n\n  // Set user ID for RevenueCat\n  static async setUserID(userID: string): Promise<void> {\n    if (IS_EXPO_GO || !Purchases) return;\n\n    try {\n      await Purchases.logIn(userID);\n      console.log(\"‚úÖ RevenueCat user ID set:\", userID);\n    } catch (error) {\n      console.error(\"Failed to set RevenueCat user ID:\", error);\n    }\n  }\n\n  // Get customer info\n  static async getCustomerInfo(): Promise<RevenueCatCustomerResult> {\n    await this.initialize();\n\n    if (IS_EXPO_GO) {\n      return { mockCustomerInfo: true };\n    }\n\n    try {\n      if (!Purchases) {\n        throw new Error(\"RevenueCat not initialized\");\n      }\n\n      const customerInfo = await Purchases.getCustomerInfo();\n      return customerInfo;\n    } catch (error) {\n      console.error(\"Failed to get customer info:\", error);\n      return null;\n    }\n  }\n\n  // Check if user has premium subscription\n  static async isUserPremium(): Promise<boolean> {\n    if (IS_EXPO_GO) {\n      console.log(\"üéØ Demo: Checking premium status (always free in demo)\");\n      return false; // Always free in demo mode\n    }\n\n    try {\n      const customerInfo = await this.getCustomerInfo();\n      if (!customerInfo || \"mockCustomerInfo\" in customerInfo) {\n        return false;\n      }\n\n      // Check for active entitlements\n      const activeEntitlements = customerInfo.entitlements?.active || {};\n      const hasActiveEntitlement = Object.keys(activeEntitlements).length > 0;\n\n      // Also check active subscriptions as fallback\n      const activeSubscriptions = customerInfo.activeSubscriptions || [];\n      const hasActiveSubscription = activeSubscriptions.length > 0;\n\n      return hasActiveEntitlement || hasActiveSubscription;\n    } catch (error) {\n      console.error(\"Failed to check premium status:\", error);\n      return false; // Default to free on error\n    }\n  }\n\n  // Mock offerings for development\n  static getMockOfferings(): SubscriptionTier[] {\n    return [\n      {\n        id: \"monthly\",\n        name: \"Premium Monthly\",\n        price: \"$4.99/month\",\n        features: [\"No ads\", \"Unlimited video recordings\", \"Advanced voice effects\", \"Priority support\"],\n      },\n      {\n        id: \"annual\",\n        name: \"Premium Annual\",\n        price: \"$39.99/year\",\n        features: [\"No ads\", \"Unlimited video recordings\", \"Advanced voice effects\", \"Priority support\", \"Save 33%\"],\n        isPopular: true,\n      },\n    ];\n  }\n\n  // Unified access for subscription tiers in all envs\n  static async getSubscriptionTiers(): Promise<SubscriptionTier[] | null> {\n    if (IS_EXPO_GO) {\n      return this.getMockOfferings();\n    }\n    try {\n      const offerings = await this.getOfferings();\n      if (!offerings || !offerings.current) return null;\n      const pkgs = offerings.current.packages || [];\n      const tiers: SubscriptionTier[] = pkgs.map((p) => ({\n        id: p.identifier,\n        name: p.product?.title || p.identifier,\n        price: p.product?.priceString || \"\",\n        features: [],\n      }));\n      return tiers.length ? tiers : null;\n    } catch (e) {\n      if (__DEV__) console.warn(\"getSubscriptionTiers failed:\", e);\n      return null;\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/ServiceInitializer.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'firebaseError' is defined but never used.","line":244,"column":18,"nodeType":null,"messageId":"unusedVar","endLine":244,"endColumn":31},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'sentryError' is defined but never used.","line":273,"column":18,"nodeType":null,"messageId":"unusedVar","endLine":273,"endColumn":29},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'firebaseError' is defined but never used.","line":286,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":286,"endColumn":29}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Service Initializer\n * Coordinates initialization of all production services\n */\n\nimport Constants from \"expo-constants\";\nimport { getConfig, validateProductionConfig, isFeatureEnabled } from \"../config/production\";\nimport { validateAdMobConfig, validateRevenueCatConfig } from \"../utils/environmentValidation\";\nimport { AdMobService } from \"./AdMobService\";\nimport { RevenueCatService } from \"./RevenueCatService\";\nimport { getAnonymiser } from \"./Anonymiser\";\nimport { initializeConsent } from \"../state/consentStore\";\n\nconst IS_EXPO_GO = Constants.appOwnership === \"expo\";\nconst config = getConfig();\n\nexport interface ServiceInitializationOptions {\n  strictConfigValidation?: boolean;\n}\n\nexport interface ServiceInitializationResult {\n  success: boolean;\n  errors: string[];\n  warnings: string[];\n  initializedServices: string[];\n}\n\nexport class ServiceInitializer {\n  private static isInitialized = false;\n  private static initializationResult: ServiceInitializationResult | null = null;\n\n  static async initializeAllServices(options: ServiceInitializationOptions = {}): Promise<ServiceInitializationResult> {\n    if (this.isInitialized && this.initializationResult) {\n      return this.initializationResult;\n    }\n\n    const result: ServiceInitializationResult = {\n      success: true,\n      errors: [],\n      warnings: [],\n      initializedServices: [],\n    };\n\n    console.log(\"üöÄ Starting service initialization...\");\n\n    // Validate production configuration\n    const { strictConfigValidation = false } = options;\n    const configValidation = validateProductionConfig();\n\n    if (!configValidation.isValid && (!__DEV__ || strictConfigValidation)) {\n      result.errors.push(`Missing production configuration: ${configValidation.missingKeys.join(\", \")}`);\n      result.success = false;\n    } else if (!configValidation.isValid) {\n      result.warnings.push(`Development mode: Missing production keys: ${configValidation.missingKeys.join(\", \")}`);\n    }\n\n    // Additional runtime validations for AdMob and RevenueCat\n    let adMobRes: ReturnType<typeof validateAdMobConfig> | null = null;\n    let revCatRes: ReturnType<typeof validateRevenueCatConfig> | null = null;\n    try {\n      adMobRes = validateAdMobConfig();\n      revCatRes = validateRevenueCatConfig();\n      const pushIssues = (prefix: string, res: ReturnType<typeof validateAdMobConfig>) => {\n        for (const issue of res.issues) {\n          const msg = `${prefix}: [${issue.severity}] ${issue.key} - ${issue.message}`;\n          if (!__DEV__ || strictConfigValidation) {\n            // Treat high/critical as errors in production/strict mode\n            if (issue.severity === \"critical\" || issue.severity === \"high\") result.errors.push(msg);\n            else result.warnings.push(msg);\n          } else {\n            result.warnings.push(msg);\n          }\n        }\n      };\n      pushIssues(\"AdMob config\", adMobRes);\n      pushIssues(\"RevenueCat config\", revCatRes);\n    } catch (e) {\n      if (__DEV__) console.warn(\"Validation checks failed:\", e);\n    }\n\n    // Initialize consent system first\n    try {\n      await initializeConsent();\n      result.initializedServices.push(\"Consent Management\");\n      console.log(\"‚úÖ Consent system initialized\");\n    } catch (error) {\n      const errorMsg = `Consent initialization failed: ${error instanceof Error ? error.message : \"Unknown error\"}`;\n      result.errors.push(errorMsg);\n      console.error(\"‚ùå\", errorMsg);\n    }\n\n    // Initialize AdMob (gated behind ENABLE_ADS) and skip on critical validation errors\n    if (isFeatureEnabled(\"ENABLE_ADS\")) {\n      const adMobHasCritical = adMobRes?.issues?.some((i) => i.severity === \"critical\");\n      if (adMobHasCritical) {\n        const msg = \"AdMob initialization skipped due to critical configuration errors\";\n        result.warnings.push(msg);\n        console.warn(`‚ö†Ô∏è ${msg}`);\n      } else {\n        try {\n          await AdMobService.initialize();\n          result.initializedServices.push(\"AdMob\");\n          if (__DEV__) {\n            console.log(\"‚úÖ AdMob initialized\");\n          }\n        } catch (error) {\n          const errorMsg = `AdMob initialization failed: ${error instanceof Error ? error.message : \"Unknown error\"}`;\n          if (IS_EXPO_GO) {\n            result.warnings.push(errorMsg);\n          } else {\n            result.errors.push(errorMsg);\n          }\n          if (__DEV__) {\n            console.error(\"‚ùå\", errorMsg);\n          }\n        }\n      }\n    }\n\n    // Initialize RevenueCat (skip on critical validation errors)\n    const revHasCritical = revCatRes?.issues?.some((i) => i.severity === \"critical\");\n    if (revHasCritical) {\n      const msg = \"RevenueCat initialization skipped due to critical configuration errors\";\n      result.warnings.push(msg);\n      console.warn(`‚ö†Ô∏è ${msg}`);\n    } else {\n      try {\n        await RevenueCatService.initialize();\n        result.initializedServices.push(\"RevenueCat\");\n        console.log(\"‚úÖ RevenueCat initialized\");\n        // Restore purchases on launch (no-op in Expo Go per service implementation)\n        try {\n          await RevenueCatService.restorePurchases();\n          console.log(\"‚úÖ RevenueCat purchases restored on launch\");\n        } catch (e) {\n          console.warn(\"RevenueCat restore on launch failed:\", e);\n        }\n      } catch (error) {\n        const errorMsg = `RevenueCat initialization failed: ${error instanceof Error ? error.message : \"Unknown error\"}`;\n        if (IS_EXPO_GO) {\n          result.warnings.push(errorMsg);\n        } else {\n          result.errors.push(errorMsg);\n        }\n        console.error(\"‚ùå\", errorMsg);\n      }\n    }\n\n    // Initialize Video Processing\n    if (isFeatureEnabled(\"ENABLE_ADVANCED_VIDEO_PROCESSING\")) {\n      try {\n        const anonymiser = await getAnonymiser();\n        await anonymiser.initialize();\n        result.initializedServices.push(\"Video Processing\");\n        console.log(\"‚úÖ Video processing initialized\");\n      } catch (error) {\n        const errorMsg = `Video processing initialization failed: ${error instanceof Error ? error.message : \"Unknown error\"}`;\n        if (IS_EXPO_GO) {\n          result.warnings.push(errorMsg);\n        } else {\n          result.errors.push(errorMsg);\n        }\n        console.error(\"‚ùå\", errorMsg);\n      }\n    }\n\n    // Initialize Analytics (if enabled)\n    if (isFeatureEnabled(\"ENABLE_ANALYTICS\")) {\n      try {\n        await this.initializeAnalytics();\n        result.initializedServices.push(\"Analytics\");\n        console.log(\"‚úÖ Analytics initialized\");\n      } catch (error) {\n        const errorMsg = `Analytics initialization failed: ${error instanceof Error ? error.message : \"Unknown error\"}`;\n        result.warnings.push(errorMsg);\n        console.warn(\"‚ö†Ô∏è\", errorMsg);\n      }\n    }\n\n    // Initialize Crash Reporting (if enabled)\n    if (isFeatureEnabled(\"ENABLE_CRASH_REPORTING\")) {\n      try {\n        await this.initializeCrashReporting();\n        result.initializedServices.push(\"Crash Reporting\");\n        console.log(\"‚úÖ Crash reporting initialized\");\n      } catch (error) {\n        const errorMsg = `Crash reporting initialization failed: ${error instanceof Error ? error.message : \"Unknown error\"}`;\n        result.warnings.push(errorMsg);\n        console.warn(\"‚ö†Ô∏è\", errorMsg);\n      }\n    }\n\n    // Initialize Push Notifications (if enabled)\n    if (isFeatureEnabled(\"ENABLE_PUSH_NOTIFICATIONS\")) {\n      try {\n        await this.initializePushNotifications();\n        result.initializedServices.push(\"Push Notifications\");\n        if (__DEV__) {\n          console.log(\"‚úÖ Push notifications initialized\");\n        }\n      } catch (error) {\n        const errorMsg = `Push notifications initialization failed: ${error instanceof Error ? error.message : \"Unknown error\"}`;\n        result.warnings.push(errorMsg);\n        if (__DEV__) {\n          console.warn(\"‚ö†Ô∏è\", errorMsg);\n        }\n      }\n    }\n\n    this.isInitialized = true;\n    this.initializationResult = result;\n\n    // Log summary\n    if (__DEV__) {\n      console.log(\"üéØ Service initialization complete:\");\n      console.log(`‚úÖ Initialized: ${result.initializedServices.join(\", \")}`);\n      if (result.warnings.length > 0) {\n        console.log(`‚ö†Ô∏è Warnings: ${result.warnings.length}`);\n      }\n    }\n    if (result.errors.length > 0) {\n      console.log(`‚ùå Errors: ${result.errors.length}`);\n      result.success = false;\n    }\n\n    return result;\n  }\n\n  private static async initializeAnalytics(): Promise<void> {\n    if (IS_EXPO_GO) {\n      console.log(\"üéØ Analytics demo mode (Expo Go)\");\n      return;\n    }\n\n    try {\n      // Initialize Firebase Analytics if configured and available\n      if (config.ANALYTICS.FIREBASE_CONFIG) {\n        try {\n          // Dynamic import with error handling for missing package\n          const analyticsModule = await import(\"@react-native-firebase/analytics\");\n          const analytics = analyticsModule.default;\n          await analytics().setAnalyticsCollectionEnabled(true);\n          console.log(\"üöÄ Firebase Analytics initialized\");\n        } catch (firebaseError) {\n          console.log(\"üìä Firebase Analytics not available, skipping\");\n        }\n      }\n\n      // Initialize other analytics services as needed\n      console.log(\"üöÄ Analytics services initialized\");\n    } catch (error) {\n      console.warn(\"Analytics initialization failed, continuing without analytics:\", error);\n    }\n  }\n\n  private static async initializeCrashReporting(): Promise<void> {\n    if (IS_EXPO_GO) {\n      console.log(\"üéØ Crash reporting demo mode (Expo Go)\");\n      return;\n    }\n\n    try {\n      // Initialize Sentry if configured and available\n      if (config.SENTRY.DSN && config.SENTRY.ENVIRONMENT) {\n        try {\n          const Sentry = await import(\"@sentry/react-native\");\n          Sentry.init({\n            dsn: config.SENTRY.DSN,\n            environment: config.SENTRY.ENVIRONMENT,\n            debug: config.SENTRY.DEBUG,\n          });\n          console.log(\"üöÄ Sentry crash reporting initialized\");\n        } catch (sentryError) {\n          console.log(\"üìä Sentry not available, skipping crash reporting\");\n        }\n      } else {\n        console.log(\"üìä Sentry configuration incomplete, skipping crash reporting\");\n      }\n\n      // Initialize Firebase Crashlytics if available\n      try {\n        const crashlyticsModule = await import(\"@react-native-firebase/crashlytics\");\n        const crashlytics = crashlyticsModule.default;\n        await crashlytics().setCrashlyticsCollectionEnabled(true);\n        console.log(\"üöÄ Firebase Crashlytics initialized\");\n      } catch (firebaseError) {\n        console.log(\"üìä Firebase Crashlytics not available, skipping\");\n      }\n    } catch (error) {\n      console.warn(\"Crash reporting initialization failed:\", error);\n      // Don't throw error - continue without crash reporting\n    }\n  }\n\n  private static async initializePushNotifications(): Promise<void> {\n    if (IS_EXPO_GO) {\n      console.log(\"üéØ Push notifications demo mode (Expo Go)\");\n      return;\n    }\n\n    try {\n      // Initialize push notification service if available\n      const pushModule = await import(\"../utils/pushNotifications\");\n      const pushNotificationManager = pushModule.pushNotificationManager;\n      await (pushNotificationManager as any)?.initialize?.();\n      console.log(\"üöÄ Push notifications initialized\");\n    } catch (error) {\n      console.warn(\"Push notifications initialization failed:\", error);\n      // Don't throw error - continue without push notifications\n    }\n  }\n\n  // Get initialization status\n  static getInitializationResult(): ServiceInitializationResult | null {\n    return this.initializationResult;\n  }\n\n  // Check if a specific service was initialized successfully\n  static isServiceInitialized(serviceName: string): boolean {\n    return this.initializationResult?.initializedServices.includes(serviceName) || false;\n  }\n\n  // Reinitialize services (useful for testing or after configuration changes)\n  static async reinitialize(): Promise<ServiceInitializationResult> {\n    this.isInitialized = false;\n    this.initializationResult = null;\n    return this.initializeAllServices();\n  }\n}\n\n// Export convenience function\nexport const initializeServices = () => ServiceInitializer.initializeAllServices();\nexport const getServiceStatus = () => ServiceInitializer.getInitializationResult();\nexport const isServiceReady = (serviceName: string) => ServiceInitializer.isServiceInitialized(serviceName);\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/SmartVideoPreloader.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'Device' is defined but never used.","line":2,"column":13,"nodeType":null,"messageId":"unusedVar","endLine":2,"endColumn":19},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'NetworkQualityTier' is defined but never used.","line":3,"column":57,"nodeType":null,"messageId":"unusedVar","endLine":3,"endColumn":75},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'environmentDetector' is defined but never used.","line":5,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":5,"endColumn":29}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import NetInfo from \"@react-native-community/netinfo\";\nimport * as Device from \"expo-device\";\nimport { videoPerformanceConfig, DevicePerformanceTier, NetworkQualityTier } from \"../config/videoPerformance\";\nimport { videoCacheManager } from \"../utils/videoCacheManager\";\nimport { environmentDetector } from \"../utils/environmentDetector\";\n\ninterface PreloadContext {\n  networkType: string;\n  networkSpeed: number;\n  deviceTier: DevicePerformanceTier;\n  batteryLevel: number;\n  memoryPressure: boolean;\n  userBehavior: UserBehaviorPattern;\n  contentType: \"feed\" | \"profile\" | \"search\";\n}\n\ninterface UserBehaviorPattern {\n  averageWatchTime: number;\n  skipRate: number;\n  interactionRate: number;\n  preferredContentTypes: string[];\n  timeOfDay: number;\n  dayOfWeek: number;\n}\n\ninterface PreloadDecision {\n  shouldPreload: boolean;\n  priority: \"high\" | \"normal\" | \"low\";\n  quality: \"high\" | \"medium\" | \"low\";\n  count: number;\n  strategy: \"aggressive\" | \"conservative\" | \"predictive\";\n}\n\nclass SmartVideoPreloader {\n  private preloadQueue: Map<string, PreloadJob> = new Map();\n  private activePreloads: Set<string> = new Set();\n  private contextHistory: PreloadContext[] = [];\n  private maxConcurrentPreloads = 3;\n\n  constructor() {\n    this.initializeContextMonitoring();\n  }\n\n  private initializeContextMonitoring() {\n    // Monitor network changes\n    NetInfo.addEventListener((state) => {\n      this.updateNetworkContext(state);\n    });\n\n    // Monitor device performance\n    this.startPerformanceMonitoring();\n  }\n\n  private updateNetworkContext(state: any) {\n    const context: Partial<PreloadContext> = {\n      networkType: state.type,\n      networkSpeed: this.estimateNetworkSpeed(state),\n    };\n    this.updateContext(context);\n  }\n\n  private estimateNetworkSpeed(state: any): number {\n    // Estimate speed based on connection type\n    switch (state.type) {\n      case \"wifi\":\n        return 50; // Mbps\n      case \"cellular\":\n        if (state.details?.cellularGeneration === \"5g\") return 100;\n        if (state.details?.cellularGeneration === \"4g\") return 25;\n        if (state.details?.cellularGeneration === \"3g\") return 5;\n        return 1;\n      default:\n        return 1;\n    }\n  }\n\n  private startPerformanceMonitoring() {\n    // Monitor device performance every 30 seconds\n    setInterval(() => {\n      this.updateDeviceContext();\n    }, 30000);\n  }\n\n  private async updateDeviceContext() {\n    // Get device tier from config (assuming it's stored internally)\n    const deviceTier = DevicePerformanceTier.MID; // Default to mid, would need to get from config\n    const memoryPressure = await this.checkMemoryPressure();\n\n    const context: Partial<PreloadContext> = {\n      deviceTier,\n      memoryPressure,\n      batteryLevel: 0.8, // Would need battery API\n    };\n\n    this.updateContext(context);\n  }\n\n  private async checkMemoryPressure(): Promise<boolean> {\n    // Check if we're approaching memory limits\n    const perfConfig = videoPerformanceConfig.getPreloadProfile();\n    return this.activePreloads.size >= perfConfig.preloadWindowSize;\n  }\n\n  private updateContext(updates: Partial<PreloadContext>) {\n    // Maintain rolling history of context (last 10 entries)\n    if (this.contextHistory.length >= 10) {\n      this.contextHistory.shift();\n    }\n\n    const currentContext = this.contextHistory[this.contextHistory.length - 1] || this.getDefaultContext();\n    this.contextHistory.push({ ...currentContext, ...updates });\n  }\n\n  private getDefaultContext(): PreloadContext {\n    return {\n      networkType: \"unknown\",\n      networkSpeed: 1,\n      deviceTier: DevicePerformanceTier.MID,\n      batteryLevel: 1,\n      memoryPressure: false,\n      userBehavior: {\n        averageWatchTime: 30,\n        skipRate: 0.3,\n        interactionRate: 0.2,\n        preferredContentTypes: [],\n        timeOfDay: new Date().getHours(),\n        dayOfWeek: new Date().getDay(),\n      },\n      contentType: \"feed\",\n    };\n  }\n\n  async preloadVideos(\n    videos: any[],\n    activeIndex: number,\n    contentType: \"feed\" | \"profile\" | \"search\" = \"feed\",\n  ): Promise<void> {\n    const context = this.getCurrentContext();\n    context.contentType = contentType;\n\n    const decisions = videos.map((video, index) => {\n      const distance = Math.abs(index - activeIndex);\n      return this.makePreloadDecision(video, distance, context);\n    });\n\n    // Execute preloads based on decisions\n    const preloadPromises = decisions\n      .filter((decision) => decision.shouldPreload)\n      .sort((a, b) => this.getPriorityWeight(b.priority) - this.getPriorityWeight(a.priority))\n      .slice(0, this.maxConcurrentPreloads)\n      .map(async (decision, index) => {\n        const video = videos[index + activeIndex];\n        if (video) {\n          await this.executePreload(video, decision);\n        }\n      });\n\n    await Promise.allSettled(preloadPromises);\n  }\n\n  private makePreloadDecision(video: any, distance: number, context: PreloadContext): PreloadDecision {\n    const baseDecision: PreloadDecision = {\n      shouldPreload: false,\n      priority: \"low\",\n      quality: \"low\",\n      count: 1,\n      strategy: \"conservative\",\n    };\n\n    // Distance-based preloading\n    if (distance === 0) {\n      return { ...baseDecision, shouldPreload: true, priority: \"high\", quality: \"high\" };\n    }\n    if (distance <= 2) {\n      baseDecision.shouldPreload = true;\n      baseDecision.priority = \"high\";\n    } else if (distance <= 5 && context.deviceTier !== \"low\") {\n      baseDecision.shouldPreload = true;\n      baseDecision.priority = \"normal\";\n    }\n\n    // Network-aware quality selection\n    if (context.networkSpeed >= 25) {\n      baseDecision.quality = \"high\";\n    } else if (context.networkSpeed >= 5) {\n      baseDecision.quality = \"medium\";\n    }\n\n    // Device-aware adjustments\n    if (context.deviceTier === \"low\") {\n      baseDecision.quality = \"low\";\n      baseDecision.count = Math.min(baseDecision.count, 2);\n    }\n\n    // Memory pressure adjustments\n    if (context.memoryPressure) {\n      baseDecision.count = Math.max(1, baseDecision.count - 1);\n      baseDecision.quality = baseDecision.quality === \"high\" ? \"medium\" : \"low\";\n    }\n\n    // Battery-aware adjustments\n    if (context.batteryLevel < 0.2) {\n      baseDecision.strategy = \"conservative\";\n      baseDecision.count = 1;\n    }\n\n    // User behavior predictions\n    if (context.userBehavior.skipRate > 0.5) {\n      baseDecision.count = Math.max(1, baseDecision.count - 1);\n    }\n\n    return baseDecision;\n  }\n\n  private getPriorityWeight(priority: \"high\" | \"normal\" | \"low\"): number {\n    switch (priority) {\n      case \"high\":\n        return 3;\n      case \"normal\":\n        return 2;\n      case \"low\":\n        return 1;\n      default:\n        return 1;\n    }\n  }\n\n  private async executePreload(video: any, decision: PreloadDecision): Promise<void> {\n    const cacheKey = `${video.id}-${decision.quality}`;\n\n    if (this.preloadQueue.has(cacheKey) || this.activePreloads.has(cacheKey)) {\n      return;\n    }\n\n    this.preloadQueue.set(cacheKey, {\n      id: cacheKey,\n      video,\n      decision,\n      timestamp: Date.now(),\n    });\n\n    try {\n      this.activePreloads.add(cacheKey);\n\n      // Select appropriate URI based on quality decision\n      const uri = this.selectUriForQuality(video, decision.quality);\n\n      // Use existing cache manager with enhanced priority\n      await videoCacheManager.preloadVideos([uri], decision.priority);\n\n      this.preloadQueue.delete(cacheKey);\n      this.activePreloads.delete(cacheKey);\n    } catch (error) {\n      console.warn(\"Smart preload failed:\", error);\n      this.preloadQueue.delete(cacheKey);\n      this.activePreloads.delete(cacheKey);\n    }\n  }\n\n  private selectUriForQuality(video: any, quality: \"high\" | \"medium\" | \"low\"): string {\n    // Use existing quality selection logic\n    if (video.selectedVideoUri) return video.selectedVideoUri;\n    if (video.videoVariants?.length > 0) {\n      const qualityMap = { high: \"1080p\", medium: \"720p\", low: \"360p\" };\n      const targetQuality = qualityMap[quality];\n      const variant = video.videoVariants.find((v: any) => v.quality === targetQuality);\n      if (variant?.uri) return variant.uri;\n    }\n    return video.videoUri || video.uri;\n  }\n\n  private getCurrentContext(): PreloadContext {\n    return this.contextHistory[this.contextHistory.length - 1] || this.getDefaultContext();\n  }\n\n  // Public API methods\n  async preloadForFeed(videos: any[], activeIndex: number): Promise<void> {\n    await this.preloadVideos(videos, activeIndex, \"feed\");\n  }\n\n  async preloadForProfile(videos: any[], activeIndex: number): Promise<void> {\n    await this.preloadVideos(videos, activeIndex, \"profile\");\n  }\n\n  async preloadForSearch(videos: any[], activeIndex: number): Promise<void> {\n    await this.preloadVideos(videos, activeIndex, \"search\");\n  }\n\n  getActivePreloads(): string[] {\n    return Array.from(this.activePreloads);\n  }\n\n  clearQueue(): void {\n    this.preloadQueue.clear();\n    this.activePreloads.clear();\n  }\n}\n\ninterface PreloadJob {\n  id: string;\n  video: any;\n  decision: PreloadDecision;\n  timestamp: number;\n}\n\n// Export singleton instance\nexport const smartVideoPreloader = new SmartVideoPreloader();\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/UnifiedVideoProcessingService.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/UnifiedVideoService.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'hasVideoProcessing' is defined but never used.","line":9,"column":20,"nodeType":null,"messageId":"unusedVar","endLine":9,"endColumn":38},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":78,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":78,"endColumn":21},{"ruleId":"@typescript-eslint/no-require-imports","severity":1,"message":"A `require()` style import is forbidden.","line":258,"column":18,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":258,"endColumn":39},{"ruleId":"@typescript-eslint/no-require-imports","severity":1,"message":"A `require()` style import is forbidden.","line":259,"column":23,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":259,"endColumn":44}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Unified Video Service for September 2025\n * Combines Vision Camera v4, Expo Video, and FFmpeg processing\n * Compatible with Reanimated v4 and supports Expo Go fallbacks\n */\n\nimport React from \"react\";\nimport { Platform } from \"react-native\";\nimport { isExpoGo, hasVideoProcessing, environmentDetector } from \"../utils/environmentDetector\";\nimport { videoProcessor } from \"./ModernVideoProcessor\";\nimport { getVisionCameraProcessor, VisionCameraProcessor } from \"./VisionCameraProcessor\";\n\nexport interface UnifiedVideoCapabilities {\n  recording: {\n    visionCamera: boolean; // High-quality recording with Vision Camera v4\n    expoCamera: boolean; // Fallback recording with Expo Camera\n    ffmpeg: boolean; // Post-processing with FFmpeg\n  };\n  effects: {\n    realtimeFaceBlur: boolean; // Vision Camera frame processor\n    realtimeFilters: boolean; // Skia integration\n    postProcessBlur: boolean; // FFmpeg blur\n    postProcessTrim: boolean; // FFmpeg trim\n    postProcessCompress: boolean; // FFmpeg compression\n  };\n  playback: {\n    expoVideo: boolean; // Expo Video player\n    streaming: boolean; // HLS/DASH support\n    controls: boolean; // Native controls\n  };\n  animation: {\n    reanimatedV4: boolean; // Reanimated v4 support\n    worklets: boolean; // Worklets support\n    gestureHandler: boolean; // Gesture support\n  };\n}\n\nexport class UnifiedVideoService {\n  private static instance: UnifiedVideoService | null = null;\n  private static initializationPromise: Promise<UnifiedVideoService> | null = null;\n  private visionCameraProcessor: VisionCameraProcessor | null = null;\n  private capabilities: UnifiedVideoCapabilities | null = null;\n  private initialized = false;\n\n  static async getInstance(): Promise<UnifiedVideoService> {\n    // If already initialized, return the instance\n    if (this.instance && this.instance.initialized) {\n      return this.instance;\n    }\n\n    // If initialization is in progress, wait for it\n    if (this.initializationPromise) {\n      return this.initializationPromise;\n    }\n\n    // Start new initialization\n    this.initializationPromise = (async () => {\n      try {\n        const service = new UnifiedVideoService();\n        await service.initialize();\n        this.instance = service;\n        return service;\n      } catch (error) {\n        // Clear promise on failure to allow retry\n        this.initializationPromise = null;\n        throw error;\n      }\n    })();\n\n    return this.initializationPromise;\n  }\n\n  private async initialize() {\n    // Initialize Vision Camera if available\n    if (!isExpoGo()) {\n      try {\n        this.visionCameraProcessor = await getVisionCameraProcessor();\n      } catch (error) {\n        console.log(\"Vision Camera not available, using fallbacks\");\n      }\n    }\n\n    // Detect capabilities\n    this.capabilities = this.detectCapabilities();\n\n    // Mark as initialized\n    this.initialized = true;\n\n    if (__DEV__) {\n      this.logCapabilities();\n    }\n  }\n\n  private detectCapabilities(): UnifiedVideoCapabilities {\n    const env = environmentDetector.getEnvironmentInfo();\n    const visionCameraAvailable = this.visionCameraProcessor?.isAvailable() || false;\n\n    return {\n      recording: {\n        visionCamera: visionCameraAvailable,\n        expoCamera: true, // Always available\n        ffmpeg: env.features.ffmpeg,\n      },\n      effects: {\n        realtimeFaceBlur: visionCameraAvailable && env.features.mlKit,\n        realtimeFilters: visionCameraAvailable && Platform.OS !== \"web\",\n        postProcessBlur: env.features.ffmpeg,\n        postProcessTrim: env.features.ffmpeg,\n        postProcessCompress: env.features.ffmpeg,\n      },\n      playback: {\n        expoVideo: true,\n        streaming: true,\n        controls: true,\n      },\n      animation: {\n        reanimatedV4: true, // We're using v4\n        worklets: !isExpoGo(), // Not in Expo Go\n        gestureHandler: true,\n      },\n    };\n  }\n\n  /**\n   * Get video recording component based on availability\n   */\n  getRecordingComponent() {\n    if (this.capabilities?.recording.visionCamera) {\n      // Return Vision Camera v4 components\n      return this.visionCameraProcessor?.getCameraComponents();\n    }\n\n    // Return Expo Camera fallback\n    return {\n      Camera: null, // Would import expo-camera here\n      isVisionCamera: false,\n      isExpoCamera: true,\n    };\n  }\n\n  /**\n   * Record video with best available method\n   */\n  async recordVideo(options: {\n    camera?: any; // Camera ref\n    quality?: \"low\" | \"medium\" | \"high\";\n    maxDuration?: number;\n    onProgress?: (progress: number) => void;\n    onFinished?: (video: { uri: string; duration: number }) => void;\n    onError?: (error: any) => void;\n  }) {\n    // Use Vision Camera if available\n    if (this.capabilities?.recording.visionCamera && options.camera) {\n      return this.visionCameraProcessor?.recordVideo(options.camera, {\n        onRecordingFinished: async (video) => {\n          // Process the recorded video\n          const processed = await this.processVideo(video.path, {\n            quality: options.quality,\n          });\n          options.onFinished?.(processed);\n        },\n        onRecordingError: options.onError,\n      });\n    }\n\n    // Fallback to Expo Camera\n    console.log(\"Using Expo Camera fallback for recording\");\n    // Implementation would go here\n  }\n\n  /**\n   * Process video with all available methods\n   */\n  async processVideo(\n    videoUri: string,\n    options: {\n      quality?: \"low\" | \"medium\" | \"high\";\n      blur?: boolean;\n      trim?: { start: number; end: number };\n      effects?: string[];\n    } = {},\n  ): Promise<{\n    uri: string;\n    duration: number;\n    width?: number;\n    height?: number;\n    thumbnail?: string;\n  }> {\n    // Check if we can use FFmpeg\n    if (this.capabilities?.effects.postProcessCompress) {\n      const processed = await videoProcessor.processVideo(videoUri, {\n        quality: options.quality || \"high\",\n      });\n\n      return {\n        uri: processed.uri,\n        duration: processed.duration,\n        width: processed.width,\n        height: processed.height,\n        thumbnail: processed.thumbnail,\n      };\n    }\n\n    // Fallback for Expo Go - minimal processing\n    console.log(\"Using minimal processing in Expo Go\");\n\n    // Generate thumbnail at least\n    let thumbnail: string | undefined;\n    try {\n      const VideoThumbnails = await import(\"expo-video-thumbnails\");\n      const { uri } = await VideoThumbnails.getThumbnailAsync(videoUri, {\n        time: 0,\n        quality: 0.8,\n      });\n      thumbnail = uri;\n    } catch (error) {\n      console.warn(\"Thumbnail generation failed:\", error);\n    }\n\n    return {\n      uri: videoUri,\n      duration: 60, // Default duration\n      thumbnail,\n    };\n  }\n\n  /**\n   * Create a frame processor for real-time effects\n   * Works with Reanimated v4 worklets\n   */\n  createFrameProcessor(effect: \"blur\" | \"filter\" | \"custom\", customProcessor?: (frame: any) => void) {\n    \"worklet\";\n\n    if (!this.capabilities?.effects.realtimeFaceBlur) {\n      console.log(\"Frame processors not available\");\n      return null;\n    }\n\n    switch (effect) {\n      case \"blur\":\n        return this.visionCameraProcessor?.createFaceBlurProcessor();\n      case \"custom\":\n        if (customProcessor) {\n          return this.visionCameraProcessor?.createFrameProcessor(customProcessor);\n        }\n        return null;\n      default:\n        return null;\n    }\n  }\n\n  /**\n   * Get video player component\n   */\n  getVideoPlayer() {\n    // Always use Expo Video for playback\n    return {\n      VideoView: require(\"expo-video\").VideoView,\n      useVideoPlayer: require(\"expo-video\").useVideoPlayer,\n      isExpoVideo: true,\n    };\n  }\n\n  /**\n   * Check and request permissions\n   */\n  async requestPermissions(): Promise<boolean> {\n    if (this.visionCameraProcessor) {\n      return this.visionCameraProcessor.requestPermissions();\n    }\n\n    // Fallback to Expo permissions\n    try {\n      const { Camera } = await import(\"expo-camera\");\n      const { status } = await Camera.requestCameraPermissionsAsync();\n      return status === \"granted\";\n    } catch (error) {\n      console.error(\"Permission request failed:\", error);\n      return false;\n    }\n  }\n\n  /**\n   * Get current capabilities\n   */\n  getCapabilities(): UnifiedVideoCapabilities | null {\n    if (!this.initialized) {\n      console.warn(\"UnifiedVideoService not initialized. Call getInstance() first.\");\n      return null;\n    }\n    return this.capabilities;\n  }\n\n  /**\n   * Log capabilities for debugging\n   */\n  private logCapabilities() {\n    console.log(\"üìπ Unified Video Service Capabilities:\");\n    console.log(\"=====================================\");\n    console.log(\"Recording:\");\n    console.log(`  Vision Camera v4: ${this.capabilities?.recording.visionCamera ? \"‚úÖ\" : \"‚ùå\"}`);\n    console.log(`  Expo Camera: ${this.capabilities?.recording.expoCamera ? \"‚úÖ\" : \"‚ùå\"}`);\n    console.log(`  FFmpeg: ${this.capabilities?.recording.ffmpeg ? \"‚úÖ\" : \"‚ùå\"}`);\n    console.log(\"\");\n    console.log(\"Real-time Effects:\");\n    console.log(`  Face Blur: ${this.capabilities?.effects.realtimeFaceBlur ? \"‚úÖ\" : \"‚ùå\"}`);\n    console.log(`  Filters: ${this.capabilities?.effects.realtimeFilters ? \"‚úÖ\" : \"‚ùå\"}`);\n    console.log(\"\");\n    console.log(\"Post-processing:\");\n    console.log(`  Blur: ${this.capabilities?.effects.postProcessBlur ? \"‚úÖ\" : \"‚ùå\"}`);\n    console.log(`  Trim: ${this.capabilities?.effects.postProcessTrim ? \"‚úÖ\" : \"‚ùå\"}`);\n    console.log(`  Compress: ${this.capabilities?.effects.postProcessCompress ? \"‚úÖ\" : \"‚ùå\"}`);\n    console.log(\"\");\n    console.log(\"Animation:\");\n    console.log(`  Reanimated v4: ${this.capabilities?.animation.reanimatedV4 ? \"‚úÖ\" : \"‚ùå\"}`);\n    console.log(`  Worklets: ${this.capabilities?.animation.worklets ? \"‚úÖ\" : \"‚ùå\"}`);\n    console.log(\"=====================================\");\n  }\n\n  /**\n   * Check if a specific feature is available\n   */\n  isFeatureAvailable(\n    feature: keyof UnifiedVideoCapabilities[\"effects\"] | keyof UnifiedVideoCapabilities[\"recording\"],\n  ): boolean {\n    const effects = this.capabilities?.effects as any;\n    const recording = this.capabilities?.recording as any;\n\n    return effects?.[feature] || recording?.[feature] || false;\n  }\n\n  /**\n   * Get recommendation for current environment\n   */\n  getEnvironmentRecommendation(): string {\n    if (isExpoGo()) {\n      return \"You are in Expo Go. Basic video features are available. For full features, create a development build.\";\n    }\n\n    if (!this.capabilities?.recording.visionCamera) {\n      return \"Vision Camera not available. Using Expo Camera for recording. Consider installing Vision Camera for better quality.\";\n    }\n\n    if (!this.capabilities?.effects.postProcessCompress) {\n      return \"FFmpeg not available. Video compression and advanced processing disabled.\";\n    }\n\n    return \"All video features are available! You have Vision Camera v4, FFmpeg, and Reanimated v4.\";\n  }\n}\n\n// Export singleton getter\nexport const getUnifiedVideoService = () => UnifiedVideoService.getInstance();\n\n// Export convenience hooks for React components\nexport const useVideoCapabilities = () => {\n  const [capabilities, setCapabilities] = React.useState<UnifiedVideoCapabilities | null>(null);\n\n  React.useEffect(() => {\n    let cancelled = false;\n\n    getUnifiedVideoService()\n      .then((service) => {\n        if (!cancelled) {\n          setCapabilities(service.getCapabilities());\n        }\n      })\n      .catch((error) => {\n        if (!cancelled) {\n          console.error(\"Failed to get video capabilities:\", error);\n          setCapabilities(null);\n        }\n      });\n\n    return () => {\n      cancelled = true;\n    };\n  }, []);\n\n  return capabilities;\n};\n\nexport const useVideoRecorder = () => {\n  const [service, setService] = React.useState<UnifiedVideoService | null>(null);\n\n  React.useEffect(() => {\n    getUnifiedVideoService().then(setService);\n  }, []);\n\n  return {\n    record: service?.recordVideo.bind(service),\n    process: service?.processVideo.bind(service),\n    requestPermissions: service?.requestPermissions.bind(service),\n    getComponents: service?.getRecordingComponent.bind(service),\n    isReady: !!service,\n  };\n};\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/VideoAnalyticsAggregator.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'VideoEngagementSummary' is defined but never used.","line":1,"column":38,"nodeType":null,"messageId":"unusedVar","endLine":1,"endColumn":60},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'videoAnalyticsStorage' is defined but never used.","line":2,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":2,"endColumn":31},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'cutoffTime' is assigned a value but never used.","line":314,"column":11,"nodeType":null,"messageId":"unusedVar","endLine":314,"endColumn":21}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { VideoEvent, VideoAnalytics, VideoEngagementSummary } from \"./VideoDataService\";\nimport { videoAnalyticsStorage } from \"../utils/videoAnalyticsStorage\";\nimport AsyncStorage from \"@react-native-async-storage/async-storage\";\n\ninterface AggregatedMetrics {\n  totalWatchTime: number;\n  totalSessions: number;\n  uniqueViewers: Set<string>;\n  averageWatchTime: number;\n  averageCompletionRate: number;\n  totalInteractions: number;\n  engagementScore: number;\n  peakViewingHours: Map<number, number>;\n  videoPerformance: Map<string, VideoPerformance>;\n}\n\ninterface VideoPerformance {\n  videoId: string;\n  watchTime: number;\n  completionRate: number;\n  engagementScore: number;\n  views: number;\n  interactions: number;\n  averageViewDuration: number;\n  retentionRate: number;\n  dropOffPoints: number[];\n}\n\ninterface UserSegment {\n  segmentId: string;\n  name: string;\n  criteria: {\n    minWatchTime?: number;\n    minCompletionRate?: number;\n    minEngagement?: number;\n  };\n  users: Set<string>;\n  metrics: {\n    averageWatchTime: number;\n    averageCompletionRate: number;\n    averageEngagement: number;\n    totalUsers: number;\n  };\n}\n\ninterface TrendData {\n  timestamp: number;\n  value: number;\n}\n\ninterface PredictiveModel {\n  videoId: string;\n  predictedViews: number;\n  predictedEngagement: number;\n  confidence: number;\n}\n\nconst CACHE_KEY_PREFIX = \"@analytics_aggregator_cache\";\nconst CACHE_TTL = 5 * 60 * 1000; // 5 minutes\n\nexport class VideoAnalyticsAggregator {\n  private cache = new Map<string, { data: any; timestamp: number }>();\n\n  /**\n   * Aggregate raw analytics events into meaningful metrics.\n   */\n  async aggregateEvents(\n    events: VideoEvent[],\n    period: \"hour\" | \"day\" | \"week\" | \"month\" = \"day\",\n  ): Promise<AggregatedMetrics> {\n    const metrics: AggregatedMetrics = {\n      totalWatchTime: 0,\n      totalSessions: 0,\n      uniqueViewers: new Set(),\n      averageWatchTime: 0,\n      averageCompletionRate: 0,\n      totalInteractions: 0,\n      engagementScore: 0,\n      peakViewingHours: new Map(),\n      videoPerformance: new Map(),\n    };\n\n    // Group events by session\n    const sessionMap = new Map<string, VideoEvent[]>();\n    events.forEach((event) => {\n      const sessionEvents = sessionMap.get(event.sessionId) || [];\n      sessionEvents.push(event);\n      sessionMap.set(event.sessionId, sessionEvents);\n    });\n\n    // Process each session\n    for (const [sessionId, sessionEvents] of sessionMap.entries()) {\n      metrics.totalSessions++;\n      metrics.uniqueViewers.add(sessionId); // Simplified: use sessionId as unique viewer\n\n      // Calculate session metrics\n      const sessionMetrics = this.calculateSessionMetrics(sessionEvents);\n      metrics.totalWatchTime += sessionMetrics.watchTime;\n\n      // Track peak hours\n      const hour = new Date(sessionEvents[0].timestamp).getHours();\n      metrics.peakViewingHours.set(hour, (metrics.peakViewingHours.get(hour) || 0) + 1);\n\n      // Track video performance\n      const videoId = sessionEvents[0].metadata?.videoId || \"unknown\";\n      const videoPerf = metrics.videoPerformance.get(videoId) || this.createEmptyVideoPerformance(videoId);\n\n      videoPerf.watchTime += sessionMetrics.watchTime;\n      videoPerf.views++;\n      videoPerf.interactions += sessionMetrics.interactions;\n      videoPerf.completionRate =\n        (videoPerf.completionRate * (videoPerf.views - 1) + sessionMetrics.completionRate) / videoPerf.views;\n\n      metrics.videoPerformance.set(videoId, videoPerf);\n    }\n\n    // Calculate averages\n    if (metrics.totalSessions > 0) {\n      metrics.averageWatchTime = metrics.totalWatchTime / metrics.totalSessions;\n\n      // Calculate average completion rate from video performances\n      const completionRates = Array.from(metrics.videoPerformance.values()).map((v) => v.completionRate);\n      metrics.averageCompletionRate = completionRates.reduce((a, b) => a + b, 0) / completionRates.length;\n\n      // Calculate overall engagement score\n      metrics.engagementScore = this.calculateEngagementScore(metrics);\n    }\n\n    return metrics;\n  }\n\n  /**\n   * Calculate engagement score based on multiple factors.\n   */\n  calculateEngagementScore(metrics: AggregatedMetrics): number {\n    const watchTimeScore = Math.min(metrics.averageWatchTime / 300, 1) * 30; // Normalize to 5 minutes\n    const completionScore = metrics.averageCompletionRate * 40;\n    const interactionScore = Math.min(metrics.totalInteractions / metrics.totalSessions, 1) * 30;\n\n    return Math.round(watchTimeScore + completionScore + interactionScore);\n  }\n\n  /**\n   * Calculate metrics for a single session.\n   */\n  private calculateSessionMetrics(events: VideoEvent[]): {\n    watchTime: number;\n    completionRate: number;\n    interactions: number;\n  } {\n    let watchTime = 0;\n    let completionRate = 0;\n    let interactions = 0;\n\n    // Sort events by timestamp\n    events.sort((a, b) => a.timestamp - b.timestamp);\n\n    let lastPlayTime: number | null = null;\n\n    events.forEach((event) => {\n      switch (event.type) {\n        case \"play\":\n        case \"resume\":\n          lastPlayTime = event.timestamp;\n          break;\n        case \"pause\":\n        case \"complete\":\n        case \"session_end\":\n          if (lastPlayTime) {\n            watchTime += (event.timestamp - lastPlayTime) / 1000; // Convert to seconds\n            lastPlayTime = null;\n          }\n          if (event.type === \"complete\") {\n            completionRate = event.metadata?.completionRate || 100;\n          }\n          break;\n        case \"like\":\n        case \"unlike\":\n        case \"comment\":\n        case \"share\":\n        case \"save\":\n          interactions++;\n          break;\n      }\n    });\n\n    return { watchTime, completionRate, interactions };\n  }\n\n  /**\n   * Create empty video performance object.\n   */\n  private createEmptyVideoPerformance(videoId: string): VideoPerformance {\n    return {\n      videoId,\n      watchTime: 0,\n      completionRate: 0,\n      engagementScore: 0,\n      views: 0,\n      interactions: 0,\n      averageViewDuration: 0,\n      retentionRate: 0,\n      dropOffPoints: [],\n    };\n  }\n\n  /**\n   * Analyze user behavior patterns and segment users.\n   */\n  async analyzeUserSegments(analytics: VideoAnalytics[]): Promise<UserSegment[]> {\n    const segments: UserSegment[] = [\n      {\n        segmentId: \"highly-engaged\",\n        name: \"Highly Engaged\",\n        criteria: {\n          minWatchTime: 300, // 5 minutes\n          minCompletionRate: 80,\n          minEngagement: 70,\n        },\n        users: new Set(),\n        metrics: {\n          averageWatchTime: 0,\n          averageCompletionRate: 0,\n          averageEngagement: 0,\n          totalUsers: 0,\n        },\n      },\n      {\n        segmentId: \"casual-viewers\",\n        name: \"Casual Viewers\",\n        criteria: {\n          minWatchTime: 60, // 1 minute\n          minCompletionRate: 30,\n          minEngagement: 30,\n        },\n        users: new Set(),\n        metrics: {\n          averageWatchTime: 0,\n          averageCompletionRate: 0,\n          averageEngagement: 0,\n          totalUsers: 0,\n        },\n      },\n      {\n        segmentId: \"new-users\",\n        name: \"New Users\",\n        criteria: {\n          minWatchTime: 0,\n          minCompletionRate: 0,\n          minEngagement: 0,\n        },\n        users: new Set(),\n        metrics: {\n          averageWatchTime: 0,\n          averageCompletionRate: 0,\n          averageEngagement: 0,\n          totalUsers: 0,\n        },\n      },\n    ];\n\n    // Segment users based on their analytics\n    analytics.forEach((userAnalytics) => {\n      const userId = userAnalytics.sessionId;\n\n      // Determine segment\n      let assignedSegment: UserSegment | null = null;\n\n      if (userAnalytics.watchTime >= 300 && userAnalytics.completionRate >= 80 && userAnalytics.engagementScore >= 70) {\n        assignedSegment = segments[0]; // Highly engaged\n      } else if (\n        userAnalytics.watchTime >= 60 &&\n        userAnalytics.completionRate >= 30 &&\n        userAnalytics.engagementScore >= 30\n      ) {\n        assignedSegment = segments[1]; // Casual viewers\n      } else {\n        assignedSegment = segments[2]; // New users\n      }\n\n      if (assignedSegment) {\n        assignedSegment.users.add(userId);\n        assignedSegment.metrics.totalUsers++;\n        assignedSegment.metrics.averageWatchTime += userAnalytics.watchTime;\n        assignedSegment.metrics.averageCompletionRate += userAnalytics.completionRate;\n        assignedSegment.metrics.averageEngagement += userAnalytics.engagementScore;\n      }\n    });\n\n    // Calculate segment averages\n    segments.forEach((segment) => {\n      if (segment.metrics.totalUsers > 0) {\n        segment.metrics.averageWatchTime /= segment.metrics.totalUsers;\n        segment.metrics.averageCompletionRate /= segment.metrics.totalUsers;\n        segment.metrics.averageEngagement /= segment.metrics.totalUsers;\n      }\n    });\n\n    return segments;\n  }\n\n  /**\n   * Identify trending videos based on recent performance.\n   */\n  async identifyTrendingVideos(\n    videoPerformances: VideoPerformance[],\n    timeWindow: number = 24 * 60 * 60 * 1000, // 24 hours\n  ): Promise<{\n    trending: VideoPerformance[];\n    rising: VideoPerformance[];\n    declining: VideoPerformance[];\n  }> {\n    const now = Date.now();\n    const cutoffTime = now - timeWindow;\n\n    // Sort by engagement score\n    const sorted = [...videoPerformances].sort((a, b) => b.engagementScore - a.engagementScore);\n\n    // Calculate trend scores\n    const trending = sorted.slice(0, 10); // Top 10 by engagement\n\n    // Identify rising (improving performance)\n    const rising = sorted\n      .filter((video) => {\n        // Simplified: videos with high recent engagement\n        return video.engagementScore > 70 && video.views > 10;\n      })\n      .slice(0, 5);\n\n    // Identify declining (decreasing performance)\n    const declining = sorted\n      .filter((video) => {\n        // Simplified: videos with low recent engagement despite views\n        return video.engagementScore < 30 && video.views > 20;\n      })\n      .slice(0, 5);\n\n    return { trending, rising, declining };\n  }\n\n  /**\n   * Predict video performance based on historical data.\n   */\n  async predictVideoPerformance(videoId: string, historicalData: VideoPerformance[]): Promise<PredictiveModel> {\n    // Simple linear prediction based on recent trends\n    const videoHistory = historicalData.filter((d) => d.videoId === videoId);\n\n    if (videoHistory.length < 2) {\n      return {\n        videoId,\n        predictedViews: 0,\n        predictedEngagement: 0,\n        confidence: 0,\n      };\n    }\n\n    // Calculate growth rate\n    const recent = videoHistory[videoHistory.length - 1];\n    const previous = videoHistory[videoHistory.length - 2];\n\n    const viewGrowthRate = (recent.views - previous.views) / Math.max(previous.views, 1);\n    const engagementGrowthRate =\n      (recent.engagementScore - previous.engagementScore) / Math.max(previous.engagementScore, 1);\n\n    // Predict next period\n    const predictedViews = Math.round(recent.views * (1 + viewGrowthRate));\n    const predictedEngagement = Math.round(recent.engagementScore * (1 + engagementGrowthRate));\n\n    // Calculate confidence based on data points and consistency\n    const dataPoints = videoHistory.length;\n    const consistency = 1 - Math.abs(viewGrowthRate - engagementGrowthRate);\n    const confidence = Math.min((dataPoints / 10) * consistency, 1) * 100;\n\n    return {\n      videoId,\n      predictedViews,\n      predictedEngagement,\n      confidence,\n    };\n  }\n\n  /**\n   * Generate comprehensive analytics report.\n   */\n  async generateReport(\n    events: VideoEvent[],\n    period: \"day\" | \"week\" | \"month\",\n  ): Promise<{\n    summary: AggregatedMetrics;\n    trends: TrendData[];\n    topVideos: VideoPerformance[];\n    userSegments: UserSegment[];\n    predictions: PredictiveModel[];\n  }> {\n    // Get aggregated metrics\n    const summary = await this.aggregateEvents(events, period);\n\n    // Generate trend data\n    const trends = this.generateTrendData(events, period);\n\n    // Get top videos\n    const topVideos = Array.from(summary.videoPerformance.values())\n      .sort((a, b) => b.engagementScore - a.engagementScore)\n      .slice(0, 10);\n\n    // Analyze user segments (simplified - using mock data)\n    const mockAnalytics: VideoAnalytics[] = Array.from(summary.videoPerformance.values()).map((perf) => ({\n      videoId: perf.videoId,\n      sessionId: `session-${perf.videoId}`,\n      watchTime: perf.watchTime,\n      completionRate: perf.completionRate,\n      engagementScore: perf.engagementScore,\n      interactions: {\n        likes: Math.floor(perf.interactions * 0.4),\n        comments: Math.floor(perf.interactions * 0.2),\n        shares: Math.floor(perf.interactions * 0.2),\n        saves: Math.floor(perf.interactions * 0.2),\n      },\n      bufferingEvents: 0,\n      seekCount: 0,\n      averageViewDuration: perf.averageViewDuration,\n      sessionStartTime: Date.now() - 24 * 60 * 60 * 1000,\n      lastWatchedPosition: 0,\n    }));\n    const userSegments = await this.analyzeUserSegments(mockAnalytics);\n\n    // Generate predictions for top videos\n    const predictions: PredictiveModel[] = [];\n    for (const video of topVideos.slice(0, 5)) {\n      const prediction = await this.predictVideoPerformance(video.videoId, [video]);\n      predictions.push(prediction);\n    }\n\n    return {\n      summary,\n      trends,\n      topVideos,\n      userSegments,\n      predictions,\n    };\n  }\n\n  /**\n   * Generate trend data over time.\n   */\n  private generateTrendData(events: VideoEvent[], period: \"day\" | \"week\" | \"month\"): TrendData[] {\n    const trends: TrendData[] = [];\n    const now = Date.now();\n\n    // Determine time buckets\n    let bucketSize: number;\n    let bucketCount: number;\n\n    switch (period) {\n      case \"day\":\n        bucketSize = 60 * 60 * 1000; // 1 hour\n        bucketCount = 24;\n        break;\n      case \"week\":\n        bucketSize = 24 * 60 * 60 * 1000; // 1 day\n        bucketCount = 7;\n        break;\n      case \"month\":\n        bucketSize = 24 * 60 * 60 * 1000; // 1 day\n        bucketCount = 30;\n        break;\n    }\n\n    // Create buckets\n    for (let i = 0; i < bucketCount; i++) {\n      const bucketStart = now - (bucketCount - i) * bucketSize;\n      const bucketEnd = bucketStart + bucketSize;\n\n      // Count events in this bucket\n      const bucketEvents = events.filter((e) => e.timestamp >= bucketStart && e.timestamp < bucketEnd);\n\n      trends.push({\n        timestamp: bucketStart,\n        value: bucketEvents.length,\n      });\n    }\n\n    return trends;\n  }\n\n  /**\n   * Cache analytics results for performance.\n   */\n  async cacheResult(key: string, data: any): Promise<void> {\n    this.cache.set(key, {\n      data,\n      timestamp: Date.now(),\n    });\n\n    // Also persist to AsyncStorage\n    try {\n      await AsyncStorage.setItem(\n        `${CACHE_KEY_PREFIX}_${key}`,\n        JSON.stringify({\n          data,\n          timestamp: Date.now(),\n        }),\n      );\n    } catch (error) {\n      console.error(\"Failed to cache analytics result:\", error);\n    }\n  }\n\n  /**\n   * Get cached result if available and not expired.\n   */\n  async getCachedResult(key: string): Promise<any | null> {\n    // Check memory cache first\n    const memCached = this.cache.get(key);\n    if (memCached && Date.now() - memCached.timestamp < CACHE_TTL) {\n      return memCached.data;\n    }\n\n    // Check persistent cache\n    try {\n      const stored = await AsyncStorage.getItem(`${CACHE_KEY_PREFIX}_${key}`);\n      if (stored) {\n        const cached = JSON.parse(stored);\n        if (Date.now() - cached.timestamp < CACHE_TTL) {\n          // Update memory cache\n          this.cache.set(key, cached);\n          return cached.data;\n        }\n      }\n    } catch (error) {\n      console.error(\"Failed to get cached analytics result:\", error);\n    }\n\n    return null;\n  }\n\n  /**\n   * Clear analytics cache.\n   */\n  async clearCache(): Promise<void> {\n    this.cache.clear();\n\n    // Clear persistent cache\n    try {\n      const keys = await AsyncStorage.getAllKeys();\n      const cacheKeys = keys.filter((k) => k.startsWith(CACHE_KEY_PREFIX));\n      await AsyncStorage.multiRemove(cacheKeys);\n    } catch (error) {\n      console.error(\"Failed to clear analytics cache:\", error);\n    }\n  }\n\n  /**\n   * Export analytics data in various formats.\n   */\n  async exportData(data: any, format: \"json\" | \"csv\" = \"json\"): Promise<string> {\n    if (format === \"json\") {\n      return JSON.stringify(data, null, 2);\n    }\n\n    // CSV export\n    if (Array.isArray(data)) {\n      const headers = Object.keys(data[0] || {}).join(\",\");\n      const rows = data.map((item) =>\n        Object.values(item)\n          .map((v) => (typeof v === \"string\" && v.includes(\",\") ? `\"${v}\"` : v))\n          .join(\",\"),\n      );\n      return [headers, ...rows].join(\"\\n\");\n    }\n\n    return \"\";\n  }\n}\n\nexport const videoAnalyticsAggregator = new VideoAnalyticsAggregator();\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/VideoBackgroundQueue.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'offlineQueue' is defined but never used.","line":2,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":2,"endColumn":22},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'BackgroundProcessingConfig' is defined but never used.","line":3,"column":57,"nodeType":null,"messageId":"unusedVar","endLine":3,"endColumn":83}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { unifiedVideoProcessingService } from \"./UnifiedVideoProcessingService\";\nimport { offlineQueue } from \"../lib/offlineQueue\";\nimport { videoPerformanceConfig, DevicePerformanceTier, BackgroundProcessingConfig } from \"../config/videoPerformance\";\nimport { environmentDetector } from \"../utils/environmentDetector\";\nimport { AppState, AppStateStatus } from \"react-native\";\nimport AsyncStorage from \"@react-native-async-storage/async-storage\";\n\nexport enum JobPriority {\n  CRITICAL = 5,\n  HIGH = 4,\n  NORMAL = 3,\n  LOW = 2,\n  IDLE = 1,\n}\n\nexport enum JobType {\n  QUALITY_VARIANT_GENERATION = \"quality_variant_generation\",\n  VIDEO_PRELOADING = \"video_preloading\",\n  CACHE_OPTIMIZATION = \"cache_optimization\",\n  THUMBNAIL_GENERATION = \"thumbnail_generation\",\n  VIDEO_TRANSCODING = \"video_transcoding\",\n  METADATA_EXTRACTION = \"metadata_extraction\",\n  CLEANUP = \"cleanup\",\n}\n\nexport interface BackgroundJob {\n  id: string;\n  type: JobType;\n  priority: JobPriority;\n  data: any;\n  status: \"pending\" | \"processing\" | \"completed\" | \"failed\" | \"cancelled\";\n  createdAt: number;\n  startedAt?: number;\n  completedAt?: number;\n  error?: string;\n  retryCount: number;\n  maxRetries: number;\n  progress?: number;\n  result?: any;\n  memoryUsage?: number;\n}\n\nexport interface JobResult<T = any> {\n  success: boolean;\n  data?: T;\n  error?: string;\n  duration?: number;\n  memoryUsed?: number;\n}\n\ninterface QueueConfig {\n  maxConcurrentJobs: number;\n  jobQueueLimit: number;\n  priorityLevels: number;\n  memoryThreshold: number;\n  idleThreshold: number;\n  batchSize: number;\n  persistJobs: boolean;\n  autoResume: boolean;\n}\n\nclass VideoBackgroundQueue {\n  private queue: Map<string, BackgroundJob> = new Map();\n  private processingJobs: Map<string, BackgroundJob> = new Map();\n  private completedJobs: Map<string, BackgroundJob> = new Map();\n  private config: QueueConfig;\n  private isProcessing = false;\n  private isPaused = false;\n  private memoryMonitorInterval?: NodeJS.Timeout;\n  private appStateSubscription?: any;\n  private currentAppState: AppStateStatus = \"active\";\n  private jobIdCounter = 0;\n  private videoProcessingService = unifiedVideoProcessingService;\n  private deviceTier: DevicePerformanceTier = DevicePerformanceTier.MID;\n  private jobListeners: Map<string, (result: JobResult) => void> = new Map();\n  private progressCallbacks: Map<string, (progress: number) => void> = new Map();\n\n  constructor(config?: Partial<QueueConfig>) {\n    this.config = this.getDefaultConfig();\n\n    if (config) {\n      this.config = { ...this.config, ...config };\n    }\n\n    this.initialize();\n  }\n\n  private getDefaultConfig(): QueueConfig {\n    const backgroundConfig = videoPerformanceConfig.getBackgroundProcessingConfig();\n\n    return {\n      maxConcurrentJobs: backgroundConfig.maxConcurrentJobs,\n      jobQueueLimit: backgroundConfig.jobQueueLimit,\n      priorityLevels: backgroundConfig.priorityLevels,\n      memoryThreshold: backgroundConfig.memoryThreshold,\n      idleThreshold: backgroundConfig.idleThreshold,\n      batchSize: backgroundConfig.batchSize,\n      persistJobs: true,\n      autoResume: true,\n    };\n  }\n\n  private async initialize(): Promise<void> {\n    // Detect device tier\n    await this.detectDeviceTier();\n\n    // Update config based on device tier\n    this.updateConfigForDeviceTier();\n\n    // Start monitoring\n    this.startMemoryMonitoring();\n    this.startAppStateMonitoring();\n\n    // Load persisted jobs if enabled\n    if (this.config.persistJobs) {\n      await this.loadPersistedJobs();\n    }\n\n    // Auto-resume if enabled\n    if (this.config.autoResume) {\n      this.resume();\n    }\n  }\n\n  private async detectDeviceTier(): Promise<void> {\n    try {\n      const memoryInfo = await environmentDetector.getMemoryInfo();\n      const totalMemoryGB = memoryInfo.totalMemory / (1024 * 1024 * 1024);\n\n      if (totalMemoryGB >= 6) {\n        this.deviceTier = DevicePerformanceTier.HIGH;\n      } else if (totalMemoryGB >= 4) {\n        this.deviceTier = DevicePerformanceTier.MID;\n      } else {\n        this.deviceTier = DevicePerformanceTier.LOW;\n      }\n\n      videoPerformanceConfig.setDeviceTier(this.deviceTier);\n    } catch (error) {\n      console.error(\"Failed to detect device tier:\", error);\n    }\n  }\n\n  private updateConfigForDeviceTier(): void {\n    const backgroundConfig = videoPerformanceConfig.getBackgroundProcessingConfig();\n\n    this.config.maxConcurrentJobs = backgroundConfig.maxConcurrentJobs;\n    this.config.jobQueueLimit = backgroundConfig.jobQueueLimit;\n    this.config.memoryThreshold = backgroundConfig.memoryThreshold;\n    this.config.batchSize = backgroundConfig.batchSize;\n  }\n\n  private startMemoryMonitoring(): void {\n    this.memoryMonitorInterval = setInterval(async () => {\n      const memoryInfo = await environmentDetector.getMemoryInfo();\n      const memoryUsage = (memoryInfo.totalMemory - memoryInfo.availableMemory) / memoryInfo.totalMemory;\n\n      if (memoryUsage > this.config.memoryThreshold) {\n        // Pause processing if memory pressure is high\n        this.pauseForMemoryPressure();\n      } else if (this.isPaused && memoryUsage < this.config.memoryThreshold - 0.1) {\n        // Resume if memory pressure has reduced\n        this.resume();\n      }\n    }, 5000);\n  }\n\n  private startAppStateMonitoring(): void {\n    this.appStateSubscription = AppState.addEventListener(\"change\", (nextAppState) => {\n      const wasBackground = this.currentAppState === \"background\";\n      const isBackground = nextAppState === \"background\";\n\n      this.currentAppState = nextAppState;\n\n      if (isBackground && !wasBackground) {\n        // App went to background - reduce processing\n        this.reduceProcessingForBackground();\n      } else if (!isBackground && wasBackground) {\n        // App came to foreground - restore processing\n        this.restoreProcessingForForeground();\n      }\n    });\n  }\n\n  private pauseForMemoryPressure(): void {\n    if (!this.isPaused) {\n      console.log(\"[BackgroundQueue] Pausing due to memory pressure\");\n      this.isPaused = true;\n\n      // Cancel low priority jobs\n      for (const [jobId, job] of this.queue) {\n        if (job.priority <= JobPriority.LOW) {\n          this.cancelJob(jobId);\n        }\n      }\n    }\n  }\n\n  private reduceProcessingForBackground(): void {\n    // Reduce concurrent jobs for background mode\n    const originalConcurrency = this.config.maxConcurrentJobs;\n    this.config.maxConcurrentJobs = Math.max(1, Math.floor(originalConcurrency / 2));\n\n    // Cancel idle priority jobs\n    for (const [jobId, job] of this.queue) {\n      if (job.priority === JobPriority.IDLE) {\n        this.cancelJob(jobId);\n      }\n    }\n  }\n\n  private restoreProcessingForForeground(): void {\n    // Restore original concurrency\n    const backgroundConfig = videoPerformanceConfig.getBackgroundProcessingConfig();\n    this.config.maxConcurrentJobs = backgroundConfig.maxConcurrentJobs;\n\n    // Resume processing if paused\n    if (this.isPaused) {\n      this.resume();\n    }\n  }\n\n  public async enqueueJob(\n    type: JobType,\n    data: any,\n    priority: JobPriority = JobPriority.NORMAL,\n    options?: {\n      maxRetries?: number;\n      onProgress?: (progress: number) => void;\n      onComplete?: (result: JobResult) => void;\n    },\n  ): Promise<string> {\n    // Check queue limits\n    if (this.queue.size >= this.config.jobQueueLimit) {\n      // Remove lowest priority job if queue is full\n      this.evictLowestPriorityJob();\n    }\n\n    const jobId = this.generateJobId();\n    const job: BackgroundJob = {\n      id: jobId,\n      type,\n      priority,\n      data,\n      status: \"pending\",\n      createdAt: Date.now(),\n      retryCount: 0,\n      maxRetries: options?.maxRetries ?? 3,\n    };\n\n    this.queue.set(jobId, job);\n\n    // Register callbacks\n    if (options?.onProgress) {\n      this.progressCallbacks.set(jobId, options.onProgress);\n    }\n    if (options?.onComplete) {\n      this.jobListeners.set(jobId, options.onComplete);\n    }\n\n    // Persist job if enabled\n    if (this.config.persistJobs) {\n      await this.persistJob(job);\n    }\n\n    // Start processing if not already running\n    if (!this.isProcessing && !this.isPaused) {\n      this.startProcessing();\n    }\n\n    return jobId;\n  }\n\n  public async enqueueBatch(jobs: { type: JobType; data: any; priority?: JobPriority }[]): Promise<string[]> {\n    const jobIds: string[] = [];\n\n    for (const jobData of jobs) {\n      const jobId = await this.enqueueJob(jobData.type, jobData.data, jobData.priority);\n      jobIds.push(jobId);\n    }\n\n    return jobIds;\n  }\n\n  private generateJobId(): string {\n    return `job_${Date.now()}_${++this.jobIdCounter}`;\n  }\n\n  private evictLowestPriorityJob(): void {\n    let lowestPriorityJob: BackgroundJob | null = null;\n    let lowestPriorityId: string | null = null;\n\n    for (const [id, job] of this.queue) {\n      if (!lowestPriorityJob || job.priority < lowestPriorityJob.priority) {\n        lowestPriorityJob = job;\n        lowestPriorityId = id;\n      }\n    }\n\n    if (lowestPriorityId) {\n      this.cancelJob(lowestPriorityId);\n    }\n  }\n\n  private async startProcessing(): Promise<void> {\n    if (this.isProcessing || this.isPaused) return;\n\n    this.isProcessing = true;\n\n    while (this.queue.size > 0 && !this.isPaused) {\n      // Check concurrent job limit\n      if (this.processingJobs.size >= this.config.maxConcurrentJobs) {\n        await this.waitForJobSlot();\n      }\n\n      // Get highest priority job\n      const nextJob = this.getNextJob();\n      if (!nextJob) break;\n\n      // Process job without blocking\n      this.processJob(nextJob);\n    }\n\n    this.isProcessing = false;\n  }\n\n  private getNextJob(): BackgroundJob | null {\n    let highestPriorityJob: BackgroundJob | null = null;\n    let highestPriorityId: string | null = null;\n\n    for (const [id, job] of this.queue) {\n      if (!highestPriorityJob || job.priority > highestPriorityJob.priority) {\n        highestPriorityJob = job;\n        highestPriorityId = id;\n      }\n    }\n\n    if (highestPriorityId && highestPriorityJob) {\n      this.queue.delete(highestPriorityId);\n      this.processingJobs.set(highestPriorityId, highestPriorityJob);\n      return highestPriorityJob;\n    }\n\n    return null;\n  }\n\n  private async waitForJobSlot(): Promise<void> {\n    return new Promise((resolve) => {\n      const checkInterval = setInterval(() => {\n        if (this.processingJobs.size < this.config.maxConcurrentJobs) {\n          clearInterval(checkInterval);\n          resolve();\n        }\n      }, 100);\n    });\n  }\n\n  private async processJob(job: BackgroundJob): Promise<void> {\n    job.status = \"processing\";\n    job.startedAt = Date.now();\n\n    try {\n      const result = await this.executeJob(job);\n\n      job.status = \"completed\";\n      job.completedAt = Date.now();\n      job.result = result.data;\n\n      // Move to completed\n      this.processingJobs.delete(job.id);\n      this.completedJobs.set(job.id, job);\n\n      // Notify listeners\n      this.notifyJobComplete(job.id, result);\n\n      // Clean up old completed jobs\n      this.cleanupCompletedJobs();\n    } catch (error) {\n      job.error = error instanceof Error ? error.message : String(error);\n      job.retryCount++;\n\n      if (job.retryCount < job.maxRetries) {\n        // Retry job with exponential backoff\n        setTimeout(\n          () => {\n            job.status = \"pending\";\n            this.queue.set(job.id, job);\n            this.processingJobs.delete(job.id);\n\n            if (!this.isProcessing) {\n              this.startProcessing();\n            }\n          },\n          Math.pow(2, job.retryCount) * 1000,\n        );\n      } else {\n        // Job failed permanently\n        job.status = \"failed\";\n        job.completedAt = Date.now();\n\n        this.processingJobs.delete(job.id);\n        this.completedJobs.set(job.id, job);\n\n        this.notifyJobComplete(job.id, {\n          success: false,\n          error: job.error,\n        });\n      }\n    }\n  }\n\n  private async executeJob(job: BackgroundJob): Promise<JobResult> {\n    const startTime = Date.now();\n    const startInfo = await environmentDetector.getMemoryInfo();\n    const startMemory = startInfo.totalMemory - startInfo.availableMemory;\n\n    try {\n      let result: any;\n\n      switch (job.type) {\n        case JobType.QUALITY_VARIANT_GENERATION:\n          result = await this.generateQualityVariants(job.data);\n          break;\n\n        case JobType.VIDEO_PRELOADING:\n          result = await this.preloadVideos(job.data);\n          break;\n\n        case JobType.CACHE_OPTIMIZATION:\n          result = await this.optimizeCache(job.data);\n          break;\n\n        case JobType.THUMBNAIL_GENERATION:\n          result = await this.generateThumbnails(job.data);\n          break;\n\n        case JobType.VIDEO_TRANSCODING:\n          result = await this.transcodeVideo(job.data);\n          break;\n\n        case JobType.METADATA_EXTRACTION:\n          result = await this.extractMetadata(job.data);\n          break;\n\n        case JobType.CLEANUP:\n          result = await this.performCleanup(job.data);\n          break;\n\n        default:\n          throw new Error(`Unknown job type: ${job.type}`);\n      }\n\n      const endInfo = await environmentDetector.getMemoryInfo();\n      const endMemory = endInfo.totalMemory - endInfo.availableMemory;\n\n      return {\n        success: true,\n        data: result,\n        duration: Date.now() - startTime,\n        memoryUsed: endMemory - startMemory,\n      };\n    } catch (error) {\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : String(error),\n        duration: Date.now() - startTime,\n      };\n    }\n  }\n\n  private async generateQualityVariants(data: any): Promise<any> {\n    // Use UnifiedVideoProcessingService for quality variant generation\n    return await this.videoProcessingService.processVideo(data.uri, data.options || {});\n  }\n\n  private async preloadVideos(data: any): Promise<any> {\n    const { uris, priority } = data;\n\n    // Import videoCacheManager dynamically to avoid circular dependency\n    const { videoCacheManager } = await import(\"../utils/videoCacheManager\");\n\n    await videoCacheManager.preloadVideos(uris, priority || \"normal\");\n\n    return { preloadedCount: uris.length };\n  }\n\n  private async optimizeCache(data: any): Promise<any> {\n    const { videoCacheManager } = await import(\"../utils/videoCacheManager\");\n\n    const result = await videoCacheManager.forceCleanup();\n\n    return {\n      removedCount: result.removedCount,\n      freedSpace: result.freedSpace,\n    };\n  }\n\n  private async generateThumbnails(data: any): Promise<any> {\n    // Placeholder for thumbnail generation\n    // In a real implementation, this would use a video processing library\n    return { thumbnailsGenerated: 0 };\n  }\n\n  private async transcodeVideo(data: any): Promise<any> {\n    return await this.videoProcessingService.processVideo(data.uri, data.options || {});\n  }\n\n  private async extractMetadata(data: any): Promise<any> {\n    return await this.videoProcessingService.processVideo(data.uri, data.options || {});\n  }\n\n  private async performCleanup(data: any): Promise<any> {\n    // Clean up old completed jobs\n    const cutoffTime = Date.now() - 24 * 60 * 60 * 1000; // 24 hours\n    let cleanedCount = 0;\n\n    for (const [id, job] of this.completedJobs) {\n      if (job.completedAt && job.completedAt < cutoffTime) {\n        this.completedJobs.delete(id);\n        cleanedCount++;\n      }\n    }\n\n    return { cleanedJobs: cleanedCount };\n  }\n\n  private notifyJobComplete(jobId: string, result: JobResult): void {\n    const listener = this.jobListeners.get(jobId);\n    if (listener) {\n      listener(result);\n      this.jobListeners.delete(jobId);\n    }\n\n    // Clean up progress callback\n    this.progressCallbacks.delete(jobId);\n  }\n\n  private updateJobProgress(jobId: string, progress: number): void {\n    const job = this.processingJobs.get(jobId) || this.queue.get(jobId);\n    if (job) {\n      job.progress = progress;\n\n      const callback = this.progressCallbacks.get(jobId);\n      if (callback) {\n        callback(progress);\n      }\n    }\n  }\n\n  private cleanupCompletedJobs(): void {\n    // Keep only recent completed jobs (last 100)\n    if (this.completedJobs.size > 100) {\n      const sortedJobs = Array.from(this.completedJobs.entries()).sort(\n        (a, b) => (b[1].completedAt || 0) - (a[1].completedAt || 0),\n      );\n\n      this.completedJobs.clear();\n\n      for (let i = 0; i < 100 && i < sortedJobs.length; i++) {\n        this.completedJobs.set(sortedJobs[i][0], sortedJobs[i][1]);\n      }\n    }\n  }\n\n  private async persistJob(job: BackgroundJob): Promise<void> {\n    try {\n      const jobs = await this.loadPersistedJobsData();\n      jobs[job.id] = job;\n      await AsyncStorage.setItem(\"background_jobs\", JSON.stringify(jobs));\n    } catch (error) {\n      console.error(\"Failed to persist job:\", error);\n    }\n  }\n\n  private async loadPersistedJobs(): Promise<void> {\n    try {\n      const jobs = await this.loadPersistedJobsData();\n\n      for (const job of Object.values(jobs)) {\n        if (job.status === \"pending\" || (job.status === \"processing\" && job.retryCount < job.maxRetries)) {\n          job.status = \"pending\";\n          this.queue.set(job.id, job);\n        }\n      }\n    } catch (error) {\n      console.error(\"Failed to load persisted jobs:\", error);\n    }\n  }\n\n  private async loadPersistedJobsData(): Promise<Record<string, BackgroundJob>> {\n    try {\n      const data = await AsyncStorage.getItem(\"background_jobs\");\n      return data ? JSON.parse(data) : {};\n    } catch {\n      return {};\n    }\n  }\n\n  public cancelJob(jobId: string): boolean {\n    // Check if job is in queue\n    if (this.queue.has(jobId)) {\n      const job = this.queue.get(jobId)!;\n      job.status = \"cancelled\";\n      this.queue.delete(jobId);\n      this.completedJobs.set(jobId, job);\n\n      this.notifyJobComplete(jobId, {\n        success: false,\n        error: \"Job cancelled\",\n      });\n\n      return true;\n    }\n\n    // Check if job is processing\n    if (this.processingJobs.has(jobId)) {\n      // Can't cancel a job that's already processing\n      return false;\n    }\n\n    return false;\n  }\n\n  public getJobStatus(jobId: string): BackgroundJob | null {\n    return this.queue.get(jobId) || this.processingJobs.get(jobId) || this.completedJobs.get(jobId) || null;\n  }\n\n  public getQueueStats(): {\n    pending: number;\n    processing: number;\n    completed: number;\n    failed: number;\n    queueSize: number;\n    processingCapacity: number;\n  } {\n    let failedCount = 0;\n    let completedCount = 0;\n\n    for (const job of this.completedJobs.values()) {\n      if (job.status === \"failed\") {\n        failedCount++;\n      } else if (job.status === \"completed\") {\n        completedCount++;\n      }\n    }\n\n    return {\n      pending: this.queue.size,\n      processing: this.processingJobs.size,\n      completed: completedCount,\n      failed: failedCount,\n      queueSize: this.config.jobQueueLimit,\n      processingCapacity: this.config.maxConcurrentJobs,\n    };\n  }\n\n  public pause(): void {\n    this.isPaused = true;\n  }\n\n  public resume(): void {\n    this.isPaused = false;\n\n    if (!this.isProcessing && this.queue.size > 0) {\n      this.startProcessing();\n    }\n  }\n\n  public async clearQueue(): Promise<void> {\n    // Cancel all pending jobs\n    for (const jobId of this.queue.keys()) {\n      this.cancelJob(jobId);\n    }\n\n    // Clear persisted jobs\n    if (this.config.persistJobs) {\n      await AsyncStorage.removeItem(\"background_jobs\");\n    }\n  }\n\n  public destroy(): void {\n    // Stop monitoring\n    if (this.memoryMonitorInterval) {\n      clearInterval(this.memoryMonitorInterval);\n    }\n\n    if (this.appStateSubscription) {\n      this.appStateSubscription.remove();\n    }\n\n    // Clear all jobs\n    this.pause();\n    this.queue.clear();\n    this.processingJobs.clear();\n    this.completedJobs.clear();\n    this.jobListeners.clear();\n    this.progressCallbacks.clear();\n  }\n}\n\nexport const videoBackgroundQueue = new VideoBackgroundQueue();\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/VideoDataService.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'deviceInfo' is assigned a value but never used.","line":319,"column":11,"nodeType":null,"messageId":"unusedVar","endLine":319,"endColumn":21},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":886,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":886,"endColumn":21}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import type { PostgrestError } from \"@supabase/supabase-js\";\nimport AsyncStorage from \"@react-native-async-storage/async-storage\";\nimport { AppState, AppStateStatus } from \"react-native\";\n\nimport { supabase } from \"../lib/supabase\";\nimport type { Confession } from \"../types/confession\";\nimport { normalizeConfessions } from \"../utils/confessionNormalizer\";\nimport { videoQualitySelector } from \"./VideoQualitySelector\";\nimport { videoPerformanceConfig, DevicePerformanceTier } from \"../config/videoPerformance\";\nimport { videoCacheManager } from \"../utils/videoCacheManager\";\nimport { environmentDetector } from \"../utils/environmentDetector\";\nimport { generateUUID } from \"../utils/consolidatedUtils\";\nimport { useConsentStore } from \"../state/consentStore\";\nimport { offlineQueue } from \"../lib/offlineQueue\";\n\ninterface TrendingHashtag {\n  hashtag: string;\n  count: number;\n  percentage: number;\n}\n\nexport interface VideoMetricUpdate {\n  videoId: string;\n  likesDelta?: number;\n  viewsDelta?: number;\n}\n\nexport interface VideoAnalytics {\n  videoId: string;\n  sessionId: string;\n  watchTime: number;\n  completionRate: number;\n  engagementScore: number;\n  interactions: {\n    likes: number;\n    comments: number;\n    shares: number;\n    saves: number;\n  };\n  qualityStats?: {\n    selectedQuality: \"360p\" | \"720p\" | \"1080p\";\n    qualitySwitches: number;\n    bufferingTime: number;\n  };\n  bufferingEvents: number;\n  seekCount: number;\n  averageViewDuration: number;\n  sessionStartTime: number;\n  sessionEndTime?: number;\n  lastWatchedPosition: number;\n}\n\nexport interface VideoEvent {\n  type:\n    | \"play\"\n    | \"pause\"\n    | \"seek\"\n    | \"complete\"\n    | \"like\"\n    | \"unlike\"\n    | \"comment\"\n    | \"share\"\n    | \"save\"\n    | \"buffer_start\"\n    | \"buffer_end\"\n    | \"quality_change\"\n    | \"volume_change\"\n    | \"fullscreen_toggle\"\n    | \"session_start\"\n    | \"session_end\"\n    | \"error\"\n    | \"resume\"\n    | \"impression\"\n    | \"comment_sheet_open\"\n    | \"comment_sheet_opened\"\n    | \"comment_submitted\"\n    | \"comment_reply_initiated\"\n    | \"comment_reaction_added\"\n    | \"comment_reaction_removed\"\n    | \"comment_liked\"\n    | \"comment_unliked\"\n    | \"comment_added\"\n    | \"comment_deleted\"\n    | \"comment_edited\"\n    | \"comments_loaded\"\n    | \"comments_searched\"\n    | \"comment_reported\";\n  timestamp: number;\n  sessionId: string;\n  metadata?: Record<string, any>;\n}\n\nexport interface VideoSession {\n  sessionId: string;\n  videoId: string;\n  startTime: number;\n  endTime?: number;\n  watchTime: number;\n  events: VideoEvent[];\n  isActive: boolean;\n}\n\nexport interface VideoEngagementSummary {\n  totalWatchTime: number;\n  averageWatchTime: number;\n  averageCompletionRate: number;\n  totalViews: number;\n  uniqueViewers: number;\n  engagementRate: number;\n  topVideos: {\n    videoId: string;\n    watchTime: number;\n    completionRate: number;\n    engagementScore: number;\n  }[];\n  timeDistribution: {\n    hour: number;\n    views: number;\n    watchTime: number;\n  }[];\n}\n\ntype SupabaseOperation<T> = () => Promise<{ data: T | null; error: PostgrestError | null }>;\n\nconst CACHE_TTL_MS = 60_000;\nconst MAX_RETRIES = 2;\nconst RETRY_BASE_DELAY_MS = 250;\nconst VIDEO_CONFESSIONS_PREFIX = \"video-confessions\";\nconst TRENDING_VIDEOS_PREFIX = \"trending-videos\";\nconst ANALYTICS_CACHE_PREFIX = \"video-analytics\";\nconst EVENT_QUEUE_KEY = \"@video_analytics_event_queue\";\nconst SESSIONS_KEY = \"@video_analytics_sessions\";\nconst BATCH_UPLOAD_INTERVAL = 30000; // 30 seconds\nconst BATCH_SIZE = 50;\nconst COMPLETION_THRESHOLD = 0.8; // 80% viewed = completed\n\nconst cacheStore = new Map<string, { data: Confession[]; timestamp: number; qualityOptimized?: boolean }>();\nconst analyticsCache = new Map<string, { data: VideoAnalytics; timestamp: number }>();\nconst eventQueue = new Map<string, VideoEvent[]>();\nconst qualitySelectionCache = new Map<\n  string,\n  {\n    quality: string;\n    selectedUri: string;\n    variants: any[];\n    deviceTier: string;\n    networkQuality: string;\n    timestamp: number;\n  }\n>();\nconst deviceTierCache = { tier: null as DevicePerformanceTier | null, timestamp: 0 };\nconst activeSessions = new Map<string, VideoSession>();\nconst watchTimeTrackers = new Map<string, { startTime: number; totalTime: number }>();\n\nlet batchUploadTimer: ReturnType<typeof setTimeout> | null = null;\nlet appState: AppStateStatus = \"active\";\n\nconst delay = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));\n\nconst buildCacheKey = (prefix: string, params: Record<string, unknown>): string => {\n  const serialized = Object.entries(params)\n    .sort(([a], [b]) => a.localeCompare(b))\n    .map(([key, value]) => `${key}=${value}`)\n    .join(\"|\");\n  return `${prefix}:${serialized}`;\n};\n\nconst cloneConfessions = (confessions: Confession[]): Confession[] =>\n  confessions.map((confession) => ({ ...confession }));\n\nconst getCachedList = (key: string, allowStale = false): Confession[] | null => {\n  const entry = cacheStore.get(key);\n  if (!entry) {\n    return null;\n  }\n  const age = Date.now() - entry.timestamp;\n  if (age <= CACHE_TTL_MS || allowStale) {\n    return cloneConfessions(entry.data);\n  }\n  cacheStore.delete(key);\n  return null;\n};\n\nconst setCachedList = (key: string, data: Confession[]) => {\n  cacheStore.set(key, { data: cloneConfessions(data), timestamp: Date.now() });\n};\n\nconst invalidateCacheByPrefix = (prefix: string) => {\n  for (const key of cacheStore.keys()) {\n    if (key.startsWith(prefix)) {\n      cacheStore.delete(key);\n    }\n  }\n};\n\nconst sanitizeVideoUri = (uri?: string | null): string | null => {\n  if (!uri) {\n    return null;\n  }\n\n  const trimmed = uri.trim();\n  return trimmed.length > 0 ? trimmed : null;\n};\n\nconst prepareVideoResults = async (confessions: Confession[], applyQualitySelection = false): Promise<Confession[]> => {\n  const results: Confession[] = [];\n\n  // Ensure confessions is a valid array\n  if (!Array.isArray(confessions)) {\n    console.warn(\"prepareVideoResults: confessions is not an array:\", confessions);\n    return results;\n  }\n\n  for (const confession of confessions) {\n    // Add null/undefined check for confession object\n    if (!confession || typeof confession !== \"object\") {\n      console.warn(\"prepareVideoResults: invalid confession object:\", confession);\n      continue;\n    }\n\n    const sanitizedUri = sanitizeVideoUri(confession.videoUri);\n    if (sanitizedUri) {\n      let finalConfession = { ...confession, videoUri: sanitizedUri };\n\n      // Apply quality selection if enabled\n      if (applyQualitySelection) {\n        try {\n          const qualityResult = await getOrSelectVideoQuality(sanitizedUri);\n          if (qualityResult) {\n            // Add quality metadata to confession without overwriting original URI\n            finalConfession = {\n              ...finalConfession,\n              videoUri: sanitizedUri, // Keep original URI\n              originalVideoUri: sanitizedUri,\n              selectedVideoUri: qualityResult.selectedUri || sanitizedUri,\n              videoQuality: qualityResult.quality,\n              videoVariants: qualityResult.variants,\n              qualityMetadata: {\n                deviceTier: qualityResult.deviceTier,\n                networkQuality: qualityResult.networkQuality,\n                selectedQuality: qualityResult.quality,\n              },\n            } as any;\n          }\n        } catch (error) {\n          console.warn(\"prepareVideoResults: quality selection failed for\", sanitizedUri, error);\n          // Continue with basic confession without quality metadata\n        }\n      }\n\n      results.push(finalConfession);\n    }\n  }\n  return results;\n};\n\n/**\n * Get cached quality selection or select new quality for video\n */\nconst getOrSelectVideoQuality = async (\n  uri: string,\n): Promise<{\n  quality: string;\n  selectedUri: string;\n  variants: any[];\n  deviceTier: string;\n  networkQuality: string;\n  timestamp: number;\n} | null> => {\n  // Check cache first\n  const cached = qualitySelectionCache.get(uri);\n  if (cached && Date.now() - cached.timestamp < CACHE_TTL_MS) {\n    return cached;\n  }\n\n  try {\n    const deviceTier = await getDeviceTier();\n    const networkQuality = \"good\"; // Simplified for now\n\n    // For now, return basic quality selection\n    // In a full implementation, this would analyze available video variants\n    const result = {\n      quality:\n        deviceTier === DevicePerformanceTier.HIGH\n          ? \"1080p\"\n          : deviceTier === DevicePerformanceTier.MID\n            ? \"720p\"\n            : \"360p\",\n      selectedUri: uri,\n      variants: [\n        { quality: \"360p\", uri: uri, width: 640, height: 360 },\n        { quality: \"720p\", uri: uri, width: 1280, height: 720 },\n        { quality: \"1080p\", uri: uri, width: 1920, height: 1080 },\n      ],\n      deviceTier: deviceTier.toString(),\n      networkQuality,\n      timestamp: Date.now(),\n    };\n\n    // Cache the result\n    qualitySelectionCache.set(uri, result);\n    return result;\n  } catch (error) {\n    console.warn(\"getOrSelectVideoQuality failed:\", error);\n    return null;\n  }\n};\n\n/**\n * Get device tier with caching\n */\nconst getDeviceTier = async (): Promise<DevicePerformanceTier> => {\n  if (deviceTierCache.tier && Date.now() - deviceTierCache.timestamp < 600000) {\n    // 10 minute cache\n    return deviceTierCache.tier;\n  }\n\n  try {\n    const deviceInfo = await environmentDetector.getDeviceInfo();\n    const memoryInfo = await environmentDetector.getMemoryInfo();\n    const totalMemoryGB = memoryInfo.totalMemory / (1024 * 1024 * 1024);\n\n    let tier: DevicePerformanceTier;\n    if (totalMemoryGB >= 6) {\n      tier = DevicePerformanceTier.HIGH;\n    } else if (totalMemoryGB >= 4) {\n      tier = DevicePerformanceTier.MID;\n    } else {\n      tier = DevicePerformanceTier.LOW;\n    }\n\n    deviceTierCache.tier = tier;\n    deviceTierCache.timestamp = Date.now();\n    videoPerformanceConfig.setDeviceTier(tier);\n\n    return tier;\n  } catch (error) {\n    console.error(\"Failed to detect device tier:\", error);\n    return DevicePerformanceTier.MID;\n  }\n};\n\nconst executeWithRetry = async <T>(operationName: string, operation: SupabaseOperation<T>): Promise<T | null> => {\n  let attempt = 0;\n  let lastError: PostgrestError | null = null;\n\n  while (attempt <= MAX_RETRIES) {\n    const { data, error } = await operation();\n    if (!error) {\n      return data;\n    }\n\n    lastError = error;\n    attempt += 1;\n    if (attempt > MAX_RETRIES) {\n      break;\n    }\n    await delay(RETRY_BASE_DELAY_MS * attempt);\n  }\n\n  throw lastError ?? new Error(`${operationName} failed after ${MAX_RETRIES + 1} attempts`);\n};\n\nconst handleFetchFailure = (context: string, cacheKey: string): Confession[] => {\n  const fallback = getCachedList(cacheKey, true);\n  if (fallback) {\n    if (__DEV__) {\n      console.warn(`${context}: falling back to stale cache`);\n    }\n    return fallback;\n  }\n  return [];\n};\n\n/**\n * Service for fetching video data for the TikTok-style feed\n * Integrates with Supabase confessions and trending RPC helpers.\n */\nexport class VideoDataService {\n  /**\n   * Fetch video confessions with intelligent quality selection and device-aware pagination.\n   */\n  static async fetchVideoConfessions(limit: number = 20, enableQualitySelection = true): Promise<Confession[]> {\n    // Adjust limit based on device tier\n    const deviceTier = await getDeviceTier();\n    const tierMultipliers = {\n      [DevicePerformanceTier.HIGH]: 1.0,\n      [DevicePerformanceTier.MID]: 0.75,\n      [DevicePerformanceTier.LOW]: 0.5,\n    };\n    const multiplier = tierMultipliers[deviceTier] ?? 0.75; // Default to MID tier multiplier\n    const adjustedLimit = Math.ceil(limit * multiplier);\n    const safeLimit = Math.max(1, Math.min(Math.floor(adjustedLimit), 200));\n\n    const cacheKey = buildCacheKey(VIDEO_CONFESSIONS_PREFIX, { limit: safeLimit, tier: deviceTier });\n    const cached = getCachedList(cacheKey);\n    if (cached) {\n      // Trigger background quality optimization for cached results\n      if (enableQualitySelection && !cacheStore.get(cacheKey)?.qualityOptimized) {\n        VideoDataService.optimizeQualityInBackground(cached);\n      }\n      return cached;\n    }\n\n    try {\n      const confessions = await executeWithRetry<any[]>(\n        \"fetchVideoConfessions\",\n        async () =>\n          await supabase\n            .from(\"confessions\")\n            .select(\n              \"id,type,content,video_uri,video_url,video_quality,transcription,created_at,is_anonymous,likes,views\",\n            )\n            .eq(\"type\", \"video\")\n            .or(\"video_uri.not.is.null,video_url.not.is.null\")\n            .order(\"created_at\", { ascending: false })\n            .limit(safeLimit),\n      );\n\n      const normalized = await normalizeConfessions(confessions ?? []);\n      const playable = await prepareVideoResults(normalized, enableQualitySelection);\n\n      if (playable.length) {\n        setCachedList(cacheKey, playable);\n\n        // Mark as quality optimized if quality selection was applied\n        if (enableQualitySelection) {\n          const entry = cacheStore.get(cacheKey);\n          if (entry) {\n            entry.qualityOptimized = true;\n          }\n        }\n\n        // Trigger intelligent preloading based on device capabilities\n        VideoDataService.intelligentPreload(playable);\n      }\n\n      return playable;\n    } catch (error) {\n      console.error(\"VideoDataService.fetchVideoConfessions failed\", error);\n      const fallback = handleFetchFailure(\"VideoDataService.fetchVideoConfessions\", cacheKey);\n      return Array.isArray(fallback) ? fallback : [];\n    }\n  }\n\n  /**\n   * Fetch trending videos with quality selection and device optimization.\n   */\n  static async fetchTrendingVideos(\n    hoursBack: number = 24,\n    limit: number = 10,\n    enableQualitySelection = true,\n  ): Promise<Confession[]> {\n    const deviceTier = await getDeviceTier();\n    const safeLimit = Math.max(1, Math.min(Math.floor(limit), 100));\n    const safeHours = Math.max(1, Math.min(Math.floor(hoursBack), 168));\n    const cacheKey = buildCacheKey(TRENDING_VIDEOS_PREFIX, {\n      limit: safeLimit,\n      hoursBack: safeHours,\n      tier: deviceTier,\n    });\n    const cached = getCachedList(cacheKey);\n    if (cached) {\n      return cached;\n    }\n\n    try {\n      const trendingData = await executeWithRetry<any[]>(\n        \"fetchTrendingVideos\",\n        async () =>\n          await supabase.rpc(\"get_trending_secrets\", {\n            hours_back: safeHours,\n            limit_count: safeLimit,\n          }),\n      );\n\n      const normalized = await normalizeConfessions(trendingData ?? []);\n      const playable = await prepareVideoResults(normalized, enableQualitySelection);\n      const sliced = playable.slice(0, safeLimit);\n\n      if (sliced.length) {\n        setCachedList(cacheKey, sliced);\n\n        // Preload trending videos more aggressively for high-tier devices\n        if (deviceTier === DevicePerformanceTier.HIGH) {\n          VideoDataService.aggressivePreload(sliced);\n        } else {\n          VideoDataService.intelligentPreload(sliced);\n        }\n      }\n\n      return sliced;\n    } catch (error) {\n      console.error(\"VideoDataService.fetchTrendingVideos failed\", error);\n      const fallback = handleFetchFailure(\"VideoDataService.fetchTrendingVideos\", cacheKey);\n      return Array.isArray(fallback) ? fallback : [];\n    }\n  }\n\n  /**\n   * Fetch trending hashtags using get_trending_hashtags.\n   */\n  static async fetchTrendingHashtags(hoursBack: number = 24, limit: number = 10): Promise<TrendingHashtag[]> {\n    try {\n      const safeLimit = Math.max(1, Math.min(Math.floor(limit), 100));\n      const safeHours = Math.max(1, Math.min(Math.floor(hoursBack), 168));\n\n      const data = await executeWithRetry<TrendingHashtag[]>(\n        \"fetchTrendingHashtags\",\n        async () =>\n          await supabase.rpc(\"get_trending_hashtags\", {\n            hours_back: safeHours,\n            limit_count: safeLimit,\n          }),\n      );\n\n      return (data ?? []).map((row) => ({\n        hashtag: row.hashtag,\n        count: Number(row.count) || 0,\n        percentage: Number(row.percentage) || 0,\n      }));\n    } catch (error) {\n      console.error(\"VideoDataService.fetchTrendingHashtags failed\", error);\n      return [];\n    }\n  }\n\n  /**\n   * Search for video confessions by hashtag via search_confessions_by_hashtag.\n   */\n  static async searchVideosByHashtag(hashtag: string, limit: number = 20): Promise<Confession[]> {\n    if (!hashtag || !hashtag.trim()) {\n      return [];\n    }\n\n    try {\n      const safeLimit = Math.max(1, Math.min(Math.floor(limit), 100));\n      const data = await executeWithRetry<any[]>(\n        \"searchVideosByHashtag\",\n        async () =>\n          await supabase.rpc(\"search_confessions_by_hashtag\", {\n            search_hashtag: hashtag,\n          }),\n      );\n\n      const normalized = await normalizeConfessions(data ?? []);\n      const results = await prepareVideoResults(normalized, true);\n      return results.slice(0, safeLimit);\n    } catch (error) {\n      console.error(\"VideoDataService.searchVideosByHashtag failed\", error);\n      return [];\n    }\n  }\n\n  /**\n   * Update video likes with improved analytics and feedback.\n   * Only tracks the event and fetches latest likes - does NOT toggle the like itself.\n   */\n  static async updateVideoLikes(videoId: string, isLiked: boolean): Promise<number | null> {\n    if (!videoId) {\n      return null;\n    }\n\n    try {\n      // Track the like event for analytics\n      VideoDataService.trackVideoEvent(videoId, {\n        type: isLiked ? \"like\" : \"unlike\",\n        timestamp: Date.now(),\n      });\n\n      // Fetch the current like count\n      const { data: confession } = await supabase.from(\"confessions\").select(\"likes\").eq(\"id\", videoId).single();\n\n      invalidateCacheByPrefix(VIDEO_CONFESSIONS_PREFIX);\n      invalidateCacheByPrefix(TRENDING_VIDEOS_PREFIX);\n\n      return confession?.likes || 0;\n    } catch (error) {\n      console.error(\"VideoDataService.updateVideoLikes failed\", error);\n      return null;\n    }\n  }\n\n  /**\n   * Update video views with improved analytics and return new count.\n   */\n  static async updateVideoViews(videoId: string): Promise<number | null> {\n    if (!videoId) {\n      return null;\n    }\n\n    try {\n      await executeWithRetry(\n        \"updateVideoViews\",\n        async () =>\n          await (supabase as any).rpc(\"increment_video_views\", {\n            confession_uuid: videoId,\n          }),\n      );\n\n      invalidateCacheByPrefix(VIDEO_CONFESSIONS_PREFIX);\n      invalidateCacheByPrefix(TRENDING_VIDEOS_PREFIX);\n\n      // Track the view event\n      VideoDataService.trackVideoEvent(videoId, {\n        type: \"play\",\n        timestamp: Date.now(),\n      });\n\n      // Try to fetch updated view count\n      const { data: confession } = await supabase.from(\"confessions\").select(\"views\").eq(\"id\", videoId).single();\n\n      return confession?.views || 0;\n    } catch (error) {\n      if (__DEV__) {\n        console.warn(\"VideoDataService.updateVideoViews failed\", error);\n      }\n      return null;\n    }\n  }\n\n  /**\n   * Get comment count for a video confession.\n   */\n  static async getCommentCount(videoId: string): Promise<number> {\n    if (!videoId) {\n      return 0;\n    }\n\n    try {\n      const { count, error } = await supabase\n        .from(\"replies\")\n        .select(\"*\", { count: \"exact\", head: true })\n        .eq(\"confession_id\", videoId);\n\n      if (error) throw error;\n      return count || 0;\n    } catch (error) {\n      if (__DEV__) {\n        console.warn(\"VideoDataService.getCommentCount failed\", error);\n      }\n      return 0;\n    }\n  }\n\n  /**\n   * Track video interaction events for analytics with consent checking.\n   *\n   * Supports both `trackVideoEvent(videoId, event)` and\n   * `trackVideoEvent(eventType, metadataWithConfessionId)` call patterns for backwards compatibility.\n   */\n  static async trackVideoEvent(\n    arg1: string,\n    arg2: Omit<VideoEvent, \"sessionId\"> | Record<string, unknown>,\n  ): Promise<void> {\n    if (!arg1 || !arg2) return;\n\n    // Handle legacy signature where the event type is passed first and metadata second\n    if (!(\"type\" in arg2)) {\n      const metadata = {\n        ...(arg2 as Record<string, unknown> & {\n          confession_id?: unknown;\n          videoId?: unknown;\n          timestamp?: unknown;\n        }),\n      };\n\n      const possibleId = metadata.confession_id ?? metadata.videoId;\n      const videoId = typeof possibleId === \"string\" && possibleId.length > 0 ? possibleId : undefined;\n      const timestampValue = typeof metadata.timestamp === \"number\" ? (metadata.timestamp as number) : Date.now();\n\n      if (!videoId) {\n        if (__DEV__) {\n          console.warn(\n            `[VideoDataService] trackVideoEvent missing videoId in metadata for event '${arg1}'. Event ignored.`,\n          );\n        }\n        return;\n      }\n\n      delete metadata.timestamp;\n\n      const event: Omit<VideoEvent, \"sessionId\"> = {\n        type: arg1 as VideoEvent[\"type\"],\n        timestamp: timestampValue,\n        metadata,\n      };\n\n      await VideoDataService.trackVideoEventInternal(videoId, event);\n      return;\n    }\n\n    await VideoDataService.trackVideoEventInternal(arg1, arg2 as Omit<VideoEvent, \"sessionId\">);\n  }\n\n  private static async trackVideoEventInternal(videoId: string, event: Omit<VideoEvent, \"sessionId\">): Promise<void> {\n    if (!videoId || !event) return;\n\n    const consentState = useConsentStore.getState();\n    if (!consentState.preferences?.analytics) {\n      return;\n    }\n\n    const sessionId = VideoDataService.getOrCreateSession(videoId);\n    const fullEvent: VideoEvent = {\n      ...event,\n      sessionId,\n      metadata: { ...(event.metadata || {}), videoId },\n    };\n\n    const events = eventQueue.get(videoId) || [];\n    events.push(fullEvent);\n    eventQueue.set(videoId, events);\n\n    const session = activeSessions.get(sessionId);\n    if (session) {\n      session.events.push(fullEvent);\n      await VideoDataService.persistSessionToStorage(session);\n    }\n\n    await VideoDataService.persistEventToStorage(videoId, fullEvent);\n\n    switch (event.type) {\n      case \"play\":\n      case \"resume\":\n        VideoDataService.startWatchTimeTracking(videoId);\n        break;\n      case \"pause\":\n      case \"complete\":\n      case \"session_end\": {\n        const delta = VideoDataService.stopWatchTimeTracking(videoId);\n        if (session) {\n          session.watchTime += delta;\n          await VideoDataService.persistSessionToStorage(session);\n        }\n        break;\n      }\n      case \"buffer_start\":\n        VideoDataService.trackBufferingStart(videoId);\n        break;\n      case \"buffer_end\":\n        VideoDataService.trackBufferingEnd(videoId);\n        break;\n    }\n\n    if (events.length >= 10) {\n      await VideoDataService.processEventQueue(videoId);\n    }\n\n    if (!batchUploadTimer) {\n      batchUploadTimer = setTimeout(() => {\n        VideoDataService.batchUploadEvents();\n      }, BATCH_UPLOAD_INTERVAL);\n    }\n  }\n\n  /**\n   * Process queued events for a video with offline support.\n   */\n  static async processEventQueue(videoId: string): Promise<void> {\n    const events = eventQueue.get(videoId);\n    if (!events || events.length === 0) return;\n\n    eventQueue.delete(videoId);\n\n    try {\n      // Check consent before processing\n      const consentStore = useConsentStore.getState();\n      if (!consentStore.preferences?.analytics) {\n        return;\n      }\n\n      // Calculate aggregated metrics\n      const session = activeSessions.get(events[0]?.sessionId);\n      if (session) {\n        const metrics = VideoDataService.calculateSessionMetrics(session);\n\n        // Update analytics cache\n        VideoDataService.updateAnalyticsCache(videoId, {\n          sessionId: session.sessionId,\n          watchTime: metrics.watchTime,\n          completionRate: metrics.completionRate,\n          engagementScore: metrics.engagementScore,\n          bufferingEvents: metrics.bufferingEvents,\n          seekCount: metrics.seekCount,\n          averageViewDuration: metrics.averageViewDuration,\n          sessionStartTime: session.startTime,\n          sessionEndTime: session.endTime,\n          lastWatchedPosition: metrics.lastPosition,\n        });\n      }\n\n      // Queue for upload via offline queue\n      await offlineQueue.enqueue(\"video.analytics.batch\", {\n        videoId,\n        events,\n        sessionId: events[0]?.sessionId,\n        timestamp: Date.now(),\n      });\n    } catch (error) {\n      console.error(\"Failed to process video events\", error);\n      // Re-add events to queue for retry\n      const existingEvents = eventQueue.get(videoId) || [];\n      eventQueue.set(videoId, [...events, ...existingEvents]);\n    }\n  }\n\n  /**\n   * Get cached analytics for a video.\n   */\n  static getCachedAnalytics(videoId: string): VideoAnalytics | null {\n    const entry = analyticsCache.get(videoId);\n    if (!entry) return null;\n\n    const age = Date.now() - entry.timestamp;\n    if (age > CACHE_TTL_MS) {\n      analyticsCache.delete(videoId);\n      return null;\n    }\n\n    return entry.data;\n  }\n\n  /**\n   * Update analytics cache with comprehensive metrics.\n   */\n  static updateAnalyticsCache(videoId: string, analytics: Partial<VideoAnalytics>): void {\n    const existing = VideoDataService.getCachedAnalytics(videoId);\n    const updated: VideoAnalytics = {\n      videoId,\n      sessionId: analytics.sessionId ?? existing?.sessionId ?? generateUUID(),\n      watchTime: analytics.watchTime ?? existing?.watchTime ?? 0,\n      completionRate: analytics.completionRate ?? existing?.completionRate ?? 0,\n      engagementScore: analytics.engagementScore ?? existing?.engagementScore ?? 0,\n      interactions: {\n        likes: analytics.interactions?.likes ?? existing?.interactions?.likes ?? 0,\n        comments: analytics.interactions?.comments ?? existing?.interactions?.comments ?? 0,\n        shares: analytics.interactions?.shares ?? existing?.interactions?.shares ?? 0,\n        saves: analytics.interactions?.saves ?? existing?.interactions?.saves ?? 0,\n      },\n      qualityStats: analytics.qualityStats ?? existing?.qualityStats,\n      bufferingEvents: analytics.bufferingEvents ?? existing?.bufferingEvents ?? 0,\n      seekCount: analytics.seekCount ?? existing?.seekCount ?? 0,\n      averageViewDuration: analytics.averageViewDuration ?? existing?.averageViewDuration ?? 0,\n      sessionStartTime: analytics.sessionStartTime ?? existing?.sessionStartTime ?? Date.now(),\n      sessionEndTime: analytics.sessionEndTime ?? existing?.sessionEndTime,\n      lastWatchedPosition: analytics.lastWatchedPosition ?? existing?.lastWatchedPosition ?? 0,\n    };\n\n    analyticsCache.set(videoId, { data: updated, timestamp: Date.now() });\n\n    // Persist to AsyncStorage for offline support\n    VideoDataService.persistAnalyticsToStorage(videoId, updated);\n  }\n\n  /**\n   * Batch update video metrics. Falls back to individual updates if the batch RPC fails.\n   */\n  static async updateVideoMetricsBatch(updates: VideoMetricUpdate[]): Promise<{ success: string[]; failed: string[] }> {\n    const normalized = updates.filter((update) => update && update.videoId);\n    if (!normalized.length) {\n      return { success: [], failed: [] };\n    }\n\n    const success: string[] = [];\n    const failed: string[] = [];\n\n    for (const update of normalized) {\n      try {\n        if (typeof update.viewsDelta === \"number\" && update.viewsDelta > 0) {\n          const iterations = Math.max(1, Math.floor(update.viewsDelta));\n          for (let index = 0; index < iterations; index += 1) {\n            await VideoDataService.updateVideoViews(update.videoId);\n          }\n        }\n\n        if (typeof update.likesDelta === \"number\" && update.likesDelta !== 0) {\n          const increment = update.likesDelta > 0;\n          const likeResult = await VideoDataService.updateVideoLikes(update.videoId, increment);\n          if (likeResult === null) {\n            throw new Error(\"Unable to update like state\");\n          }\n        }\n\n        success.push(update.videoId);\n      } catch (error) {\n        failed.push(update.videoId);\n      }\n    }\n\n    if (success.length) {\n      invalidateCacheByPrefix(VIDEO_CONFESSIONS_PREFIX);\n      invalidateCacheByPrefix(TRENDING_VIDEOS_PREFIX);\n    }\n\n    return { success, failed };\n  }\n\n  /**\n   * Track video completion event with configurable threshold.\n   */\n  static async trackVideoCompletion(videoId: string, watchTime: number, duration: number): Promise<void> {\n    const completionRate = duration > 0 ? watchTime / duration : 0;\n    const isCompleted = completionRate >= COMPLETION_THRESHOLD;\n\n    await VideoDataService.trackVideoEvent(videoId, {\n      type: isCompleted ? \"complete\" : \"pause\",\n      timestamp: Date.now(),\n      metadata: {\n        watchTime,\n        duration,\n        completionRate: completionRate * 100,\n        threshold: COMPLETION_THRESHOLD * 100,\n        isCompleted,\n      },\n    });\n\n    // Calculate engagement score\n    const engagementScore = VideoDataService.calculateEngagementScore({\n      completionRate,\n      watchTime,\n      interactions: VideoDataService.getCachedAnalytics(videoId)?.interactions,\n    });\n\n    VideoDataService.updateAnalyticsCache(videoId, {\n      watchTime,\n      completionRate: completionRate * 100,\n      engagementScore,\n    });\n\n    // End session if completed\n    if (isCompleted) {\n      const sessionId = VideoDataService.getCurrentSessionId(videoId);\n      if (sessionId) {\n        VideoDataService.endSession(sessionId);\n      }\n    }\n  }\n\n  /**\n   * Flush all pending analytics events.\n   */\n  static async flushAllEvents(): Promise<void> {\n    const promises: Promise<void>[] = [];\n    for (const videoId of eventQueue.keys()) {\n      promises.push(VideoDataService.processEventQueue(videoId));\n    }\n    await Promise.all(promises);\n  }\n\n  /**\n   * Intelligent preloading based on device capabilities and network conditions.\n   */\n  static async intelligentPreload(confessions: Confession[]): Promise<void> {\n    try {\n      const preloadProfile = videoPerformanceConfig.getPreloadProfile();\n      const videoUris = confessions\n        .slice(0, preloadProfile.preloadWindowSize)\n        .map((c) => (c as any).videoUri)\n        .filter(Boolean);\n\n      if (videoUris.length > 0) {\n        // Use device-aware preloading from cache manager\n        await videoCacheManager.preloadVideos(videoUris, \"normal\");\n      }\n    } catch (error) {\n      console.error(\"Intelligent preload failed:\", error);\n    }\n  }\n\n  /**\n   * Aggressive preloading for high-tier devices.\n   */\n  static async aggressivePreload(confessions: Confession[]): Promise<void> {\n    if (!videoPerformanceConfig.shouldEnableFeature(\"aggressivePreloading\")) {\n      return VideoDataService.intelligentPreload(confessions);\n    }\n\n    try {\n      const videoUris = confessions\n        .slice(0, 15) // Preload more videos for high-tier devices\n        .map((c) => (c as any).videoUri)\n        .filter(Boolean);\n\n      if (videoUris.length > 0) {\n        await videoCacheManager.preloadVideos(videoUris, \"high\");\n      }\n    } catch (error) {\n      console.error(\"Aggressive preload failed:\", error);\n    }\n  }\n\n  /**\n   * Optimize quality selection in background for cached videos.\n   */\n  static async optimizeQualityInBackground(confessions: Confession[]): Promise<void> {\n    try {\n      const { videoBackgroundQueue, JobType, JobPriority } = await import(\"./VideoBackgroundQueue\");\n\n      const videoUris = confessions\n        .slice(0, 5)\n        .map((c) => (c as any).videoUri)\n        .filter(Boolean);\n\n      // Enqueue quality optimization job\n      await videoBackgroundQueue.enqueueJob(\n        JobType.QUALITY_VARIANT_GENERATION,\n        {\n          videoUris,\n          batchOptimization: true,\n        },\n        JobPriority.LOW,\n        {\n          onComplete: async (result) => {\n            if (result.success) {\n              // Batch select qualities\n              await videoQualitySelector.selectBatchVideoQualities(videoUris);\n            }\n          },\n        },\n      );\n    } catch (error) {\n      console.error(\"Failed to enqueue background quality optimization:\", error);\n    }\n  }\n\n  /**\n   * Check if quality upgrade is available for current network conditions.\n   */\n  static async checkQualityUpgrade(videoUri: string): Promise<boolean> {\n    try {\n      return await videoQualitySelector.canUpgradeQuality(videoUri);\n    } catch (error) {\n      console.error(\"Quality upgrade check failed:\", error);\n      return false;\n    }\n  }\n\n  /**\n   * Get performance-optimized batch size for operations.\n   */\n  static async getOptimizedBatchSize(): Promise<number> {\n    const deviceTier = await getDeviceTier();\n    const batchSizes = {\n      [DevicePerformanceTier.HIGH]: 20,\n      [DevicePerformanceTier.MID]: 10,\n      [DevicePerformanceTier.LOW]: 5,\n    };\n    return batchSizes[deviceTier];\n  }\n\n  /**\n   * Generate or retrieve session ID for a video.\n   */\n  static getOrCreateSession(videoId: string): string {\n    // Check if active session exists\n    for (const [sessionId, session] of activeSessions.entries()) {\n      if (session.videoId === videoId && session.isActive) {\n        return sessionId;\n      }\n    }\n\n    // Create new session\n    const sessionId = generateUUID();\n    const session: VideoSession = {\n      sessionId,\n      videoId,\n      startTime: Date.now(),\n      watchTime: 0,\n      events: [],\n      isActive: true,\n    };\n    activeSessions.set(sessionId, session);\n\n    // Persist session\n    VideoDataService.persistSessionToStorage(session);\n\n    return sessionId;\n  }\n\n  /**\n   * Get current session ID for a video.\n   */\n  static getCurrentSessionId(videoId: string): string | null {\n    for (const [sessionId, session] of activeSessions.entries()) {\n      if (session.videoId === videoId && session.isActive) {\n        return sessionId;\n      }\n    }\n    return null;\n  }\n\n  /**\n   * End a video session.\n   */\n  static endSession(sessionId: string): void {\n    const session = activeSessions.get(sessionId);\n    if (session) {\n      session.isActive = false;\n      session.endTime = Date.now();\n      VideoDataService.persistSessionToStorage(session);\n    }\n  }\n\n  /**\n   * Start watch time tracking.\n   */\n  static startWatchTimeTracking(videoId: string): void {\n    const tracker = watchTimeTrackers.get(videoId) || { startTime: Date.now(), totalTime: 0 };\n    tracker.startTime = Date.now();\n    watchTimeTrackers.set(videoId, tracker);\n  }\n\n  /**\n   * Stop watch time tracking.\n   */\n  static stopWatchTimeTracking(videoId: string): number {\n    const tracker = watchTimeTrackers.get(videoId);\n    if (tracker && tracker.startTime > 0) {\n      const elapsed = (Date.now() - tracker.startTime) / 1000; // Convert to seconds\n      tracker.totalTime += elapsed;\n      tracker.startTime = 0;\n      watchTimeTrackers.set(videoId, tracker);\n      return tracker.totalTime;\n    }\n    return 0;\n  }\n\n  /**\n   * Track buffering start.\n   */\n  private static bufferingStartTimes = new Map<string, number>();\n\n  static trackBufferingStart(videoId: string): void {\n    VideoDataService.bufferingStartTimes.set(videoId, Date.now());\n  }\n\n  /**\n   * Track buffering end.\n   */\n  static trackBufferingEnd(videoId: string): void {\n    const startTime = VideoDataService.bufferingStartTimes.get(videoId);\n    if (startTime) {\n      const bufferTime = Date.now() - startTime;\n      VideoDataService.bufferingStartTimes.delete(videoId);\n\n      const analytics = VideoDataService.getCachedAnalytics(videoId);\n      if (analytics) {\n        const currentBufferTime = analytics.qualityStats?.bufferingTime || 0;\n        VideoDataService.updateAnalyticsCache(videoId, {\n          qualityStats: {\n            ...analytics.qualityStats,\n            bufferingTime: currentBufferTime + bufferTime,\n          } as any,\n          bufferingEvents: (analytics.bufferingEvents || 0) + 1,\n        });\n      }\n    }\n  }\n\n  /**\n   * Calculate engagement score based on multiple factors.\n   */\n  static calculateEngagementScore(metrics: {\n    completionRate: number;\n    watchTime: number;\n    interactions?: VideoAnalytics[\"interactions\"];\n  }): number {\n    const completionWeight = 0.4;\n    const watchTimeWeight = 0.3;\n    const interactionWeight = 0.3;\n\n    const completionScore = Math.min(metrics.completionRate, 1) * 100;\n    const watchTimeScore = Math.min(metrics.watchTime / 300, 1) * 100; // Normalize to 5 minutes\n    const interactionScore = Math.min(\n      ((metrics.interactions?.likes || 0) * 10 +\n        (metrics.interactions?.comments || 0) * 20 +\n        (metrics.interactions?.shares || 0) * 30 +\n        (metrics.interactions?.saves || 0) * 15) /\n        100,\n      100,\n    );\n\n    return Math.round(\n      completionScore * completionWeight + watchTimeScore * watchTimeWeight + interactionScore * interactionWeight,\n    );\n  }\n\n  /**\n   * Calculate session metrics.\n   */\n  static calculateSessionMetrics(session: VideoSession): {\n    watchTime: number;\n    completionRate: number;\n    engagementScore: number;\n    bufferingEvents: number;\n    seekCount: number;\n    averageViewDuration: number;\n    lastPosition: number;\n  } {\n    const seekEvents = session.events.filter((e) => e.type === \"seek\").length;\n    const bufferEvents = session.events.filter((e) => e.type === \"buffer_start\").length;\n    const playEvents = session.events.filter((e) => e.type === \"play\" || e.type === \"resume\");\n\n    const watchTime = session.watchTime || 0;\n    const duration = session.events.find((e) => e.metadata?.duration)?.metadata?.duration || 0;\n    const completionRate = duration > 0 ? (watchTime / duration) * 100 : 0;\n\n    const lastPositionEvent = [...session.events].reverse().find((e) => e.metadata?.position !== undefined);\n    const lastPosition = lastPositionEvent?.metadata?.position || 0;\n\n    const engagementScore = VideoDataService.calculateEngagementScore({\n      completionRate: completionRate / 100,\n      watchTime,\n    });\n\n    return {\n      watchTime,\n      completionRate,\n      engagementScore,\n      bufferingEvents: bufferEvents,\n      seekCount: seekEvents,\n      averageViewDuration: playEvents.length > 0 ? watchTime / playEvents.length : 0,\n      lastPosition,\n    };\n  }\n\n  /**\n   * Persist event to AsyncStorage.\n   */\n  static async persistEventToStorage(videoId: string, event: VideoEvent): Promise<void> {\n    try {\n      const key = `${EVENT_QUEUE_KEY}_${videoId}`;\n      const stored = await AsyncStorage.getItem(key);\n      const events = stored ? JSON.parse(stored) : [];\n      events.push(event);\n\n      // Limit stored events to prevent storage bloat\n      if (events.length > 100) {\n        events.splice(0, events.length - 100);\n      }\n\n      await AsyncStorage.setItem(key, JSON.stringify(events));\n    } catch (error) {\n      console.error(\"Failed to persist event to storage:\", error);\n    }\n  }\n\n  /**\n   * Persist session to AsyncStorage.\n   */\n  static async persistSessionToStorage(session: VideoSession): Promise<void> {\n    try {\n      const stored = await AsyncStorage.getItem(SESSIONS_KEY);\n      const sessions = stored ? JSON.parse(stored) : {};\n      sessions[session.sessionId] = session;\n\n      // Clean up old sessions (keep last 50)\n      const sessionKeys = Object.keys(sessions);\n      if (sessionKeys.length > 50) {\n        const sortedKeys = sessionKeys.sort((a, b) => (sessions[b].startTime || 0) - (sessions[a].startTime || 0));\n        sortedKeys.slice(50).forEach((key) => delete sessions[key]);\n      }\n\n      await AsyncStorage.setItem(SESSIONS_KEY, JSON.stringify(sessions));\n    } catch (error) {\n      console.error(\"Failed to persist session to storage:\", error);\n    }\n  }\n\n  /**\n   * Persist analytics to AsyncStorage.\n   */\n  static async persistAnalyticsToStorage(videoId: string, analytics: VideoAnalytics): Promise<void> {\n    try {\n      const key = `${ANALYTICS_CACHE_PREFIX}_${videoId}`;\n      await AsyncStorage.setItem(key, JSON.stringify(analytics));\n    } catch (error) {\n      console.error(\"Failed to persist analytics to storage:\", error);\n    }\n  }\n\n  /**\n   * Load persisted events from storage.\n   */\n  static async loadPersistedEvents(): Promise<void> {\n    try {\n      const keys = await AsyncStorage.getAllKeys();\n      const eventKeys = keys.filter((k) => k.startsWith(EVENT_QUEUE_KEY));\n\n      for (const key of eventKeys) {\n        const videoId = key.replace(`${EVENT_QUEUE_KEY}_`, \"\");\n        const stored = await AsyncStorage.getItem(key);\n        if (stored) {\n          const events = JSON.parse(stored);\n          eventQueue.set(videoId, events);\n        }\n      }\n    } catch (error) {\n      console.error(\"Failed to load persisted events:\", error);\n    }\n  }\n\n  /**\n   * Clear persisted events for specific video IDs.\n   */\n  static async clearPersistedEvents(videoIds: string[]): Promise<void> {\n    try {\n      const keys = videoIds.map((id) => `${EVENT_QUEUE_KEY}_${id}`);\n      await AsyncStorage.multiRemove(keys);\n\n      // Also clear from in-memory queue\n      videoIds.forEach((id) => eventQueue.delete(id));\n    } catch (error) {\n      console.error(\"Failed to clear persisted events:\", error);\n    }\n  }\n\n  /**\n   * Batch upload analytics events.\n   */\n  static async batchUploadEvents(): Promise<void> {\n    batchUploadTimer = null;\n\n    const consentStore = useConsentStore.getState();\n    if (!consentStore.preferences?.analytics) {\n      return;\n    }\n\n    const allEvents: { videoId: string; events: VideoEvent[] }[] = [];\n\n    for (const [videoId, events] of eventQueue.entries()) {\n      if (events.length > 0) {\n        allEvents.push({ videoId, events: [...events] });\n        eventQueue.delete(videoId);\n      }\n    }\n\n    if (allEvents.length === 0) return;\n\n    try {\n      // Batch events by session\n      const sessionBatches = new Map<string, VideoEvent[]>();\n      allEvents.forEach(({ events }) => {\n        events.forEach((event) => {\n          const batch = sessionBatches.get(event.sessionId) || [];\n          batch.push(event);\n          sessionBatches.set(event.sessionId, batch);\n        });\n      });\n\n      // Upload each session batch\n      for (const [sessionId, events] of sessionBatches.entries()) {\n        await offlineQueue.enqueue(\"video.analytics.batch\", {\n          sessionId,\n          events: events.slice(0, BATCH_SIZE),\n          timestamp: Date.now(),\n        });\n      }\n    } catch (error) {\n      console.error(\"Failed to batch upload events:\", error);\n      // Re-add events to queue\n      allEvents.forEach(({ videoId, events }) => {\n        const existing = eventQueue.get(videoId) || [];\n        eventQueue.set(videoId, [...existing, ...events]);\n      });\n    }\n  }\n\n  /**\n   * Get video engagement summary for dashboard.\n   */\n  static async getVideoEngagementSummary(\n    period: \"day\" | \"week\" | \"month\" = \"week\",\n  ): Promise<VideoEngagementSummary | null> {\n    try {\n      // Simplified implementation - get basic video stats\n      const hoursBack = period === \"day\" ? 24 : period === \"week\" ? 168 : 720;\n\n      const { data: videos, error } = await supabase\n        .from(\"confessions\")\n        .select(\"id, likes, views, created_at\")\n        .eq(\"type\", \"video\")\n        .gte(\"created_at\", new Date(Date.now() - hoursBack * 60 * 60 * 1000).toISOString());\n\n      if (error) throw error;\n\n      const totalVideos = videos?.length || 0;\n      const totalViews = videos?.reduce((sum, v) => sum + (v.views || 0), 0) || 0;\n      const totalLikes = videos?.reduce((sum, v) => sum + (v.likes || 0), 0) || 0;\n\n      return {\n        totalVideos,\n        totalViews,\n        totalLikes,\n        averageEngagement: totalVideos > 0 ? (totalLikes / totalViews) * 100 : 0,\n        totalWatchTime: 0, // Would need analytics tracking\n        averageWatchTime: 0, // Would need analytics tracking\n        averageCompletionRate: 0, // Would need analytics tracking\n        uniqueViewers: totalViews, // Simplified\n        topPerformingVideos: [], // Would need more complex query\n        engagementTrends: [], // Would need time-series data\n        engagementRate: totalViews > 0 ? (totalLikes / totalViews) * 100 : 0,\n        topVideos: [], // Would need more complex query\n        timeDistribution: [], // Would need time-series data\n        period,\n      } as VideoEngagementSummary;\n    } catch (error) {\n      console.error(\"Failed to fetch video engagement summary:\", error);\n      return null;\n    }\n  }\n\n  /**\n   * Get watch time analytics.\n   */\n  static async getWatchTimeAnalytics(videoId?: string): Promise<{\n    totalWatchTime: number;\n    averageWatchTime: number;\n    sessions: number;\n  } | null> {\n    try {\n      // Simplified implementation - would need proper analytics tracking\n      if (!videoId) return null;\n\n      const session = activeSessions.get(videoId);\n      const watchTracker = watchTimeTrackers.get(videoId);\n\n      return {\n        totalWatchTime: watchTracker?.totalTime || 0,\n        averageWatchTime: watchTracker?.totalTime || 0,\n        sessions: session ? 1 : 0,\n      };\n    } catch (error) {\n      console.error(\"Failed to fetch watch time analytics:\", error);\n      return null;\n    }\n  }\n\n  /**\n   * Get completion rate statistics.\n   */\n  static async getCompletionRateStats(): Promise<{\n    averageCompletionRate: number;\n    completedVideos: number;\n    totalVideos: number;\n  } | null> {\n    try {\n      // Simplified implementation - would need proper analytics tracking\n      const { data: videos, error } = await supabase.from(\"confessions\").select(\"id, views\").eq(\"type\", \"video\");\n\n      if (error) throw error;\n\n      const totalVideos = videos?.length || 0;\n      // Simplified completion rate calculation\n      const completedVideos = Math.floor(totalVideos * 0.7); // Assume 70% completion rate\n\n      return {\n        averageCompletionRate: totalVideos > 0 ? (completedVideos / totalVideos) * 100 : 0,\n        completedVideos,\n        totalVideos,\n      };\n    } catch (error) {\n      console.error(\"Failed to fetch completion rate stats:\", error);\n      return null;\n    }\n  }\n\n  /**\n   * Initialize app state monitoring.\n   */\n  static initializeAppStateMonitoring(): void {\n    AppState.addEventListener(\"change\", (nextAppState: AppStateStatus) => {\n      if (appState === \"active\" && nextAppState.match(/inactive|background/)) {\n        // App going to background - pause all tracking\n        for (const videoId of watchTimeTrackers.keys()) {\n          VideoDataService.stopWatchTimeTracking(videoId);\n        }\n        // Flush events\n        VideoDataService.batchUploadEvents();\n      } else if (appState.match(/inactive|background/) && nextAppState === \"active\") {\n        // App coming to foreground - load persisted events\n        VideoDataService.loadPersistedEvents();\n      }\n      appState = nextAppState;\n    });\n  }\n\n  /**\n   * Clean up resources on unmount.\n   */\n  static cleanup(): void {\n    // Clear quality selection cache\n    qualitySelectionCache.clear();\n\n    // Stop batch upload timer\n    if (batchUploadTimer) {\n      clearTimeout(batchUploadTimer);\n      batchUploadTimer = null;\n    }\n\n    // End all active sessions\n    for (const [sessionId, session] of activeSessions.entries()) {\n      if (session.isActive) {\n        VideoDataService.endSession(sessionId);\n      }\n    }\n\n    // Flush any pending events\n    VideoDataService.flushAllEvents();\n  }\n}\n\n// Initialize app state monitoring on module load\nVideoDataService.initializeAppStateMonitoring();\n// Load persisted events on startup\nVideoDataService.loadPersistedEvents();\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/VideoErrorRecoveryService.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'VideoLoadError' is defined but never used.","line":5,"column":3,"nodeType":null,"messageId":"unusedVar","endLine":5,"endColumn":17},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'VideoNetworkError' is defined but never used.","line":6,"column":3,"nodeType":null,"messageId":"unusedVar","endLine":6,"endColumn":20},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'VideoPlaybackError' is defined but never used.","line":7,"column":3,"nodeType":null,"messageId":"unusedVar","endLine":7,"endColumn":21},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'RetryConfig' is defined but never used.","line":20,"column":36,"nodeType":null,"messageId":"unusedVar","endLine":20,"endColumn":47},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'RetryResult' is defined but never used.","line":20,"column":49,"nodeType":null,"messageId":"unusedVar","endLine":20,"endColumn":60}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import {\n  BaseVideoError,\n  VideoErrorCode,\n  VideoErrorSeverity,\n  VideoLoadError,\n  VideoNetworkError,\n  VideoPlaybackError,\n} from \"../types/videoErrors\";\nimport {\n  createErrorRecoveryStrategy,\n  ErrorRecoveryStrategy,\n  ErrorContext,\n  isRecoverableError,\n  extractErrorContext,\n  getRecoverySuggestions,\n  errorRateLimiter,\n  errorCorrelator,\n  analyzeErrorPatterns,\n} from \"../utils/videoErrors\";\nimport { createRetryableOperation, RetryConfig, RetryResult } from \"../utils/retryLogic\";\nimport { VideoDataService } from \"./VideoDataService\";\nimport { isOnline } from \"../lib/offlineQueue\";\n\n// Recovery policies configuration\nexport interface RecoveryPolicy {\n  errorCode: VideoErrorCode;\n  maxRetries: number;\n  backoffStrategy: \"exponential\" | \"linear\" | \"fixed\";\n  cooldownPeriod: number;\n  fallbackEnabled: boolean;\n  userNotificationThreshold: number;\n}\n\n// Fallback video source management\nexport interface FallbackSource {\n  url: string;\n  quality: \"high\" | \"medium\" | \"low\";\n  isLocal: boolean;\n  priority: number;\n}\n\n// Recovery result tracking\nexport interface RecoveryResult {\n  success: boolean;\n  errorCode: VideoErrorCode;\n  recoveryStrategy: ErrorRecoveryStrategy;\n  attemptCount: number;\n  duration: number;\n  timestamp: number; // Comment 4: Added timestamp field\n  fallbackUsed: boolean;\n  userNotified: boolean;\n}\n\n// Circuit breaker state for different error types\ninterface CircuitBreakerState {\n  errorCode: VideoErrorCode;\n  state: \"closed\" | \"open\" | \"half-open\";\n  failureCount: number;\n  lastFailureTime: number;\n  successCount: number;\n  nextRetryTime: number;\n}\n\n// Error queue for batch processing\ninterface QueuedError {\n  error: BaseVideoError;\n  context: ErrorContext;\n  timestamp: number;\n  retryCount: number;\n  priority: number;\n}\n\n// Service configuration\nexport interface VideoErrorRecoveryConfig {\n  enableAutoRecovery: boolean;\n  enableFallbacks: boolean;\n  enableUserNotifications: boolean;\n  enableAnalytics: boolean;\n  maxConcurrentRecoveries: number;\n  recoveryTimeout: number;\n  circuitBreakerThreshold: number;\n  circuitBreakerTimeout: number;\n}\n\n/**\n * Comprehensive video error recovery service\n */\nexport class VideoErrorRecoveryService {\n  private static instance: VideoErrorRecoveryService;\n\n  private config: VideoErrorRecoveryConfig;\n  private recoveryPolicies: Map<VideoErrorCode, RecoveryPolicy>;\n  private fallbackSources: FallbackSource[];\n  private circuitBreakers: Map<VideoErrorCode, CircuitBreakerState>;\n  private errorQueue: QueuedError[];\n  private activeRecoveries: Map<string, Promise<RecoveryResult>>;\n  private recoveryHistory: RecoveryResult[];\n  private isProcessing: boolean;\n  private offlineQueue: BaseVideoError[];\n\n  private constructor(config?: Partial<VideoErrorRecoveryConfig>) {\n    this.config = {\n      enableAutoRecovery: true,\n      enableFallbacks: true,\n      enableUserNotifications: true,\n      enableAnalytics: true,\n      maxConcurrentRecoveries: 3,\n      recoveryTimeout: 30000,\n      circuitBreakerThreshold: 5,\n      circuitBreakerTimeout: 60000,\n      ...config,\n    };\n\n    this.recoveryPolicies = this.initializeDefaultPolicies();\n    this.fallbackSources = this.initializeDefaultFallbacks();\n    this.circuitBreakers = new Map();\n    this.errorQueue = [];\n    this.activeRecoveries = new Map();\n    this.recoveryHistory = [];\n    this.isProcessing = false;\n    this.offlineQueue = [];\n\n    // Start queue processor\n    this.startQueueProcessor();\n\n    // Monitor network status\n    this.monitorNetworkStatus();\n  }\n\n  /**\n   * Get singleton instance\n   */\n  static getInstance(config?: Partial<VideoErrorRecoveryConfig>): VideoErrorRecoveryService {\n    if (!VideoErrorRecoveryService.instance) {\n      VideoErrorRecoveryService.instance = new VideoErrorRecoveryService(config);\n    }\n    return VideoErrorRecoveryService.instance;\n  }\n\n  /**\n   * Handle video error with automatic recovery\n   */\n  async handleError(error: BaseVideoError, context?: Partial<ErrorContext>): Promise<RecoveryResult> {\n    const startTime = Date.now();\n    const fullContext = {\n      ...extractErrorContext(error),\n      ...context,\n    };\n\n    // Record error for correlation analysis\n    errorCorrelator.recordError(error.code);\n\n    // Check rate limiting\n    const errorKey = `${error.code}_${fullContext.videoId || \"unknown\"}`;\n    if (!errorRateLimiter.shouldReportError(errorKey)) {\n      return this.createRecoveryResult(false, error.code, \"none\", 0, Date.now() - startTime);\n    }\n\n    // Check circuit breaker\n    const breaker = this.getOrCreateCircuitBreaker(error.code);\n    if (breaker.state === \"open\") {\n      if (Date.now() < breaker.nextRetryTime) {\n        return this.createRecoveryResult(false, error.code, \"none\", 0, Date.now() - startTime);\n      }\n      // Move to half-open state\n      breaker.state = \"half-open\";\n    }\n\n    // Check if error is recoverable\n    if (!isRecoverableError(error)) {\n      this.handleUnrecoverableError(error, fullContext);\n      return this.createRecoveryResult(false, error.code, \"manual\", 0, Date.now() - startTime);\n    }\n\n    // Create recovery strategy\n    const strategy = createErrorRecoveryStrategy(error, fullContext);\n\n    // Queue or process immediately based on strategy\n    if (strategy.type === \"immediate\") {\n      return this.processRecovery(error, fullContext, strategy);\n    } else {\n      this.queueError(error, fullContext, strategy);\n      return this.createRecoveryResult(false, error.code, strategy.type, 0, Date.now() - startTime);\n    }\n  }\n\n  /**\n   * Process recovery for an error\n   */\n  private async processRecovery(\n    error: BaseVideoError,\n    context: ErrorContext,\n    strategy: ErrorRecoveryStrategy,\n  ): Promise<RecoveryResult> {\n    const startTime = Date.now();\n    const recoveryKey = `${error.code}_${context.videoId || Date.now()}`;\n\n    // Check if already recovering\n    const existingRecovery = this.activeRecoveries.get(recoveryKey);\n    if (existingRecovery) {\n      return existingRecovery;\n    }\n\n    // Create recovery promise\n    const recoveryPromise = this.executeRecovery(error, context, strategy, startTime);\n    this.activeRecoveries.set(recoveryKey, recoveryPromise);\n\n    try {\n      const result = await recoveryPromise;\n      this.updateCircuitBreaker(error.code, result.success);\n      this.recordRecoveryResult(result);\n      return result;\n    } finally {\n      this.activeRecoveries.delete(recoveryKey);\n    }\n  }\n\n  /**\n   * Execute recovery strategy\n   */\n  private async executeRecovery(\n    error: BaseVideoError,\n    context: ErrorContext,\n    strategy: ErrorRecoveryStrategy,\n    startTime: number,\n  ): Promise<RecoveryResult> {\n    const policy = this.recoveryPolicies.get(error.code);\n    let attemptCount = 0;\n    let success = false;\n    let fallbackUsed = false;\n\n    // Implement retry logic if configured\n    if (strategy.retryConfig && policy) {\n      try {\n        const result = await Promise.race([\n          createRetryableOperation(async () => {\n            attemptCount++;\n            return this.attemptRecovery(error, context);\n          }, strategy.retryConfig),\n          this.timeout(this.config.recoveryTimeout),\n        ]);\n\n        success = result.success;\n      } catch (retryError) {\n        console.warn(`Recovery failed after retries: ${retryError}`);\n      }\n    }\n\n    // Attempt fallback if primary recovery failed\n    if (!success && this.config.enableFallbacks && strategy.type === \"fallback\") {\n      try {\n        const fallbackResult = await this.attemptFallback(error, context);\n        success = fallbackResult.success;\n        fallbackUsed = fallbackResult.fallbackUsed;\n      } catch (fallbackError) {\n        console.warn(`Fallback failed: ${fallbackError}`);\n      }\n    }\n\n    // Notify user if necessary\n    const userNotified = this.shouldNotifyUser(error, attemptCount, success);\n    if (userNotified && strategy.userMessage) {\n      this.notifyUser(strategy.userMessage, getRecoverySuggestions(error));\n    }\n\n    return this.createRecoveryResult(\n      success,\n      error.code,\n      strategy.type,\n      attemptCount,\n      Date.now() - startTime,\n      fallbackUsed,\n      userNotified,\n    );\n  }\n\n  /**\n   * Attempt to recover from error\n   */\n  private async attemptRecovery(error: BaseVideoError, context: ErrorContext): Promise<{ success: boolean }> {\n    switch (error.code) {\n      case VideoErrorCode.NETWORK_ERROR:\n      case VideoErrorCode.CONNECTION_FAILED:\n        return this.recoverFromNetworkError(context);\n\n      case VideoErrorCode.LOAD_FAILED:\n        return this.recoverFromLoadError(context);\n\n      case VideoErrorCode.PLAYBACK_STALLED:\n      case VideoErrorCode.BUFFERING_TIMEOUT:\n        return this.recoverFromPlaybackError(context);\n\n      case VideoErrorCode.SOURCE_NOT_FOUND:\n      case VideoErrorCode.SOURCE_INVALID:\n        return this.recoverFromSourceError(context);\n\n      case VideoErrorCode.RATE_LIMITED:\n        return this.recoverFromRateLimit(context);\n\n      default:\n        return { success: false };\n    }\n  }\n\n  /**\n   * Network error recovery\n   */\n  private async recoverFromNetworkError(context: ErrorContext): Promise<{ success: boolean }> {\n    // Wait for network to be available\n    if (!isOnline()) {\n      await this.waitForNetwork();\n    }\n\n    // Retry the operation\n    try {\n      if (context.videoId) {\n        const retryFn = (\n          VideoDataService as unknown as {\n            retryFailedRequest?: (videoId: string) => Promise<void>;\n          }\n        ).retryFailedRequest;\n        if (retryFn) {\n          await retryFn(context.videoId);\n        }\n      }\n      return { success: true };\n    } catch {\n      return { success: false };\n    }\n  }\n\n  /**\n   * Load error recovery\n   */\n  private async recoverFromLoadError(context: ErrorContext): Promise<{ success: boolean }> {\n    try {\n      // Try alternative source\n      if (context.source) {\n        const alternativeSource = await this.findAlternativeSource(context.source);\n        if (alternativeSource) {\n          return { success: true };\n        }\n      }\n\n      // Refresh video data\n      if (context.videoId) {\n        const refreshFn = (\n          VideoDataService as unknown as {\n            refreshVideoData?: (videoId: string) => Promise<void>;\n          }\n        ).refreshVideoData;\n        if (refreshFn) {\n          await refreshFn(context.videoId);\n          return { success: true };\n        }\n      }\n    } catch {\n      // Fall through\n    }\n\n    return { success: false };\n  }\n\n  /**\n   * Playback error recovery\n   */\n  private async recoverFromPlaybackError(context: ErrorContext): Promise<{ success: boolean }> {\n    // Implement progressive quality reduction\n    if (context.source) {\n      const lowerQualitySource = await this.getLowerQualitySource(context.source);\n      if (lowerQualitySource) {\n        return { success: true };\n      }\n    }\n\n    return { success: false };\n  }\n\n  /**\n   * Source error recovery\n   */\n  private async recoverFromSourceError(context: ErrorContext): Promise<{ success: boolean }> {\n    // Find alternative source\n    const fallback = this.getNextFallbackSource();\n    if (fallback) {\n      return { success: true };\n    }\n\n    return { success: false };\n  }\n\n  /**\n   * Rate limit recovery\n   */\n  private async recoverFromRateLimit(context: ErrorContext): Promise<{ success: boolean }> {\n    // Wait for cooldown period\n    const policy = this.recoveryPolicies.get(VideoErrorCode.RATE_LIMITED);\n    if (policy) {\n      await new Promise((resolve) => setTimeout(resolve, policy.cooldownPeriod));\n      return { success: true };\n    }\n\n    return { success: false };\n  }\n\n  /**\n   * Attempt fallback recovery\n   */\n  private async attemptFallback(\n    error: BaseVideoError,\n    context: ErrorContext,\n  ): Promise<{ success: boolean; fallbackUsed: boolean }> {\n    const fallbackSource = this.getNextFallbackSource();\n\n    if (!fallbackSource) {\n      return { success: false, fallbackUsed: false };\n    }\n\n    try {\n      // Load fallback source\n      if (context.videoId) {\n        const fallbackFn = (\n          VideoDataService as unknown as {\n            loadFallbackVideo?: (videoId: string, url: string) => Promise<void>;\n          }\n        ).loadFallbackVideo;\n        if (fallbackFn) {\n          await fallbackFn(context.videoId, fallbackSource.url);\n        }\n      }\n      return { success: true, fallbackUsed: true };\n    } catch {\n      return { success: false, fallbackUsed: true };\n    }\n  }\n\n  /**\n   * Get next available fallback source\n   */\n  private getNextFallbackSource(): FallbackSource | null {\n    // Sort by priority and filter available sources\n    const availableSources = this.fallbackSources\n      .filter((source) => !source.isLocal || isOnline())\n      .sort((a, b) => a.priority - b.priority);\n\n    return availableSources[0] || null;\n  }\n\n  /**\n   * Find alternative video source\n   */\n  private async findAlternativeSource(currentSource: string): Promise<string | null> {\n    // Implementation would check for CDN alternatives, different qualities, etc.\n    return null;\n  }\n\n  /**\n   * Get lower quality source\n   */\n  private async getLowerQualitySource(currentSource: string): Promise<string | null> {\n    // Implementation would return a lower quality version of the video\n    return null;\n  }\n\n  /**\n   * Queue error for delayed processing\n   */\n  private queueError(error: BaseVideoError, context: ErrorContext, strategy: ErrorRecoveryStrategy): void {\n    const priority = this.calculateErrorPriority(error);\n\n    this.errorQueue.push({\n      error,\n      context,\n      timestamp: Date.now(),\n      retryCount: 0,\n      priority,\n    });\n\n    // Sort by priority\n    this.errorQueue.sort((a, b) => b.priority - a.priority);\n\n    // Trigger processing if not already running\n    if (!this.isProcessing) {\n      this.processQueue();\n    }\n  }\n\n  /**\n   * Process error queue\n   */\n  private async processQueue(): Promise<void> {\n    if (this.isProcessing || this.errorQueue.length === 0) {\n      return;\n    }\n\n    this.isProcessing = true;\n\n    while (this.errorQueue.length > 0 && this.activeRecoveries.size < this.config.maxConcurrentRecoveries) {\n      const queuedError = this.errorQueue.shift();\n      if (!queuedError) continue;\n\n      const strategy = createErrorRecoveryStrategy(queuedError.error, queuedError.context);\n      this.processRecovery(queuedError.error, queuedError.context, strategy);\n    }\n\n    this.isProcessing = false;\n  }\n\n  /**\n   * Start queue processor\n   */\n  private startQueueProcessor(): void {\n    setInterval(() => {\n      this.processQueue();\n      this.cleanupOldHistory();\n      this.analyzeAndOptimize();\n    }, 5000);\n  }\n\n  /**\n   * Monitor network status\n   */\n  private monitorNetworkStatus(): void {\n    setInterval(() => {\n      if (isOnline() && this.offlineQueue.length > 0) {\n        this.processOfflineQueue();\n      }\n    }, 10000);\n  }\n\n  /**\n   * Process offline queue\n   */\n  private async processOfflineQueue(): Promise<void> {\n    while (this.offlineQueue.length > 0) {\n      const error = this.offlineQueue.shift();\n      if (error) {\n        await this.handleError(error);\n      }\n    }\n  }\n\n  /**\n   * Wait for network connection\n   */\n  private async waitForNetwork(timeout = 30000): Promise<void> {\n    const startTime = Date.now();\n\n    while (!isOnline() && Date.now() - startTime < timeout) {\n      await new Promise((resolve) => setTimeout(resolve, 1000));\n    }\n\n    if (!isOnline()) {\n      throw new Error(\"Network timeout\");\n    }\n  }\n\n  /**\n   * Handle unrecoverable error\n   */\n  private handleUnrecoverableError(error: BaseVideoError, context: ErrorContext): void {\n    // Log for analytics\n    if (this.config.enableAnalytics) {\n      this.logError(error, context, false);\n    }\n\n    // Add to offline queue if network error\n    if (!isOnline()) {\n      this.offlineQueue.push(error);\n    }\n  }\n\n  /**\n   * Calculate error priority\n   */\n  private calculateErrorPriority(error: BaseVideoError): number {\n    let priority = 0;\n\n    // Severity-based priority\n    switch (error.severity) {\n      case VideoErrorSeverity.CRITICAL:\n        priority += 100;\n        break;\n      case VideoErrorSeverity.ERROR:\n        priority += 50;\n        break;\n      case VideoErrorSeverity.WARNING:\n        priority += 25;\n        break;\n    }\n\n    // Type-based priority\n    switch (error.code) {\n      case VideoErrorCode.PLAYBACK_STALLED:\n      case VideoErrorCode.BUFFERING_TIMEOUT:\n        priority += 30; // User-facing issues get higher priority\n        break;\n      case VideoErrorCode.NETWORK_ERROR:\n        priority += 20;\n        break;\n      case VideoErrorCode.DISPOSAL_ERROR:\n        priority += 10; // Background issues get lower priority\n        break;\n    }\n\n    return priority;\n  }\n\n  /**\n   * Should notify user about error\n   */\n  private shouldNotifyUser(error: BaseVideoError, attemptCount: number, success: boolean): boolean {\n    if (!this.config.enableUserNotifications) {\n      return false;\n    }\n\n    const policy = this.recoveryPolicies.get(error.code);\n    if (!policy) {\n      return false;\n    }\n\n    return !success && attemptCount >= policy.userNotificationThreshold;\n  }\n\n  /**\n   * Notify user about error\n   */\n  private notifyUser(message: string, suggestions: string[]): void {\n    // Implementation would show user notification\n    console.log(`User notification: ${message}`, suggestions);\n  }\n\n  /**\n   * Get or create circuit breaker for error type\n   */\n  private getOrCreateCircuitBreaker(errorCode: VideoErrorCode): CircuitBreakerState {\n    let breaker = this.circuitBreakers.get(errorCode);\n\n    if (!breaker) {\n      breaker = {\n        errorCode,\n        state: \"closed\",\n        failureCount: 0,\n        lastFailureTime: 0,\n        successCount: 0,\n        nextRetryTime: 0,\n      };\n      this.circuitBreakers.set(errorCode, breaker);\n    }\n\n    return breaker;\n  }\n\n  /**\n   * Update circuit breaker state\n   */\n  private updateCircuitBreaker(errorCode: VideoErrorCode, success: boolean): void {\n    const breaker = this.getOrCreateCircuitBreaker(errorCode);\n\n    if (success) {\n      breaker.successCount++;\n      if (breaker.state === \"half-open\") {\n        breaker.state = \"closed\";\n        breaker.failureCount = 0;\n      }\n    } else {\n      breaker.failureCount++;\n      breaker.lastFailureTime = Date.now();\n\n      if (breaker.failureCount >= this.config.circuitBreakerThreshold) {\n        breaker.state = \"open\";\n        breaker.nextRetryTime = Date.now() + this.config.circuitBreakerTimeout;\n      }\n    }\n  }\n\n  /**\n   * Create recovery result\n   */\n  private createRecoveryResult(\n    success: boolean,\n    errorCode: VideoErrorCode,\n    strategyType: string,\n    attemptCount: number,\n    duration: number,\n    fallbackUsed = false,\n    userNotified = false,\n  ): RecoveryResult {\n    return {\n      success,\n      errorCode,\n      recoveryStrategy: { type: strategyType as any },\n      attemptCount,\n      duration,\n      timestamp: Date.now(), // Comment 4: Populate timestamp\n      fallbackUsed,\n      userNotified,\n    };\n  }\n\n  /**\n   * Record recovery result for analytics\n   */\n  private recordRecoveryResult(result: RecoveryResult): void {\n    this.recoveryHistory.push(result);\n\n    if (this.config.enableAnalytics) {\n      this.logRecovery(result);\n    }\n  }\n\n  /**\n   * Log error for analytics\n   */\n  private logError(error: BaseVideoError, context: ErrorContext, recoverable: boolean): void {\n    // Implementation would send to analytics service\n    console.log(\"Error logged:\", { error, context, recoverable });\n  }\n\n  /**\n   * Log recovery for analytics\n   */\n  private logRecovery(result: RecoveryResult): void {\n    // Implementation would send to analytics service\n    console.log(\"Recovery logged:\", result);\n  }\n\n  /**\n   * Clean up old history\n   */\n  private cleanupOldHistory(): void {\n    const cutoffTime = Date.now() - 24 * 60 * 60 * 1000; // 24 hours\n    // Comment 4: Filter by timestamp instead of duration\n    this.recoveryHistory = this.recoveryHistory.filter((result) => result.timestamp > cutoffTime);\n  }\n\n  /**\n   * Analyze patterns and optimize policies\n   */\n  private analyzeAndOptimize(): void {\n    if (!this.config.enableAnalytics) {\n      return;\n    }\n\n    const patterns = analyzeErrorPatterns();\n\n    // Adjust policies based on patterns\n    if (patterns.recentTrend === \"increasing\") {\n      // Increase circuit breaker thresholds temporarily\n      this.config.circuitBreakerThreshold = Math.min(10, this.config.circuitBreakerThreshold + 1);\n    } else if (patterns.recentTrend === \"decreasing\") {\n      // Restore normal thresholds\n      this.config.circuitBreakerThreshold = Math.max(5, this.config.circuitBreakerThreshold - 1);\n    }\n\n    // Update policies for frequent errors\n    for (const errorCode of patterns.mostFrequent) {\n      const policy = this.recoveryPolicies.get(errorCode);\n      if (policy && policy.maxRetries > 1) {\n        // Reduce retries for consistently failing errors\n        const successRate = this.calculateSuccessRate(errorCode);\n        if (successRate < 0.2) {\n          policy.maxRetries = Math.max(1, policy.maxRetries - 1);\n        }\n      }\n    }\n  }\n\n  /**\n   * Calculate success rate for error type\n   */\n  private calculateSuccessRate(errorCode: VideoErrorCode): number {\n    const relevantResults = this.recoveryHistory.filter((r) => r.errorCode === errorCode);\n\n    if (relevantResults.length === 0) {\n      return 0;\n    }\n\n    const successCount = relevantResults.filter((r) => r.success).length;\n    return successCount / relevantResults.length;\n  }\n\n  /**\n   * Timeout utility\n   */\n  private timeout(ms: number): Promise<never> {\n    return new Promise((_, reject) => {\n      setTimeout(() => reject(new Error(\"Recovery timeout\")), ms);\n    });\n  }\n\n  /**\n   * Initialize default recovery policies\n   */\n  private initializeDefaultPolicies(): Map<VideoErrorCode, RecoveryPolicy> {\n    const policies = new Map<VideoErrorCode, RecoveryPolicy>();\n\n    // Network errors\n    policies.set(VideoErrorCode.NETWORK_ERROR, {\n      errorCode: VideoErrorCode.NETWORK_ERROR,\n      maxRetries: 5,\n      backoffStrategy: \"exponential\",\n      cooldownPeriod: 2000,\n      fallbackEnabled: true,\n      userNotificationThreshold: 3,\n    });\n\n    // Playback errors\n    policies.set(VideoErrorCode.PLAYBACK_STALLED, {\n      errorCode: VideoErrorCode.PLAYBACK_STALLED,\n      maxRetries: 3,\n      backoffStrategy: \"exponential\",\n      cooldownPeriod: 1000,\n      fallbackEnabled: true,\n      userNotificationThreshold: 2,\n    });\n\n    // Rate limit errors\n    policies.set(VideoErrorCode.RATE_LIMITED, {\n      errorCode: VideoErrorCode.RATE_LIMITED,\n      maxRetries: 3,\n      backoffStrategy: \"exponential\",\n      cooldownPeriod: 30000,\n      fallbackEnabled: false,\n      userNotificationThreshold: 1,\n    });\n\n    // Source errors\n    policies.set(VideoErrorCode.SOURCE_NOT_FOUND, {\n      errorCode: VideoErrorCode.SOURCE_NOT_FOUND,\n      maxRetries: 2,\n      backoffStrategy: \"linear\",\n      cooldownPeriod: 1000,\n      fallbackEnabled: true,\n      userNotificationThreshold: 1,\n    });\n\n    // Disposal errors\n    policies.set(VideoErrorCode.DISPOSAL_ERROR, {\n      errorCode: VideoErrorCode.DISPOSAL_ERROR,\n      maxRetries: 3,\n      backoffStrategy: \"fixed\",\n      cooldownPeriod: 100,\n      fallbackEnabled: false,\n      userNotificationThreshold: 99, // Don't notify for disposal errors\n    });\n\n    return policies;\n  }\n\n  /**\n   * Initialize default fallback sources\n   */\n  private initializeDefaultFallbacks(): FallbackSource[] {\n    return [\n      {\n        url: \"https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\",\n        quality: \"high\",\n        isLocal: false,\n        priority: 1,\n      },\n      {\n        url: \"https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/Sintel.mp4\",\n        quality: \"medium\",\n        isLocal: false,\n        priority: 2,\n      },\n      {\n        url: \"https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/TearsOfSteel.mp4\",\n        quality: \"low\",\n        isLocal: false,\n        priority: 3,\n      },\n    ];\n  }\n\n  /**\n   * Get current service status\n   */\n  getStatus(): {\n    activeRecoveries: number;\n    queuedErrors: number;\n    circuitBreakers: { code: VideoErrorCode; state: string }[];\n    successRate: number;\n    recentErrors: number;\n  } {\n    // Comment 4: Check timestamp for recent errors\n    const recentErrors = this.recoveryHistory.filter((r) => r.timestamp > Date.now() - 5 * 60 * 1000).length;\n\n    const successRate = this.calculateOverallSuccessRate();\n\n    return {\n      activeRecoveries: this.activeRecoveries.size,\n      queuedErrors: this.errorQueue.length,\n      circuitBreakers: Array.from(this.circuitBreakers.values()).map((b) => ({\n        code: b.errorCode,\n        state: b.state,\n      })),\n      successRate,\n      recentErrors,\n    };\n  }\n\n  /**\n   * Calculate overall success rate\n   */\n  private calculateOverallSuccessRate(): number {\n    if (this.recoveryHistory.length === 0) {\n      return 1;\n    }\n\n    const successCount = this.recoveryHistory.filter((r) => r.success).length;\n    return successCount / this.recoveryHistory.length;\n  }\n\n  /**\n   * Update configuration\n   */\n  updateConfig(config: Partial<VideoErrorRecoveryConfig>): void {\n    this.config = {\n      ...this.config,\n      ...config,\n    };\n  }\n\n  /**\n   * Update recovery policy\n   */\n  updatePolicy(errorCode: VideoErrorCode, policy: Partial<RecoveryPolicy>): void {\n    const existingPolicy = this.recoveryPolicies.get(errorCode);\n    if (existingPolicy) {\n      this.recoveryPolicies.set(errorCode, {\n        ...existingPolicy,\n        ...policy,\n      });\n    }\n  }\n\n  /**\n   * Add fallback source\n   */\n  addFallbackSource(source: FallbackSource): void {\n    this.fallbackSources.push(source);\n    this.fallbackSources.sort((a, b) => a.priority - b.priority);\n  }\n\n  /**\n   * Clear recovery history\n   */\n  clearHistory(): void {\n    this.recoveryHistory = [];\n  }\n\n  /**\n   * Reset circuit breakers\n   */\n  resetCircuitBreakers(): void {\n    this.circuitBreakers.clear();\n  }\n\n  /**\n   * Reset service\n   */\n  reset(): void {\n    this.errorQueue = [];\n    this.activeRecoveries.clear();\n    this.recoveryHistory = [];\n    this.circuitBreakers.clear();\n    this.offlineQueue = [];\n    this.isProcessing = false;\n  }\n}\n\n// Export singleton instance\nexport const videoErrorRecoveryService = VideoErrorRecoveryService.getInstance();\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/VideoQualitySelector.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'healthMonitor' is defined but never used.","line":4,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":4,"endColumn":23},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":356,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":356,"endColumn":21}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import NetInfo, { NetInfoState } from \"@react-native-community/netinfo\";\nimport { Platform } from \"react-native\";\nimport { environmentDetector } from \"../utils/environmentDetector\";\nimport { healthMonitor } from \"../utils/healthMonitor\";\nimport AsyncStorage from \"@react-native-async-storage/async-storage\";\nimport { networkProfiler } from \"../utils/networkProfiler\";\n\nexport type VideoQuality = \"360p\" | \"720p\" | \"1080p\";\ntype NetworkQuality = \"poor\" | \"fair\" | \"good\" | \"excellent\";\ntype DeviceCapabilityTier = \"low\" | \"mid\" | \"high\";\n\ninterface NetworkProfile {\n  bandwidth: number;\n  connectionType: string;\n  stability: number;\n  quality: NetworkQuality;\n  timestamp: number;\n}\n\ninterface QualityVariant {\n  quality: VideoQuality;\n  uri: string;\n  bitrate: number;\n}\n\ninterface QualitySelectionResult {\n  selectedQuality: VideoQuality;\n  variants: QualityVariant[];\n  fallbackQuality?: VideoQuality;\n  networkProfile: NetworkProfile;\n  deviceTier: DeviceCapabilityTier;\n}\n\nclass NetworkProfiler {\n  private lastProfile: NetworkProfile | null = null;\n  private measurementCache = new Map<string, NetworkProfile>();\n  private stabilityHistory: number[] = [];\n  private readonly CACHE_DURATION = 60000;\n  private readonly STABILITY_WINDOW = 10;\n\n  async measureBandwidth(): Promise<number> {\n    try {\n      // Use the network profiler utility for accurate measurement\n      const profile = await networkProfiler.getCurrentProfile();\n      if (profile && profile.bandwidth > 0) {\n        return profile.bandwidth;\n      }\n\n      // Fallback to network profiler's measurement if no cached profile\n      const newProfile = await networkProfiler.measureNetworkCondition();\n      if (newProfile && newProfile.bandwidth > 0) {\n        return newProfile.bandwidth;\n      }\n\n      // Final fallback to estimation\n      return this.estimateBandwidthFromConnection();\n    } catch (error) {\n      console.error(\"Bandwidth measurement failed:\", error);\n      return this.estimateBandwidthFromConnection();\n    }\n  }\n\n  private async estimateBandwidthFromConnection(): Promise<number> {\n    const netInfo = await NetInfo.fetch();\n\n    const bandwidthMap: Record<string, number> = {\n      \"2g\": 0.05,\n      \"3g\": 0.5,\n      \"4g\": 5,\n      \"5g\": 20,\n      wifi: 10,\n      ethernet: 100,\n      unknown: 2,\n    };\n\n    const type = netInfo.type.toLowerCase();\n    const effectiveType = (netInfo.details as any)?.cellularGeneration?.toLowerCase() || type;\n\n    return bandwidthMap[effectiveType] || bandwidthMap[type] || bandwidthMap.unknown;\n  }\n\n  async getNetworkProfile(forceRefresh = false): Promise<NetworkProfile> {\n    // Use networkProfiler utility for consistent network measurement\n    const utilityProfile = await (forceRefresh\n      ? networkProfiler.measureNetworkCondition()\n      : networkProfiler.getCurrentProfile() || networkProfiler.measureNetworkCondition());\n\n    if (utilityProfile) {\n      // Convert from utility profile format\n      const profile: NetworkProfile = {\n        bandwidth: utilityProfile.bandwidth,\n        connectionType: utilityProfile.connectionType,\n        stability: utilityProfile.stability,\n        quality: utilityProfile.quality as NetworkQuality,\n        timestamp: utilityProfile.timestamp,\n      };\n\n      this.lastProfile = profile;\n      this.measurementCache.set(\"current\", profile);\n      await this.persistProfile(profile);\n\n      return profile;\n    }\n\n    // Fallback to basic network info if utility fails\n    const netInfo = await NetInfo.fetch();\n    const bandwidth = await this.estimateBandwidthFromConnection();\n    const stability = 0.5; // Default medium stability\n    const quality = this.classifyNetworkQuality(bandwidth, stability);\n\n    const profile: NetworkProfile = {\n      bandwidth,\n      connectionType: netInfo.type,\n      stability,\n      quality,\n      timestamp: Date.now(),\n    };\n\n    this.lastProfile = profile;\n    this.measurementCache.set(\"current\", profile);\n    await this.persistProfile(profile);\n\n    return profile;\n  }\n\n  private calculateStability(): number {\n    if (this.stabilityHistory.length < 2) return 1;\n\n    const mean = this.stabilityHistory.reduce((a, b) => a + b, 0) / this.stabilityHistory.length;\n    const variance =\n      this.stabilityHistory.reduce((sum, val) => {\n        return sum + Math.pow(val - mean, 2);\n      }, 0) / this.stabilityHistory.length;\n\n    const coefficientOfVariation = Math.sqrt(variance) / mean;\n    return Math.max(0, 1 - coefficientOfVariation);\n  }\n\n  private classifyNetworkQuality(bandwidth: number, stability: number): NetworkQuality {\n    const adjustedBandwidth = bandwidth * stability;\n\n    if (adjustedBandwidth >= 5) return \"excellent\";\n    if (adjustedBandwidth >= 2) return \"good\";\n    if (adjustedBandwidth >= 0.5) return \"fair\";\n    return \"poor\";\n  }\n\n  private async persistProfile(profile: NetworkProfile): Promise<void> {\n    try {\n      await AsyncStorage.setItem(\"last_network_profile\", JSON.stringify(profile));\n    } catch (error) {\n      console.error(\"Failed to persist network profile:\", error);\n    }\n  }\n\n  async loadPersistedProfile(): Promise<NetworkProfile | null> {\n    try {\n      const stored = await AsyncStorage.getItem(\"last_network_profile\");\n      return stored ? JSON.parse(stored) : null;\n    } catch (error) {\n      console.error(\"Failed to load persisted profile:\", error);\n      return null;\n    }\n  }\n}\n\nclass DeviceCapabilityDetector {\n  private cachedTier: DeviceCapabilityTier | null = null;\n  private readonly detectionCache = new Map<string, any>();\n\n  async detectDeviceTier(): Promise<DeviceCapabilityTier> {\n    if (this.cachedTier) return this.cachedTier;\n\n    const deviceInfo = await environmentDetector.getDeviceInfo();\n    const memoryInfo = await environmentDetector.getMemoryInfo();\n\n    const totalMemoryGB = memoryInfo.totalMemory / (1024 * 1024 * 1024);\n    const isTablet = deviceInfo.deviceType === \"tablet\";\n    const platform = Platform.OS;\n\n    let tier: DeviceCapabilityTier;\n\n    if (platform === \"ios\") {\n      const model = deviceInfo.modelName?.toLowerCase() || \"\";\n\n      if (\n        model.includes(\"iphone 14\") ||\n        model.includes(\"iphone 15\") ||\n        model.includes(\"ipad pro\") ||\n        totalMemoryGB >= 6\n      ) {\n        tier = \"high\";\n      } else if (\n        model.includes(\"iphone 11\") ||\n        model.includes(\"iphone 12\") ||\n        model.includes(\"iphone 13\") ||\n        totalMemoryGB >= 4\n      ) {\n        tier = \"mid\";\n      } else {\n        tier = \"low\";\n      }\n    } else {\n      if (totalMemoryGB >= 8) {\n        tier = \"high\";\n      } else if (totalMemoryGB >= 4) {\n        tier = \"mid\";\n      } else {\n        tier = \"low\";\n      }\n    }\n\n    if (isTablet && tier !== \"high\") {\n      tier = \"mid\";\n    }\n\n    this.cachedTier = tier;\n    await this.persistDeviceTier(tier);\n\n    return tier;\n  }\n\n  private async persistDeviceTier(tier: DeviceCapabilityTier): Promise<void> {\n    try {\n      await AsyncStorage.setItem(\"device_capability_tier\", tier);\n    } catch (error) {\n      console.error(\"Failed to persist device tier:\", error);\n    }\n  }\n\n  async loadPersistedTier(): Promise<DeviceCapabilityTier | null> {\n    try {\n      const stored = await AsyncStorage.getItem(\"device_capability_tier\");\n      return stored as DeviceCapabilityTier | null;\n    } catch (error) {\n      console.error(\"Failed to load persisted tier:\", error);\n      return null;\n    }\n  }\n\n  getMemoryBasedQualityLimit(memoryPressure: number): VideoQuality {\n    if (memoryPressure > 0.8) return \"360p\";\n    if (memoryPressure > 0.6) return \"720p\";\n    return \"1080p\";\n  }\n}\n\nclass QualitySelectionEngine {\n  private readonly qualityMatrix: Record<DeviceCapabilityTier, Record<NetworkQuality, VideoQuality>> = {\n    high: {\n      excellent: \"1080p\",\n      good: \"1080p\",\n      fair: \"720p\",\n      poor: \"360p\",\n    },\n    mid: {\n      excellent: \"1080p\",\n      good: \"720p\",\n      fair: \"720p\",\n      poor: \"360p\",\n    },\n    low: {\n      excellent: \"720p\",\n      good: \"720p\",\n      fair: \"360p\",\n      poor: \"360p\",\n    },\n  };\n\n  private readonly bitrateMap: Record<VideoQuality, number> = {\n    \"360p\": 800,\n    \"720p\": 2500,\n    \"1080p\": 5000,\n  };\n\n  selectOptimalQuality(\n    networkProfile: NetworkProfile,\n    deviceTier: DeviceCapabilityTier,\n    memoryPressure?: number,\n  ): VideoQuality {\n    let baseQuality = this.qualityMatrix[deviceTier][networkProfile.quality];\n\n    if (memoryPressure && memoryPressure > 0.5) {\n      const detector = new DeviceCapabilityDetector();\n      const memoryLimit = detector.getMemoryBasedQualityLimit(memoryPressure);\n      baseQuality = this.downgradeQuality(baseQuality, memoryLimit);\n    }\n\n    if (networkProfile.stability < 0.5) {\n      baseQuality = this.downgradeQuality(baseQuality);\n    }\n\n    return baseQuality;\n  }\n\n  private downgradeQuality(current: VideoQuality, limit?: VideoQuality): VideoQuality {\n    const qualities: VideoQuality[] = [\"360p\", \"720p\", \"1080p\"];\n    const currentIndex = qualities.indexOf(current);\n    const limitIndex = limit ? qualities.indexOf(limit) : -1;\n\n    if (limitIndex >= 0 && currentIndex > limitIndex) {\n      return limit!;\n    }\n\n    if (currentIndex > 0) {\n      return qualities[currentIndex - 1];\n    }\n\n    return current;\n  }\n\n  async generateQualityVariants(baseUri: string, selectedQuality: VideoQuality): Promise<QualityVariant[]> {\n    const variants: QualityVariant[] = [];\n    const qualities: VideoQuality[] = [\"360p\", \"720p\", \"1080p\"];\n    const selectedIndex = qualities.indexOf(selectedQuality);\n\n    const extension = baseUri.split(\".\").pop() || \"mp4\";\n    const basePath = baseUri.substring(0, baseUri.lastIndexOf(\".\"));\n\n    // Always include the original as fallback\n    variants.push({\n      quality: selectedQuality,\n      uri: baseUri,\n      bitrate: this.bitrateMap[selectedQuality],\n    });\n\n    // Generate potential variant URIs and validate them\n    const potentialVariants: QualityVariant[] = [];\n    for (let i = 0; i <= selectedIndex; i++) {\n      const quality = qualities[i];\n      if (quality !== selectedQuality) {\n        potentialVariants.push({\n          quality,\n          uri: `${basePath}_${quality.replace(\"p\", \"\")}.${extension}`,\n          bitrate: this.bitrateMap[quality],\n        });\n      }\n    }\n\n    // Validate variants exist (HEAD request with timeout)\n    const validationPromises = potentialVariants.map(async (variant) => {\n      try {\n        const controller = new AbortController();\n        const timeout = setTimeout(() => controller.abort(), 2000); // 2 second timeout\n\n        const response = await fetch(variant.uri, {\n          method: \"HEAD\",\n          signal: controller.signal,\n        });\n\n        clearTimeout(timeout);\n\n        if (response.ok) {\n          return variant;\n        }\n      } catch (error) {\n        // Variant doesn't exist or network error\n      }\n      return null;\n    });\n\n    const validatedVariants = await Promise.all(validationPromises);\n\n    // Add only valid variants\n    for (const variant of validatedVariants) {\n      if (variant) {\n        variants.push(variant);\n      }\n    }\n\n    return variants;\n  }\n\n  selectFallbackQuality(currentQuality: VideoQuality): VideoQuality | undefined {\n    const qualities: VideoQuality[] = [\"360p\", \"720p\", \"1080p\"];\n    const currentIndex = qualities.indexOf(currentQuality);\n\n    if (currentIndex > 0) {\n      return qualities[currentIndex - 1];\n    }\n\n    return undefined;\n  }\n}\n\nexport class VideoQualitySelector {\n  private networkProfiler: NetworkProfiler;\n  private deviceDetector: DeviceCapabilityDetector;\n  private selectionEngine: QualitySelectionEngine;\n  private selectionCache: Map<string, QualitySelectionResult> = new Map();\n  private networkListener: any = null;\n\n  constructor() {\n    this.networkProfiler = new NetworkProfiler();\n    this.deviceDetector = new DeviceCapabilityDetector();\n    this.selectionEngine = new QualitySelectionEngine();\n    this.initializeNetworkListener();\n  }\n\n  private initializeNetworkListener(): void {\n    this.networkListener = NetInfo.addEventListener((state) => {\n      this.handleNetworkChange(state);\n    });\n  }\n\n  private async handleNetworkChange(state: NetInfoState): Promise<void> {\n    if (!state.isConnected) return;\n\n    const profile = await this.networkProfiler.getNetworkProfile(true);\n    // Clear cache on significant network change\n    for (const [uri, selection] of this.selectionCache.entries()) {\n      if (profile.quality !== selection.networkProfile.quality) {\n        this.selectionCache.delete(uri);\n      }\n    }\n  }\n\n  async selectVideoQuality(videoUri: string, forceRefresh = false): Promise<QualitySelectionResult> {\n    if (!forceRefresh && this.selectionCache.has(videoUri)) {\n      return this.selectionCache.get(videoUri)!;\n    }\n\n    const [networkProfile, deviceTier] = await Promise.all([\n      this.networkProfiler.getNetworkProfile(forceRefresh),\n      this.deviceDetector.detectDeviceTier(),\n    ]);\n\n    const memoryInfo = await environmentDetector.getMemoryInfo();\n    const memoryPressure = (memoryInfo.totalMemory - memoryInfo.availableMemory) / memoryInfo.totalMemory;\n\n    const selectedQuality = this.selectionEngine.selectOptimalQuality(networkProfile, deviceTier, memoryPressure);\n\n    const variants = await this.selectionEngine.generateQualityVariants(videoUri, selectedQuality);\n    const fallbackQuality = this.selectionEngine.selectFallbackQuality(selectedQuality);\n\n    const selection = {\n      selectedQuality,\n      variants,\n      fallbackQuality,\n      networkProfile,\n      deviceTier,\n    };\n\n    this.selectionCache.set(videoUri, selection);\n    return selection;\n  }\n\n  async selectBatchVideoQualities(videoUris: string[]): Promise<Map<string, QualitySelectionResult>> {\n    const [networkProfile, deviceTier] = await Promise.all([\n      this.networkProfiler.getNetworkProfile(),\n      this.deviceDetector.detectDeviceTier(),\n    ]);\n\n    const memoryInfo = await environmentDetector.getMemoryInfo();\n    const memoryPressure = (memoryInfo.totalMemory - memoryInfo.availableMemory) / memoryInfo.totalMemory;\n\n    const selectedQuality = this.selectionEngine.selectOptimalQuality(networkProfile, deviceTier, memoryPressure);\n\n    const results = new Map<string, QualitySelectionResult>();\n\n    for (const uri of videoUris) {\n      const variants = await this.selectionEngine.generateQualityVariants(uri, selectedQuality);\n      const fallbackQuality = this.selectionEngine.selectFallbackQuality(selectedQuality);\n\n      results.set(uri, {\n        selectedQuality,\n        variants,\n        fallbackQuality,\n        networkProfile,\n        deviceTier,\n      });\n    }\n\n    return results;\n  }\n\n  async canUpgradeQuality(videoUri: string): Promise<boolean> {\n    const selection = this.selectionCache.get(videoUri);\n    if (!selection) return false;\n\n    const currentProfile = await this.networkProfiler.getNetworkProfile();\n    const currentQuality = selection.selectedQuality;\n\n    return currentProfile.quality === \"excellent\" && currentQuality !== \"1080p\" && currentProfile.stability > 0.8;\n  }\n\n  async shouldDowngradeQuality(videoUri: string): Promise<boolean> {\n    const selection = this.selectionCache.get(videoUri);\n    if (!selection) return false;\n\n    const currentProfile = await this.networkProfiler.getNetworkProfile();\n    const currentQuality = selection.selectedQuality;\n\n    return (currentProfile.quality === \"poor\" && currentQuality !== \"360p\") || currentProfile.stability < 0.3;\n  }\n\n  getQualityForUri(uri: string, quality: VideoQuality): string {\n    const extension = uri.split(\".\").pop() || \"mp4\";\n    const basePath = uri.substring(0, uri.lastIndexOf(\".\"));\n    return `${basePath}_${quality.replace(\"p\", \"\")}.${extension}`;\n  }\n\n  cleanup(): void {\n    if (this.networkListener) {\n      this.networkListener();\n      this.networkListener = null;\n    }\n  }\n}\n\nexport const videoQualitySelector = new VideoQualitySelector();\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/VisionCameraProcessor.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'FileSystem' is defined but never used.","line":14,"column":13,"nodeType":null,"messageId":"unusedVar","endLine":14,"endColumn":23},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'VideoView' is defined but never used.","line":16,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":16,"endColumn":19},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'useVideoPlayer' is defined but never used.","line":16,"column":21,"nodeType":null,"messageId":"unusedVar","endLine":16,"endColumn":35},{"ruleId":"import/no-unresolved","severity":2,"message":"Unable to resolve path to module 'react-native-worklets-core'.","line":75,"column":43,"nodeType":"Literal","endLine":75,"endColumn":71},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":84,"column":12,"nodeType":null,"messageId":"unusedVar","endLine":84,"endColumn":17},{"ruleId":"react-hooks/rules-of-hooks","severity":2,"message":"React Hook \"useFrameProcessor\" cannot be called in a class component. React Hooks must be called in a React function component or a custom React Hook function.","line":161,"column":12,"nodeType":"Identifier","endLine":161,"endColumn":29},{"ruleId":"react-hooks/rules-of-hooks","severity":2,"message":"React Hook \"useSkiaFrameProcessor\" cannot be called in a class component. React Hooks must be called in a React function component or a custom React Hook function.","line":178,"column":12,"nodeType":"Identifier","endLine":178,"endColumn":33},{"ruleId":"react-hooks/rules-of-hooks","severity":2,"message":"React Hook \"useCameraDevice\" cannot be called in a class component. React Hooks must be called in a React function component or a custom React Hook function.","line":331,"column":13,"nodeType":"Identifier","endLine":331,"endColumn":28},{"ruleId":"react-hooks/rules-of-hooks","severity":2,"message":"React Hook \"useCameraDevice\" cannot be called in a class component. React Hooks must be called in a React function component or a custom React Hook function.","line":332,"column":14,"nodeType":"Identifier","endLine":332,"endColumn":29},{"ruleId":"react-hooks/rules-of-hooks","severity":2,"message":"React Hook \"useCameraDevice\" cannot be called in a class component. React Hooks must be called in a React function component or a custom React Hook function.","line":333,"column":17,"nodeType":"Identifier","endLine":333,"endColumn":32},{"ruleId":"react-hooks/rules-of-hooks","severity":2,"message":"React Hook \"useCameraFormat\" cannot be called in a class component. React Hooks must be called in a React function component or a custom React Hook function.","line":345,"column":12,"nodeType":"Identifier","endLine":345,"endColumn":27}],"suppressedMessages":[],"errorCount":7,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Vision Camera v4 Video Processing Service\n * September 2025 - Compatible with Reanimated v4\n *\n * Features:\n * - Frame processors with worklets\n * - Real-time video effects\n * - Face detection integration\n * - Skia integration for drawing\n * - Automatic Expo Go fallbacks\n */\n\nimport { Platform } from \"react-native\";\nimport * as FileSystem from \"../utils/legacyFileSystem\";\nimport * as VideoThumbnails from \"expo-video-thumbnails\";\nimport { VideoView, useVideoPlayer } from \"expo-video\";\nimport { isExpoGo, hasVideoProcessing } from \"../utils/environmentDetector\";\n\n// Vision Camera v4 types\nexport interface VisionCameraConfig {\n  device?: \"front\" | \"back\";\n  format?: any;\n  fps?: number;\n  videoHdr?: boolean;\n  photoHdr?: boolean;\n  lowLightBoost?: boolean;\n  videoStabilizationMode?: \"off\" | \"standard\" | \"cinematic\" | \"cinematic-extended\" | \"auto\";\n  torch?: \"off\" | \"on\";\n  zoom?: number;\n  exposure?: number;\n}\n\n// Lazy load Vision Camera for development builds\nlet Camera: any = null;\nlet useCameraDevice: any = null;\nlet useCameraFormat: any = null;\nlet useFrameProcessor: any = null;\nlet useSkiaFrameProcessor: any = null;\nlet Worklets: any = null;\n\nconst loadVisionCamera = async () => {\n  if (isExpoGo()) {\n    console.log(\"üì± Vision Camera not available in Expo Go - using expo-camera fallback\");\n    return false;\n  }\n\n  try {\n    // Load react-native-vision-camera v4\n    const visionCameraModule = await import(\"react-native-vision-camera\");\n    Camera = visionCameraModule.Camera;\n    useCameraDevice = visionCameraModule.useCameraDevice;\n    useCameraFormat = visionCameraModule.useCameraFormat;\n    useFrameProcessor = visionCameraModule.useFrameProcessor;\n\n    // Load Skia integration if available\n    try {\n      const skiaModule = await import(\"@shopify/react-native-skia\");\n      // Check if useSkiaFrameProcessor exists in the module\n      if (\"useSkiaFrameProcessor\" in skiaModule) {\n        useSkiaFrameProcessor = skiaModule.useSkiaFrameProcessor;\n      } else {\n        console.log(\"‚ö†Ô∏è Skia frame processor not available in this version\");\n      }\n    } catch {\n      console.log(\"‚ö†Ô∏è Skia not available for advanced effects\");\n    }\n\n    // Load worklets\n    try {\n      const workletsModule = await import(\"react-native-worklets\");\n      Worklets = workletsModule;\n    } catch {\n      // Fallback to worklets-core for Vision Camera compatibility\n      try {\n        const workletsCore = await import(\"react-native-worklets-core\");\n        Worklets = workletsCore;\n      } catch {\n        console.log(\"‚ö†Ô∏è Worklets not available\");\n      }\n    }\n\n    console.log(\"‚úÖ Vision Camera v4 loaded successfully\");\n    return true;\n  } catch (error) {\n    console.log(\"‚ö†Ô∏è Vision Camera not available - using fallback\");\n    return false;\n  }\n};\n\nexport class VisionCameraProcessor {\n  private static instance: VisionCameraProcessor;\n  private static initPromise: Promise<VisionCameraProcessor> | null = null;\n  private isVisionCameraAvailable: boolean = false;\n\n  static async getInstance(): Promise<VisionCameraProcessor> {\n    if (!this.instance) {\n      if (!this.initPromise) {\n        this.initPromise = this.createInstance();\n      }\n      return this.initPromise;\n    }\n    return this.instance;\n  }\n\n  private static async createInstance(): Promise<VisionCameraProcessor> {\n    this.instance = new VisionCameraProcessor();\n    await this.instance.initialize();\n    this.initPromise = null; // Clear the promise after completion\n    return this.instance;\n  }\n\n  private async initialize() {\n    this.isVisionCameraAvailable = await loadVisionCamera();\n  }\n\n  /**\n   * Check if Vision Camera is available\n   */\n  isAvailable(): boolean {\n    return this.isVisionCameraAvailable && !isExpoGo();\n  }\n\n  /**\n   * Get camera components based on availability\n   */\n  getCameraComponents() {\n    if (this.isVisionCameraAvailable) {\n      return {\n        Camera,\n        useCameraDevice,\n        useCameraFormat,\n        useFrameProcessor,\n        useSkiaFrameProcessor,\n        isAvailable: true,\n      };\n    }\n\n    // Return Expo Camera fallback components\n    return {\n      Camera: null,\n      useCameraDevice: null,\n      useCameraFormat: null,\n      useFrameProcessor: null,\n      useSkiaFrameProcessor: null,\n      isAvailable: false,\n    };\n  }\n\n  /**\n   * Create a frame processor for real-time video effects\n   * Compatible with Reanimated v4 worklets\n   */\n  createFrameProcessor(processFrame: (frame: any) => void) {\n    \"worklet\";\n\n    if (!this.isVisionCameraAvailable || !useFrameProcessor) {\n      console.log(\"Frame processors not available\");\n      return null;\n    }\n\n    return useFrameProcessor((frame: any) => {\n      \"worklet\";\n      processFrame(frame);\n    }, []);\n  }\n\n  /**\n   * Create a Skia frame processor for advanced drawing\n   */\n  createSkiaFrameProcessor(draw: (canvas: any, frame: any) => void) {\n    \"worklet\";\n\n    if (!useSkiaFrameProcessor) {\n      console.log(\"Skia frame processors not available\");\n      return null;\n    }\n\n    return useSkiaFrameProcessor((frame: any, canvas: any) => {\n      \"worklet\";\n      draw(canvas, frame);\n    }, []);\n  }\n\n  /**\n   * Apply face blur effect using ML Kit\n   */\n  createFaceBlurProcessor() {\n    \"worklet\";\n\n    return this.createFrameProcessor((frame) => {\n      \"worklet\";\n      // Face detection would happen here with ML Kit integration\n      // This is a placeholder for the actual implementation\n      console.log(\"Processing frame for face blur\");\n    });\n  }\n\n  /**\n   * Record video with Vision Camera\n   */\n  async recordVideo(\n    camera: any,\n    options: {\n      onRecordingStarted?: () => void;\n      onRecordingFinished?: (video: any) => void;\n      onRecordingError?: (error: any) => void;\n    } = {},\n  ): Promise<void> {\n    if (!camera || !this.isVisionCameraAvailable) {\n      console.warn(\"Vision Camera not available for recording\");\n      return;\n    }\n\n    try {\n      await camera.startRecording({\n        onRecordingStarted: options.onRecordingStarted,\n        onRecordingFinished: options.onRecordingFinished,\n        onRecordingError: options.onRecordingError,\n        videoCodec: \"h264\",\n        videoBitRate: \"high\",\n      });\n    } catch (error) {\n      console.error(\"Recording error:\", error);\n      options.onRecordingError?.(error);\n    }\n  }\n\n  /**\n   * Stop recording\n   */\n  async stopRecording(camera: any): Promise<void> {\n    if (!camera || !this.isVisionCameraAvailable) {\n      return;\n    }\n\n    try {\n      await camera.stopRecording();\n    } catch (error) {\n      console.error(\"Stop recording error:\", error);\n    }\n  }\n\n  /**\n   * Take photo with Vision Camera\n   */\n  async takePhoto(camera: any, options: any = {}): Promise<any> {\n    if (!camera || !this.isVisionCameraAvailable) {\n      console.warn(\"Vision Camera not available for photo capture\");\n      return null;\n    }\n\n    try {\n      const photo = await camera.takePhoto({\n        ...options,\n        qualityPrioritization: \"quality\",\n        enableAutoStabilization: true,\n      });\n      return photo;\n    } catch (error) {\n      console.error(\"Photo capture error:\", error);\n      return null;\n    }\n  }\n\n  /**\n   * Process video file (post-recording)\n   */\n  async processRecordedVideo(\n    videoUri: string,\n    options: {\n      blur?: boolean;\n      compress?: boolean;\n      trim?: { start: number; end: number };\n    } = {},\n  ): Promise<{ uri: string; thumbnail?: string }> {\n    // Generate thumbnail\n    let thumbnail: string | undefined;\n    try {\n      const { uri } = await VideoThumbnails.getThumbnailAsync(videoUri, {\n        time: 0,\n        quality: 0.8,\n      });\n      thumbnail = uri;\n    } catch (error) {\n      console.warn(\"Thumbnail generation failed:\", error);\n    }\n\n    // In Expo Go or without FFmpeg, return original\n    if (isExpoGo() || !hasVideoProcessing()) {\n      return {\n        uri: videoUri,\n        thumbnail,\n      };\n    }\n\n    // Process with FFmpeg in development builds\n    // This would integrate with ModernVideoProcessor for full processing\n    const { videoProcessor } = await import(\"./ModernVideoProcessor\");\n\n    try {\n      const processed = await videoProcessor.processVideo(videoUri, {\n        quality: options.compress ? \"medium\" : \"high\",\n      });\n\n      return {\n        uri: processed.uri,\n        thumbnail: processed.thumbnail || thumbnail,\n      };\n    } catch (error) {\n      console.error(\"Video processing error:\", error);\n      return {\n        uri: videoUri,\n        thumbnail,\n      };\n    }\n  }\n\n  /**\n   * Get available camera devices\n   */\n  getAvailableDevices() {\n    if (!this.isVisionCameraAvailable || !useCameraDevice) {\n      return {\n        back: null,\n        front: null,\n        external: null,\n      };\n    }\n\n    return {\n      back: useCameraDevice(\"back\"),\n      front: useCameraDevice(\"front\"),\n      external: useCameraDevice(\"external\"),\n    };\n  }\n\n  /**\n   * Get optimal format for device\n   */\n  getOptimalFormat(device: any, targetFps: number = 30) {\n    if (!device || !useCameraFormat) {\n      return null;\n    }\n\n    return useCameraFormat(device, [\n      { fps: targetFps },\n      { videoAspectRatio: 16 / 9 },\n      { videoResolution: \"max\" },\n      { photoAspectRatio: 16 / 9 },\n      { photoResolution: \"max\" },\n    ]);\n  }\n\n  /**\n   * Check camera permissions\n   */\n  async requestPermissions(): Promise<boolean> {\n    if (Platform.OS === \"web\") {\n      return true; // Web handles permissions differently\n    }\n\n    try {\n      if (this.isVisionCameraAvailable && Camera) {\n        const cameraPermission = await Camera.requestCameraPermission();\n        const microphonePermission = await Camera.requestMicrophonePermission();\n\n        return cameraPermission === \"granted\" && microphonePermission === \"granted\";\n      }\n\n      // Fallback to expo-camera permissions\n      const { Camera: ExpoCamera } = await import(\"expo-camera\");\n      const { status } = await ExpoCamera.requestCameraPermissionsAsync();\n      return status === \"granted\";\n    } catch (error) {\n      console.error(\"Permission request error:\", error);\n      return false;\n    }\n  }\n\n  /**\n   * Get capabilities summary\n   */\n  static getCapabilities() {\n    const instance = this.instance || new VisionCameraProcessor();\n\n    return {\n      visionCamera: instance.isVisionCameraAvailable,\n      frameProcessors: instance.isVisionCameraAvailable && !!useFrameProcessor,\n      skiaIntegration: !!useSkiaFrameProcessor,\n      reanimatedV4: true, // We're using v4\n      worklets: !!Worklets,\n      features: {\n        recording: instance.isVisionCameraAvailable,\n        photo: instance.isVisionCameraAvailable,\n        frameProcessing: instance.isVisionCameraAvailable && !!useFrameProcessor,\n        faceBlur: instance.isVisionCameraAvailable && !!useFrameProcessor,\n        skiaEffects: !!useSkiaFrameProcessor,\n        hdr: instance.isVisionCameraAvailable,\n        stabilization: instance.isVisionCameraAvailable,\n      },\n    };\n  }\n}\n\n// Export singleton getter\nexport const getVisionCameraProcessor = () => VisionCameraProcessor.getInstance();\n","usedDeprecatedRules":[]},{"filePath":"/Users/iamabillionaire/Downloads/SupaSecret/src/services/VoiceProcessor.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]}]